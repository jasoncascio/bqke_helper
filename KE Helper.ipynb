{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install mercury --quiet\n",
        "## ignore errors"
      ],
      "metadata": {
        "id": "-PjhpEAsZseK"
      },
      "id": "-PjhpEAsZseK",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mercury as mr"
      ],
      "metadata": {
        "id": "WBaUOZ2YZ9WB"
      },
      "id": "WBaUOZ2YZ9WB",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BQKE Helper"
      ],
      "metadata": {
        "id": "BK9Al1fMxCsw"
      },
      "id": "BK9Al1fMxCsw"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classes for consuming Knowledge Engine API"
      ],
      "metadata": {
        "id": "128MNryM3tf8"
      },
      "id": "128MNryM3tf8"
    },
    {
      "cell_type": "code",
      "id": "UmYSOwdVdtslcSEluVMwJ6Ad",
      "metadata": {
        "tags": [],
        "id": "UmYSOwdVdtslcSEluVMwJ6Ad"
      },
      "source": [
        "\"\"\"\n",
        "  ------------------------------------------\n",
        "  Classes for consuming Knowledge Engine API\n",
        "  ------------------------------------------\n",
        "\"\"\"\n",
        "\n",
        "from datetime import datetime\n",
        "from typing import List, Optional, Any, Dict, ClassVar\n",
        "from uuid import UUID\n",
        "\n",
        "from pydantic import BaseModel, Field, ValidationError\n",
        "from enum import Enum\n",
        "\n",
        "\"\"\"\n",
        "  Generic Models for KE Scans API\n",
        "\"\"\"\n",
        "class Data(BaseModel):\n",
        "    \"\"\"Represents the data source for the scan.\"\"\"\n",
        "    RESOURCE_TYPE_TABLE: ClassVar[str] = \"table\"\n",
        "    RESOURCE_TYPE_DATASET: ClassVar[str] = \"dataset\"\n",
        "\n",
        "    resource: str\n",
        "\n",
        "    @property\n",
        "    def is_for_table(self) -> bool:\n",
        "        return self.resource.split('/')[-2][:-1] == self.RESOURCE_TYPE_TABLE\n",
        "\n",
        "    @property\n",
        "    def is_for_dataset(self) -> bool:\n",
        "        return self.resource.split('/')[-2][:-1] == self.RESOURCE_TYPE_DATASET\n",
        "\n",
        "\n",
        "class OnDemand(BaseModel):\n",
        "    \"\"\"Represents an on-demand trigger configuration. Empty in the provided data.\"\"\"\n",
        "    pass\n",
        "\n",
        "\n",
        "class Trigger(BaseModel):\n",
        "    \"\"\"Represents the trigger mechanism for a scan.\"\"\"\n",
        "    on_demand: OnDemand = Field(..., alias='onDemand')\n",
        "\n",
        "\n",
        "class ExecutionSpec(BaseModel):\n",
        "    \"\"\"Represents the execution specification for a scan.\"\"\"\n",
        "    trigger: Trigger\n",
        "\n",
        "\n",
        "class ExecutionStatus(BaseModel):\n",
        "    \"\"\"Represents the execution status of the latest job for a scan.\"\"\"\n",
        "    # This field is optional as it's not present in all scan types (e.g., KNOWLEDGE_ENGINE).\n",
        "    latest_job_start_time: Optional[datetime] = Field(None, alias='latestJobStartTime')\n",
        "    latest_job_end_time: datetime = Field(..., alias='latestJobEndTime')\n",
        "    latest_job_create_time: datetime = Field(..., alias='latestJobCreateTime')\n",
        "\n",
        "\n",
        "class ScanTypeValue(Enum):\n",
        "    KNOWLEDGE_ENGINE = \"KNOWLEDGE_ENGINE\"\n",
        "    DATA_DOCUMENTATION = \"DATA_DOCUMENTATION\"\n",
        "    DATA_PROFILE = \"DATA_PROFILE\"\n",
        "\n",
        "\n",
        "class DataScan(BaseModel):\n",
        "    \"\"\"Represents a single data scan item.\"\"\"\n",
        "    name: str\n",
        "    uid: UUID\n",
        "    description: Optional[str] = None\n",
        "    display_name: Optional[str] = Field(None, alias='displayName') #***\n",
        "    state: str\n",
        "    create_time: datetime = Field(..., alias='createTime')\n",
        "    update_time: datetime = Field(..., alias='updateTime')\n",
        "    data: Data\n",
        "    execution_spec: ExecutionSpec = Field(..., alias='executionSpec')\n",
        "    execution_status: ExecutionStatus = Field(..., alias='executionStatus')\n",
        "    type: ScanTypeValue\n",
        "\n",
        "    @property\n",
        "    def is_for_table(self) -> bool:\n",
        "        return self.data.is_for_table\n",
        "\n",
        "    @property\n",
        "    def is_for_dataset(self) -> bool:\n",
        "        return self.data.is_for_dataset\n",
        "\n",
        "    @property\n",
        "    def resource_name(self) -> str:\n",
        "        return self.data.resource\n",
        "\n",
        "\n",
        "class DataScansResponse(BaseModel):\n",
        "    \"\"\"The root model for the entire JSON API response.\"\"\"\n",
        "    data_scans: List[DataScan] = Field(..., alias='dataScans')\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "  type KNOWLEDGE_ENGINE models\n",
        "\"\"\"\n",
        "class KESpec(BaseModel):\n",
        "    \"\"\"Represents knowledgeEngineSpec.\"\"\"\n",
        "    pass\n",
        "\n",
        "\n",
        "class ColumnTuple(BaseModel):\n",
        "    \"\"\"Represents a fully qualified column used in a join relationship.\"\"\"\n",
        "    entry_fqn: str = Field(..., alias='entryFqn', description=\"Fully qualified name of the BigQuery table.\")\n",
        "    field_path: str = Field(..., alias='fieldPath', description=\"The name of the column.\")\n",
        "\n",
        "\n",
        "class SchemaRelationship(BaseModel):\n",
        "    \"\"\"Defines a join relationship between two sets of columns.\"\"\"\n",
        "    left_columns_tuple: List[ColumnTuple] = Field(..., alias='leftColumnsTuple')\n",
        "    right_columns_tuple: List[ColumnTuple] = Field(..., alias='rightColumnsTuple')\n",
        "    type: str = Field(..., description=\"The type of relationship, e.g., 'JOIN'.\")\n",
        "\n",
        "\n",
        "class BusinessTerm(BaseModel):\n",
        "    \"\"\"A single term and its definition from the business glossary.\"\"\"\n",
        "    title: str\n",
        "    description: str\n",
        "\n",
        "\n",
        "class BusinessGlossary(BaseModel):\n",
        "    \"\"\"Contains a list of business terms relevant to the dataset.\"\"\"\n",
        "    terms: List[BusinessTerm]\n",
        "\n",
        "\n",
        "class DatasetResult(BaseModel):\n",
        "    \"\"\"Contains the description, schema relationships, and glossary for a dataset.\"\"\"\n",
        "    description: str\n",
        "    schema_relationship: List[SchemaRelationship] = Field(..., alias='schemaRelationship')\n",
        "    business_glossary: BusinessGlossary = Field(..., alias='businessGlossary')\n",
        "\n",
        "\n",
        "class KEResult(BaseModel):\n",
        "    \"\"\"The main result object from a KNOWLEDGE_ENGINE data scan.\"\"\"\n",
        "    dataset_result: DatasetResult = Field(..., alias='datasetResult')\n",
        "\n",
        "\n",
        "class KEScan(DataScan):\n",
        "    \"\"\"Represents a KNOWLEDGE_ENGINE data scan.\"\"\"\n",
        "    knowledge_engine_spec: Optional[KESpec] = Field(None, alias='knowledgeEngineSpec')\n",
        "    knowledge_engine_result: KEResult = Field(..., alias='knowledgeEngineResult')\n",
        "\n",
        "    @property\n",
        "    def dataset_description(self) -> str:\n",
        "        return self.knowledge_engine_result.dataset_result.description # shortcut\n",
        "\n",
        "    @property\n",
        "    def business_glossary(self) -> BusinessGlossary:\n",
        "        return self.knowledge_engine_result.dataset_result.business_glossary\n",
        "\n",
        "    @property\n",
        "    def schema_relationships(self) -> SchemaRelationship:\n",
        "        return self.knowledge_engine_result.dataset_result.schema_relationship\n",
        "\n",
        "\"\"\"\n",
        "  type DATA_DOCUMENTATION generic models\n",
        "\"\"\"\n",
        "\n",
        "class DDSpec(BaseModel):\n",
        "    \"\"\"Represents dataDocumentationSpec.\"\"\"\n",
        "    pass\n",
        "\n",
        "\n",
        "class Query(BaseModel):\n",
        "    \"\"\"Represents a single SQL query with its description.\"\"\"\n",
        "    sql: str\n",
        "    description: str\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "  type DATA_DOCUMENTATION table models\n",
        "\"\"\"\n",
        "class SchemaField(BaseModel):\n",
        "    \"\"\"Represents a single field (column) in a table schema.\"\"\"\n",
        "    name: str\n",
        "    description: str\n",
        "\n",
        "\n",
        "class Schema(BaseModel):\n",
        "    \"\"\"Represents the schema of a table, containing a list of fields.\"\"\"\n",
        "    fields: List[SchemaField]\n",
        "\n",
        "\n",
        "class TableResult(BaseModel):\n",
        "    \"\"\"Contains the detailed documentation results for a specific table.\"\"\"\n",
        "    overview: str\n",
        "    the_schema: Schema = Field(alias=\"schema\") # renamed to the_schema to preven collision\n",
        "    queries: List[Query]\n",
        "    query_theme: Optional[Dict[str, Any]] = Field(None, alias='queryTheme')\n",
        "\n",
        "\n",
        "class DDTableResult(BaseModel):\n",
        "    \"\"\"The main result object from a DATA_DOCUMENTATION table scan.\"\"\"\n",
        "    queries: List[Query]\n",
        "    overview: str\n",
        "    the_schema: Schema = Field(alias=\"schema\") # renamed to the_schema to preven collision\n",
        "    table_result: TableResult = Field(..., alias='tableResult')\n",
        "\n",
        "\n",
        "class DDTableScan(DataScan):\n",
        "    \"\"\"Represents a DATA_DOCUMENTATION data scan.\"\"\"\n",
        "    data_documentation_spec: Optional[DDSpec] = Field(None, alias='dataDocumentationSpec')\n",
        "    data_documentation_result: DDTableResult = Field(..., alias='dataDocumentationResult')\n",
        "\n",
        "    @property\n",
        "    def full_table_name(self) -> str:\n",
        "        parts = self.data.resource.split('/')\n",
        "        return f\"{parts[4]}.{parts[6]}.{parts[8]}\"\n",
        "\n",
        "    @property\n",
        "    def overview(self) -> str:\n",
        "        return self.data_documentation_result.table_result.overview # shortcut\n",
        "\n",
        "    @property\n",
        "    def fields(self) -> List[SchemaField]:\n",
        "        return self.data_documentation_result.table_result.the_schema.fields\n",
        "\n",
        "    @property\n",
        "    def queries(self) -> List[Query]:\n",
        "        return self.data_documentation_result.table_result.queries\n",
        "\n",
        "\"\"\"\n",
        "  type DATA_DOCUMENTATION dataset models\n",
        "\"\"\"\n",
        "class DDDatasetResult(BaseModel):\n",
        "    queries: List[Query]\n",
        "\n",
        "class DDDataDocumentationResult(BaseModel):\n",
        "    \"\"\"The main result object from a DATA_DOCUMENTATION dataset scan.\"\"\"\n",
        "    queries: List[Query]\n",
        "    dataset_result: DDDatasetResult = Field(..., alias='datasetResult')\n",
        "\n",
        "\n",
        "class DDDatasetScan(DataScan):\n",
        "    \"\"\"Represents a DATA_DOCUMENTATION dataset scan.\"\"\"\n",
        "    data_documentation_spec: Optional[DDSpec] = Field(None, alias='dataDocumentationSpec')\n",
        "    data_documentation_result: DDDataDocumentationResult = Field(..., alias='dataDocumentationResult')\n",
        "\n",
        "    @property\n",
        "    def queries(self) -> List[Query]:\n",
        "        return self.data_documentation_result.dataset_result.queries\n",
        "\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## KEDataScanHelper"
      ],
      "metadata": {
        "id": "7XkLvlYw32Jm"
      },
      "id": "7XkLvlYw32Jm"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classes for output from KEDatasetScanHelper"
      ],
      "metadata": {
        "id": "FXRDs6xH4LOZ"
      },
      "id": "FXRDs6xH4LOZ"
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "  ------------------------------------------\n",
        "  Classes for output from KEDatasetScanHelper\n",
        "  ------------------------------------------\n",
        "\"\"\"\n",
        "import json\n",
        "\n",
        "class KEDatasetTable(BaseModel):\n",
        "    \"\"\"\n",
        "    Represents a single table.\n",
        "    \"\"\"\n",
        "    name: str\n",
        "    overview: Optional[str] = None\n",
        "    fields: List[SchemaField] = Field(..., description=\"A list of fields in the table.\")\n",
        "    queries: List[Query] = Field(..., description=\"A list of queries that can be run against the table.\")\n",
        "    ddl: Optional[str] = None\n",
        "    row_count: Optional[int] = None\n",
        "    size_bytes: Optional[int] = None\n",
        "\n",
        "    @property\n",
        "    def fields_json(self) -> str:\n",
        "        full_model = self.model_dump()\n",
        "        return json.dumps(full_model['fields'])\n",
        "\n",
        "    @property\n",
        "    def queries_json(self) -> str:\n",
        "        full_model = self.model_dump()\n",
        "        return json.dumps(full_model['queries'])\n",
        "\n",
        "    @property\n",
        "    def text_field_descriptions(self) -> str:\n",
        "        field_descriptions = '```\\n'\n",
        "        for field in self.fields:\n",
        "            field_descriptions += f\"`{field.name}` -- Definition: {field.description}\\n\"\n",
        "\n",
        "        field_descriptions += '```'\n",
        "\n",
        "        return field_descriptions\n",
        "\n",
        "\n",
        "class KEDatasetRelationship(BaseModel):\n",
        "    \"\"\"\n",
        "    Represents a single relationship between two database tables.\n",
        "    \"\"\"\n",
        "    table1: str = Field(..., description=\"The name of the first table in the relationship.\")\n",
        "    table2: str = Field(..., description=\"The name of the second table in the relationship.\")\n",
        "    relationship: str = Field(..., description=\"The join condition that defines the relationship.\")\n",
        "    source: str = Field(..., description=\"The source that inferred or defined this relationship.\")\n",
        "\n",
        "class KEDatasetDetails(BaseModel):\n",
        "    \"\"\"\n",
        "    Represents the detailed documentation results for a specific dataset.\n",
        "    \"\"\"\n",
        "    project_id: str = Field(..., description=\"Project ID of the dataset.\")\n",
        "    dataset_name: str = Field(..., description=\"Name of the dataset\")\n",
        "    dataset_location: str = Field(..., description=\"Location of the dataset.\")\n",
        "    dataset_description: str = Field(..., description=\"A brief overview of the dataset.\")\n",
        "    dataset_relationships: List[KEDatasetRelationship] = Field(..., description=\"A list of table relationships.\")\n",
        "    dataset_queries: List[Query] = Field(..., description=\"A list of queries that can be run against the dataset.\")\n",
        "    dataset_business_glossary: List[BusinessTerm] = Field(..., description=\"A list of business glossary terms.\")\n",
        "    dataset_tables: List[KEDatasetTable] = Field(..., description=\"A list of tables in the dataset.\")\n",
        "\n",
        "    @property\n",
        "    def dataset_relationships_json(self) -> str:\n",
        "        full_model = self.model_dump()\n",
        "        return json.dumps(full_model['dataset_relationships'])\n",
        "\n",
        "    @property\n",
        "    def dataset_queries_json(self) -> str:\n",
        "        full_model = self.model_dump()\n",
        "        return json.dumps(full_model['dataset_queries'])\n",
        "\n",
        "    @property\n",
        "    def dataset_glossary_terms_json(self) -> str:\n",
        "        full_model = self.model_dump()\n",
        "        return json.dumps(full_model['dataset_business_glossary'])\n",
        "\n",
        "    @property\n",
        "    def text_table_ddls(self) -> str:\n",
        "        table_ddls = '```\\n'\n",
        "        for table in self.dataset_tables:\n",
        "            table_ddls += f\"Table: {table.name}\\n\"\n",
        "            table_ddls += f\"DDL: {table.ddl}\\n\"\n",
        "\n",
        "        table_ddls += '```'\n",
        "        return table_ddls"
      ],
      "metadata": {
        "id": "97z7Mi2O4HGt"
      },
      "id": "97z7Mi2O4HGt",
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper Authentication"
      ],
      "metadata": {
        "id": "yEx3D6513_kN"
      },
      "id": "yEx3D6513_kN"
    },
    {
      "cell_type": "code",
      "source": [
        "import requests, re\n",
        "\n",
        "from google.cloud import bigquery\n",
        "from google.auth.transport.requests import Request\n",
        "from google.oauth2.credentials import Credentials\n",
        "import google.auth\n",
        "\n",
        "class APIRequestError(Exception): pass\n",
        "class AuthenticationError(APIRequestError): pass\n",
        "\n",
        "class KEAuth:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.__credentials = None\n",
        "        self.__project = None\n",
        "\n",
        "    def _get_credentials(self) -> Credentials:\n",
        "            if self.__credentials is None:\n",
        "                self.__credentials, self.__project = google.auth.default()\n",
        "\n",
        "            if not self.__credentials.valid:\n",
        "                try:\n",
        "                    self.__credentials.refresh(Request())\n",
        "                except Exception as e:\n",
        "                    raise AuthenticationError(f\"Failed to refresh Google credentials: {e}\") from e\n",
        "\n",
        "            return self.__credentials\n",
        "\n",
        "    def _get_headers(self) -> dict:\n",
        "        credentials = self._get_credentials()\n",
        "        return {\n",
        "          \"Authorization\": f\"Bearer {credentials.token}\",\n",
        "          \"Content-Type\": \"application/json\"\n",
        "        }\n",
        "\n",
        "    def get_url_content(self, url: str) -> str:\n",
        "            headers = self._get_headers()\n",
        "            try:\n",
        "                response = requests.get(url, headers=headers)\n",
        "                response.raise_for_status() # Raises for 4xx or 5xx status codes\n",
        "                return response.text\n",
        "\n",
        "            except requests.exceptions.HTTPError as e:\n",
        "                if e.response.status_code in (401, 403):\n",
        "                    raise AuthenticationError(\n",
        "                        f\"Access Denied (HTTP {e.response.status_code}) fetching {url}. \"\n",
        "                        \"Ensure your service account has the necessary IAM roles.\"\n",
        "                    ) from e\n",
        "\n",
        "                raise APIRequestError(f\"HTTP Error {e.response.status_code} fetching {url}: {e.response.text}\") from e\n",
        "\n",
        "            except requests.exceptions.RequestException as e:\n",
        "                raise APIRequestError(f\"Network error fetching {url}: {e}\") from e"
      ],
      "metadata": {
        "id": "dKQf3WhXsImh"
      },
      "id": "dKQf3WhXsImh",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### KEDatasetScanHelper"
      ],
      "metadata": {
        "id": "5CXXETf94TbW"
      },
      "id": "5CXXETf94TbW"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"\n",
        "  ------------------------------------------\n",
        "  KEDatasetScanHelper\n",
        "  ------------------------------------------\n",
        "\"\"\"\n",
        "\n",
        "class KEDatasetScanHelper(KEAuth):\n",
        "    \"\"\"A helper for interacting with the Knowledge Engine API.\"\"\"\n",
        "    DATAPLEX_BASE_URL = \"https://dataplex.googleapis.com/v1\"\n",
        "    DATAPLEX_LIST_SCANS_URL = DATAPLEX_BASE_URL + \"/projects/{project_id}/locations/{location}/dataScans\"\n",
        "\n",
        "    def __init__(self, project_id: str, dataset_name: str):\n",
        "        super().__init__()\n",
        "        self.dataset_name = dataset_name\n",
        "        self.project_id = project_id\n",
        "        self.__dataset_location = None\n",
        "        self.__tables = []\n",
        "        self.__data_scans = []\n",
        "        self.__allowlist_tables = set()\n",
        "        self.__blocklist_tables = set()\n",
        "        self.__with_ddls = False\n",
        "        self.__ddls = {}\n",
        "        self.__with_table_counts = False\n",
        "        self.__table_counts = {}\n",
        "\n",
        "    def _flush(self):\n",
        "        self.__tables.clear()\n",
        "        self.__data_scans.clear()\n",
        "        self.__ddls.clear()\n",
        "\n",
        "    def _table_is_allowed(self, table_resource_fqn: str) -> bool:\n",
        "        \"\"\"\n",
        "        Check if a table is allowed based on the allowlist and blocklist.\n",
        "        The table resource FQN is in the format:\n",
        "        //bigquery.googleapis.com/projects/{project_id}/datasets/{dataset_name}/tables/{table_name}\n",
        "        \"\"\"\n",
        "        short_table_name = table_resource_fqn.split('/')[-1]\n",
        "\n",
        "        return (\n",
        "            self._is_in_allowlist(short_table_name) and not\n",
        "            self._is_in_blocklist(short_table_name)\n",
        "        )\n",
        "\n",
        "    def _is_in_allowlist(self, short_table_name: str) -> bool:\n",
        "        if not self.__allowlist_tables:\n",
        "            return True\n",
        "\n",
        "        return short_table_name in self.__allowlist_tables\n",
        "\n",
        "    def _is_in_blocklist(self, short_table_name: str) -> bool:\n",
        "        if not self.__blocklist_tables:\n",
        "            return False\n",
        "\n",
        "        return short_table_name in self.__blocklist_tables\n",
        "\n",
        "    def _get_scans_of_interest(self) -> list:\n",
        "        scan_url = self.DATAPLEX_LIST_SCANS_URL.format(\n",
        "            base_url=self.DATAPLEX_BASE_URL,\n",
        "            project_id=self.project_id,\n",
        "            location=self.dataset_location\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            response = self.get_url_content(scan_url)\n",
        "        except Exception as e:\n",
        "            print(f\"Error fetching data scans: {e}\")\n",
        "            raise e\n",
        "\n",
        "        try:\n",
        "            scans = json.loads(response)\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"Error decoding JSON response: {e}\")\n",
        "            raise e\n",
        "\n",
        "        # Limit the scans to items in the requested dataset (per constructor)\n",
        "        ds_test_string = f\"/datasets/{self.dataset_name}\"\n",
        "        table_test_string = f\"{ds_test_string}/tables/\"\n",
        "\n",
        "        scans_of_interest = []\n",
        "        for scan in scans.get('dataScans', []):\n",
        "            if scan.get('data') and scan.get('data').get('resource'):\n",
        "                resource = scan.get('data').get('resource')\n",
        "\n",
        "                if resource.endswith(ds_test_string) or table_test_string in resource:\n",
        "\n",
        "                    try:\n",
        "                      new_scan = DataScan(**scan)\n",
        "                    except ValidationError as e:\n",
        "                      print(f\"Error creating DataScan object for {json.dumps(scan, indent=2)}:\\n {e}\")\n",
        "                      raise e\n",
        "\n",
        "                    if new_scan.is_for_table:\n",
        "                        if self._table_is_allowed(new_scan.resource_name):\n",
        "                            scans_of_interest.append(new_scan)\n",
        "\n",
        "                    if new_scan.is_for_dataset:\n",
        "                        scans_of_interest.append(new_scan)\n",
        "\n",
        "        return scans_of_interest\n",
        "\n",
        "\n",
        "    def with_table_list_constraints(self, allowlist: list = [], blocklist: list = []):\n",
        "        \"\"\" configuration option \"\"\"\n",
        "        overlap = list(set(allowlist).intersection(set(blocklist)))\n",
        "        if overlap:\n",
        "            raise ValueError(f\"Allowlist and blocklist cannot contain the same items: {overlap}\")\n",
        "\n",
        "        self._flush()\n",
        "        self.__allowlist_tables.clear()\n",
        "        self.__blocklist_tables.clear()\n",
        "        self.__allowlist_tables.update(allowlist)\n",
        "        self.__blocklist_tables.update(blocklist)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def with_table_ddls(self, with_ddls=True):\n",
        "        \"\"\" configuration option \"\"\"\n",
        "        self.__with_ddls = with_ddls\n",
        "        self._flush()\n",
        "\n",
        "        return self\n",
        "\n",
        "    def with_table_counts(self, with_table_counts=True):\n",
        "        \"\"\" configuration option \"\"\"\n",
        "        self.__with_table_counts = with_table_counts\n",
        "        self._flush()\n",
        "\n",
        "        return self\n",
        "\n",
        "    @property\n",
        "    def table_counts(self) -> dict:\n",
        "        \"\"\" gets all the table counts for the dataset - row count, size_bytes\"\"\"\n",
        "        if not self.__table_counts:\n",
        "            client = bigquery.Client(project=self.project_id)\n",
        "            query = f\"\"\"\n",
        "                SELECT\n",
        "                    CONCAT(project_id,'.',dataset_id,'.',table_id) AS fq_table_name\n",
        "                , row_count\n",
        "                , size_bytes\n",
        "                FROM `{self.project_id}.{self.dataset_name}.__TABLES__`\n",
        "            \"\"\"\n",
        "            query_job = client.query(query)\n",
        "            results = query_job.result()\n",
        "\n",
        "            for row in results:\n",
        "                self.__table_counts[row.fq_table_name] = {\n",
        "                    \"row_count\": row.row_count,\n",
        "                    \"size_bytes\": row.size_bytes\n",
        "                }\n",
        "\n",
        "        return self.__table_counts\n",
        "\n",
        "    @property\n",
        "    def table_ddls(self) -> dict:\n",
        "        \"\"\" gets all the table DDLs for the dataset \"\"\"\n",
        "        if not self.__ddls:\n",
        "          client = bigquery.Client(project=self.project_id)\n",
        "          query = f\"\"\"\n",
        "              SELECT\n",
        "                  CONCAT(\n",
        "                      table_catalog,'.',table_schema,'.',table_name) AS fq_table_name,\n",
        "                  ddl\n",
        "              FROM `{self.project_id}.{self.dataset_name}.INFORMATION_SCHEMA.TABLES`\n",
        "          \"\"\"\n",
        "          query_job = client.query(query)\n",
        "          results = query_job.result()\n",
        "\n",
        "          for row in results:\n",
        "              self.__ddls[row.fq_table_name] = row.ddl\n",
        "\n",
        "        return self.__ddls\n",
        "\n",
        "    @property\n",
        "    def dataset_location(self) -> str:\n",
        "        if not self.__dataset_location:\n",
        "            client = bigquery.Client()\n",
        "            dataset = client.get_dataset(f'{self.project_id}.{self.dataset_name}')\n",
        "            self.__dataset_location = dataset.location\n",
        "\n",
        "        return self.__dataset_location\n",
        "\n",
        "    @property\n",
        "    def dataplex_scans(self) -> list:\n",
        "        if not self.__data_scans:\n",
        "            scans = self._get_scans_of_interest()\n",
        "\n",
        "            for scan in scans:\n",
        "                full_scan_url = f\"{self.DATAPLEX_BASE_URL}/{scan.name}?view=FULL\"\n",
        "\n",
        "                try:\n",
        "                    response = self.get_url_content(full_scan_url)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error fetching data scans: {e}\")\n",
        "                    raise e\n",
        "\n",
        "                try:\n",
        "                    full_view_scan = json.loads(response)\n",
        "                except json.JSONDecodeError as e:\n",
        "                    print(f\"Error decoding JSON response: {e}\")\n",
        "                    raise e\n",
        "\n",
        "                new_scan = None\n",
        "\n",
        "                if scan.type == ScanTypeValue.KNOWLEDGE_ENGINE:\n",
        "                    new_scan = KEScan(**full_view_scan)\n",
        "\n",
        "                if scan.type == ScanTypeValue.DATA_DOCUMENTATION:\n",
        "                    if scan.is_for_table:\n",
        "                        new_scan = DDTableScan(**full_view_scan)\n",
        "\n",
        "                    if scan.is_for_dataset:\n",
        "                        new_scan = DDDatasetScan(**full_view_scan)\n",
        "\n",
        "                if new_scan:\n",
        "                  self.__data_scans.append(new_scan)\n",
        "\n",
        "        return self.__data_scans\n",
        "\n",
        "    @property # dataset knowledge engine scan, loop locally\n",
        "    def dataset_ke_scan(self) -> KEScan:\n",
        "        for scan in self.dataplex_scans:\n",
        "            if isinstance(scan, KEScan):\n",
        "                return scan\n",
        "\n",
        "    @property # dataset data documentation scan, loop locally\n",
        "    def dataset_dd_scan(self) -> DDDatasetScan:\n",
        "        for scan in self.dataplex_scans:\n",
        "            if isinstance(scan, DDDatasetScan):\n",
        "                return scan\n",
        "\n",
        "    @property\n",
        "    def dataset_description(self) -> str:\n",
        "        return self.dataset_ke_scan.dataset_description\n",
        "\n",
        "    @property\n",
        "    def dataset_tables(self) -> List[KEDatasetTable]:\n",
        "        tables = []\n",
        "        for scan in self.dataplex_scans:\n",
        "            if isinstance(scan, DDTableScan):\n",
        "                if self._table_is_allowed(scan.resource_name):\n",
        "\n",
        "                    ddl = None\n",
        "                    if self.__with_ddls:\n",
        "                        ddl = self.table_ddls.get(scan.full_table_name, None)\n",
        "\n",
        "                    row_count = None\n",
        "                    size_bytes = None\n",
        "                    if self.__with_table_counts:\n",
        "                        table_counts = self.table_counts.get(scan.full_table_name, None)\n",
        "                        row_count = table_counts.get(\"row_count\") if table_counts else None\n",
        "                        size_bytes = table_counts.get(\"size_bytes\") if table_counts else None\n",
        "\n",
        "                    tables.append(KEDatasetTable(**{\n",
        "                        \"name\": scan.full_table_name,\n",
        "                        \"overview\": scan.overview,\n",
        "                        \"fields\": scan.fields,\n",
        "                        \"queries\": scan.queries,\n",
        "                        \"ddl\": ddl,\n",
        "                        \"row_count\": row_count,\n",
        "                        \"size_bytes\": size_bytes,\n",
        "                    }))\n",
        "\n",
        "        return tables\n",
        "\n",
        "    @property\n",
        "    def dataset_queries(self) -> List[Query]:\n",
        "        return self.dataset_dd_scan.queries\n",
        "\n",
        "    @property\n",
        "    def dataset_business_glossary(self) -> List[BusinessTerm]:\n",
        "        return self.dataset_ke_scan.business_glossary.terms\n",
        "\n",
        "    @property\n",
        "    def dataset_relationships(self) -> List[KEDatasetRelationship]:\n",
        "        \"\"\"\n",
        "          This will require update when the relation representation becomes more complex.\n",
        "          Currently should handle multple anded = conditions between left and right side.\n",
        "        \"\"\"\n",
        "        project_dataset = self.project_id + '.' + self.dataset_name\n",
        "\n",
        "        return_relationships = []\n",
        "\n",
        "        relationships = self.dataset_ke_scan.schema_relationships\n",
        "        for relationship in relationships:\n",
        "\n",
        "          left_tuples = relationship.left_columns_tuple\n",
        "          table1_fqn = left_tuples[0].entry_fqn\n",
        "          table1_sql_name = f\"{project_dataset}.{table1_fqn.split('/')[-1]}\"\n",
        "          if not self._table_is_allowed(table1_fqn):\n",
        "              continue\n",
        "\n",
        "          right_tuples = relationship.right_columns_tuple\n",
        "          table2_fqn = right_tuples[0].entry_fqn\n",
        "          table2_sql_name = f\"{project_dataset}.{table2_fqn.split('/')[-1]}\"\n",
        "          if not self._table_is_allowed(table2_fqn):\n",
        "              continue\n",
        "\n",
        "          join_conditions = []\n",
        "\n",
        "          for i, left_item in enumerate(left_tuples):\n",
        "              right_item = right_tuples[i]\n",
        "              new_join_condition = table1_sql_name + '.' + left_item.field_path\n",
        "              new_join_condition += ' = '\n",
        "              new_join_condition += table2_sql_name + '.' + right_item.field_path\n",
        "              join_conditions.append(new_join_condition)\n",
        "\n",
        "          return_relationships.append(KEDatasetRelationship(**{\n",
        "              'table1': table1_sql_name,\n",
        "              'table2': table2_sql_name,\n",
        "              'relationship': ' AND '.join(join_conditions),\n",
        "              'source': 'LLM-inferred'\n",
        "          }))\n",
        "\n",
        "        return return_relationships\n",
        "\n",
        "    @property\n",
        "    def dataset_all_details(self) -> KEDatasetDetails:\n",
        "        return KEDatasetDetails(**{\n",
        "            \"project_id\": self.project_id,\n",
        "            \"dataset_name\": self.dataset_name,\n",
        "            \"dataset_location\": self.dataset_location,\n",
        "            \"dataset_description\": self.dataset_description,\n",
        "            \"dataset_relationships\": self.dataset_relationships,\n",
        "            \"dataset_queries\": self.dataset_queries,\n",
        "            \"dataset_business_glossary\": self.dataset_business_glossary,\n",
        "            \"dataset_tables\": self.dataset_tables\n",
        "        })"
      ],
      "metadata": {
        "id": "fMPFc7oU3pYD"
      },
      "id": "fMPFc7oU3pYD",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper Testing"
      ],
      "metadata": {
        "id": "H9LdVURn4kTB"
      },
      "id": "H9LdVURn4kTB"
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_ID = 'ai-learning-agents'\n",
        "DATASET_NAME = 'thelook'\n",
        "RESULTS_BUCKET = 'dataset_metadata_results'\n",
        "\n",
        "ke_helper = KEDatasetScanHelper(PROJECT_ID, DATASET_NAME)\n",
        "ke_helper.with_table_list_constraints(allowlist=[], blocklist=['sales'])\n",
        "ke_helper.with_table_ddls()\n",
        "ke_helper.with_table_counts()\n",
        "ds_details = ke_helper.dataset_all_details\n",
        "\n",
        "json_string = ds_details.model_dump_json()\n",
        "print(json_string)"
      ],
      "metadata": {
        "id": "qkifYnFa4oTo"
      },
      "id": "qkifYnFa4oTo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example Display with Mercury, change the\n",
        "app = mr.App(title=\"Display notebook\", static_notebook=True)\n",
        "mr.JSON(json_string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "lNCl9shHX6I5",
        "outputId": "176f5199-16c0-4ee0-afbd-6c3a3aa03a16"
      },
      "id": "lNCl9shHX6I5",
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "mercury.App"
            ],
            "text/html": [
              "<h3>Mercury Application</h3><small>This output won't appear in the web app.</small>"
            ],
            "application/mercury+json": "{\n    \"widget\": \"App\",\n    \"title\": \"Display notebook\",\n    \"description\": \"Description\",\n    \"show_code\": false,\n    \"show_prompt\": false,\n    \"output\": \"app\",\n    \"schedule\": \"\",\n    \"notify\": \"{}\",\n    \"continuous_update\": true,\n    \"static_notebook\": true,\n    \"show_sidebar\": true,\n    \"full_screen\": true,\n    \"allow_download\": true,\n    \"allow_share\": true,\n    \"stop_on_error\": false,\n    \"model_id\": \"mercury-app\",\n    \"code_uid\": \"App.0.50.110.2-rand143c0392\"\n}"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>.renderjson a              { text-decoration: none; }\n",
              ".renderjson .disclosure    { color: grey; font-size: 125%; }\n",
              ".renderjson .syntax        { color: grey; }\n",
              ".renderjson .string        { color: #fe46a5; }\n",
              ".renderjson .number        { color: #0f9b8e; }\n",
              ".renderjson .boolean       { color: black; }\n",
              ".renderjson .key           { color: #2684ff; }\n",
              ".renderjson .keyword       { color: gray; }\n",
              ".renderjson .object.syntax { color: gray; }\n",
              ".renderjson .array.syntax  { color: gray; }</style><div id=\"87eecf38-18d9-4b2f-bee1-348113c3c26d\"></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<script>var renderjson=function(){var t=function(){for(var t=[];arguments.length;)t.push(n(s(Array.prototype.shift.call(arguments)),o(Array.prototype.shift.call(arguments))));return t},n=function(){for(var t=Array.prototype.shift.call(arguments),e=0;e<arguments.length;e++)arguments[e].constructor==Array?n.apply(this,[t].concat(arguments[e])):t.appendChild(arguments[e]);return t},e=function(t,n){return t.insertBefore(n,t.firstChild),t},r=function(t,n){var e=n||Object.keys(t);for(var r in e)if(Object.hasOwnProperty.call(t,e[r]))return!1;return!0},o=function(t){return document.createTextNode(t)},s=function(t){var n=document.createElement(\"span\");return t&&(n.className=t),n},l=function(t,n,e){var r=document.createElement(\"a\");return n&&(r.className=n),r.appendChild(o(t)),r.href=\"#\",r.onclick=function(t){return e(),t&&t.stopPropagation(),!1},r};function a(i,c,u,p,y){var _=u?\"\":c,f=function(r,a,i,c,u){var f,g=s(c),h=function(){f||n(g.parentNode,f=e(u(),l(y.hide,\"disclosure\",(function(){f.style.display=\"none\",g.style.display=\"inline\"})))),f.style.display=\"inline\",g.style.display=\"none\"};n(g,l(y.show,\"disclosure\",h),t(c+\" syntax\",r),l(a,null,h),t(c+\" syntax\",i));var d=n(s(),o(_.slice(0,-1)),g);return p>0&&\"string\"!=c&&h(),d};return null===i?t(null,_,\"keyword\",\"null\"):void 0===i?t(null,_,\"keyword\",\"undefined\"):\"string\"==typeof i&&i.length>y.max_string_length?f('\"',i.substr(0,y.max_string_length)+\" ...\",'\"',\"string\",(function(){return n(s(\"string\"),t(null,_,\"string\",JSON.stringify(i)))})):\"object\"!=typeof i||[Number,String,Boolean,Date].indexOf(i.constructor)>=0?t(null,_,typeof i,JSON.stringify(i)):i.constructor==Array?0==i.length?t(null,_,\"array syntax\",\"[]\"):f(\"[\",y.collapse_msg(i.length),\"]\",\"array\",(function(){for(var e=n(s(\"array\"),t(\"array syntax\",\"[\",null,\"\\n\")),r=0;r<i.length;r++)n(e,a(y.replacer.call(i,r,i[r]),c+\"    \",!1,p-1,y),r!=i.length-1?t(\"syntax\",\",\"):[],o(\"\\n\"));return n(e,t(null,c,\"array syntax\",\"]\")),e})):r(i,y.property_list)?t(null,_,\"object syntax\",\"{}\"):f(\"{\",y.collapse_msg(Object.keys(i).length),\"}\",\"object\",(function(){var e=n(s(\"object\"),t(\"object syntax\",\"{\",null,\"\\n\"));for(var r in i)var l=r;var u=y.property_list||Object.keys(i);for(var _ in y.sort_objects&&(u=u.sort()),u){(r=u[_])in i&&n(e,t(null,c+\"    \",\"key\",'\"'+r+'\"',\"object syntax\",\": \"),a(y.replacer.call(i,r,i[r]),c+\"    \",!0,p-1,y),r!=l?t(\"syntax\",\",\"):[],o(\"\\n\"))}return n(e,t(null,c,\"object syntax\",\"}\")),e}))}var i=function t(e){var r=new Object(t.options);r.replacer=\"function\"==typeof r.replacer?r.replacer:function(t,n){return n};var o=n(document.createElement(\"pre\"),a(e,\"\",!1,r.show_to_level,r));return o.className=\"renderjson\",o};return i.set_icons=function(t,n){return i.options.show=t,i.options.hide=n,i},i.set_show_to_level=function(t){return i.options.show_to_level=\"string\"==typeof t&&\"all\"===t.toLowerCase()?Number.MAX_VALUE:t,i},i.set_max_string_length=function(t){return i.options.max_string_length=\"string\"==typeof t&&\"none\"===t.toLowerCase()?Number.MAX_VALUE:t,i},i.set_sort_objects=function(t){return i.options.sort_objects=t,i},i.set_replacer=function(t){return i.options.replacer=t,i},i.set_collapse_msg=function(t){return i.options.collapse_msg=t,i},i.set_property_list=function(t){return i.options.property_list=t,i},i.set_show_by_default=function(t){return i.options.show_to_level=t?Number.MAX_VALUE:0,i},i.options={},i.set_icons(\"⊕\",\"⊖\"),i.set_show_by_default(!1),i.set_sort_objects(!1),i.set_max_string_length(\"none\"),i.set_replacer(void 0),i.set_property_list(void 0),i.set_collapse_msg((function(t){return t+\" item\"+(1==t?\"\":\"s\")})),i}(); renderjson.set_show_to_level(1); document.getElementById(\"87eecf38-18d9-4b2f-bee1-348113c3c26d\").appendChild(renderjson({\"project_id\":\"ai-learning-agents\",\"dataset_name\":\"thelook\",\"dataset_location\":\"us-central1\",\"dataset_description\":\"This dataset contains comprehensive information about e-commerce operations, encompassing user behavior, product details, order management, and inventory tracking. It provides a detailed view of customer interactions on the website, including browsing activity and order placements. The dataset includes granular information about products, such as pricing, category, and distribution center location. Order details are recorded, capturing the full lifecycle from creation to delivery and returns. Inventory levels and sales transactions are also tracked, allowing for analysis of product performance and supply chain efficiency. This data enables in-depth analysis of sales trends, user demographics, and operational effectiveness.\",\"dataset_relationships\":[{\"table1\":\"ai-learning-agents.thelook.order_items\",\"table2\":\"ai-learning-agents.thelook.orders\",\"relationship\":\"ai-learning-agents.thelook.order_items.order_id = ai-learning-agents.thelook.orders.order_id\",\"source\":\"LLM-inferred\"},{\"table1\":\"ai-learning-agents.thelook.inventory_items\",\"table2\":\"ai-learning-agents.thelook.distribution_centers\",\"relationship\":\"ai-learning-agents.thelook.inventory_items.product_distribution_center_id = ai-learning-agents.thelook.distribution_centers.id\",\"source\":\"LLM-inferred\"},{\"table1\":\"ai-learning-agents.thelook.order_items\",\"table2\":\"ai-learning-agents.thelook.inventory_items\",\"relationship\":\"ai-learning-agents.thelook.order_items.inventory_item_id = ai-learning-agents.thelook.inventory_items.id\",\"source\":\"LLM-inferred\"},{\"table1\":\"ai-learning-agents.thelook.order_items\",\"table2\":\"ai-learning-agents.thelook.products\",\"relationship\":\"ai-learning-agents.thelook.order_items.product_id = ai-learning-agents.thelook.products.id\",\"source\":\"LLM-inferred\"},{\"table1\":\"ai-learning-agents.thelook.orders\",\"table2\":\"ai-learning-agents.thelook.users\",\"relationship\":\"ai-learning-agents.thelook.orders.user_id = ai-learning-agents.thelook.users.id\",\"source\":\"LLM-inferred\"},{\"table1\":\"ai-learning-agents.thelook.order_items\",\"table2\":\"ai-learning-agents.thelook.users\",\"relationship\":\"ai-learning-agents.thelook.order_items.user_id = ai-learning-agents.thelook.users.id\",\"source\":\"LLM-inferred\"},{\"table1\":\"ai-learning-agents.thelook.inventory_items\",\"table2\":\"ai-learning-agents.thelook.products\",\"relationship\":\"ai-learning-agents.thelook.inventory_items.product_id = ai-learning-agents.thelook.products.id\",\"source\":\"LLM-inferred\"},{\"table1\":\"ai-learning-agents.thelook.distribution_centers\",\"table2\":\"ai-learning-agents.thelook.products\",\"relationship\":\"ai-learning-agents.thelook.distribution_centers.id = ai-learning-agents.thelook.products.distribution_center_id\",\"source\":\"LLM-inferred\"},{\"table1\":\"ai-learning-agents.thelook.events\",\"table2\":\"ai-learning-agents.thelook.users\",\"relationship\":\"ai-learning-agents.thelook.events.user_id = ai-learning-agents.thelook.users.id\",\"source\":\"LLM-inferred\"}],\"dataset_queries\":[{\"sql\":\"SELECT\\n    CORR(u.age, o.num_of_item) AS age_order_item_correlation\\n  FROM\\n    `thelook.users` AS u\\n  JOIN\\n    `thelook.orders` AS o\\n  ON\\n    u.id = o.user_id;\",\"description\":\"Calculate the correlation between user age and the number of items in their orders to understand if older users tend to order more items.\"},{\"sql\":\"SELECT\\n    u.traffic_source,\\n    AVG(oi.sale_price) AS average_order_value\\n  FROM\\n    `thelook.users` AS u\\n  JOIN\\n    `thelook.order_items` AS oi\\n  ON\\n    u.id = oi.user_id\\n  GROUP BY\\n    u.traffic_source;\",\"description\":\"Determine the average order value (AOV) for orders placed by users from different traffic sources.\"},{\"sql\":\"SELECT\\n    dc.name,\\n    AVG(ii.cost) AS avg_inventory_cost\\n  FROM\\n    `thelook.inventory_items` AS ii\\n  JOIN\\n    `thelook.distribution_centers` AS dc\\n  ON\\n    ii.product_distribution_center_id = dc.id\\n  GROUP BY\\n    dc.name\\nORDER BY\\n  avg_inventory_cost DESC;\",\"description\":\"Find the distribution centers with the highest average cost of inventory items to identify potentially expensive storage locations.\"},{\"sql\":\"SELECT\\n    u.state,\\n    AVG(TIMESTAMP_DIFF(o.delivered_at, o.created_at, DAY)) AS avg_delivery_time\\n  FROM\\n    `thelook.orders` AS o\\n  JOIN\\n    `thelook.users` AS u\\n  ON\\n    o.user_id = u.id\\n  WHERE o.delivered_at IS NOT NULL\\n  GROUP BY\\n    u.state;\",\"description\":\"Calculate the average time between order creation and delivery for each state to identify potential shipping delays.\"},{\"sql\":\"SELECT\\n    ii.product_brand,\\n    SUM(oi.sale_price) AS total_returned_sales\\n  FROM\\n    `thelook.order_items` AS oi\\n  JOIN\\n    `thelook.inventory_items` AS ii\\n  ON\\n    oi.inventory_item_id = ii.id\\n  WHERE\\n    oi.status = 'Returned'\\n  GROUP BY\\n    ii.product_brand\\nORDER BY\\n  total_returned_sales DESC;\",\"description\":\"Find the product brands with the highest total sale price of returned items to identify potential quality issues.\"},{\"sql\":\"SELECT\\n    AVG(days_to_order) AS avg_days_to_order\\n  FROM (\\n    SELECT\\n        u.id AS user_id,\\n        MIN(DATE_DIFF(DATE(o.created_at), DATE(u.created_at), DAY)) AS days_to_order\\n      FROM\\n        `thelook.users` AS u\\n      JOIN\\n        `thelook.orders` AS o\\n      ON\\n        u.id = o.user_id\\n      GROUP BY\\n        u.id\\n  );\",\"description\":\"Determine the average number of days between user creation and their first order to understand user activation time.\"},{\"sql\":\"SELECT\\n    CORR(t1.age, t2.num_of_item) AS age_num_items_correlation\\n  FROM\\n    `thelook.users` AS t1\\n  JOIN\\n    `thelook.orders` AS t2\\n  ON t1.id = t2.user_id;\",\"description\":\"Calculate the correlation between user age and the number of items in their orders.\"},{\"sql\":\"SELECT\\n    e.traffic_source,\\n    AVG(oi.sale_price) AS average_order_value\\n  FROM\\n    `thelook.events` e\\n  JOIN\\n    `thelook.order_items` oi ON e.user_id = oi.user_id\\n  GROUP BY\\n    e.traffic_source;\",\"description\":\"Identify the average order value (AOV) for orders originating from different traffic sources.\"},{\"sql\":\"SELECT\\n    t1.gender,\\n    t2.status,\\n    COUNT(*) AS order_count\\n  FROM\\n    `thelook.users` AS t1\\n  JOIN\\n    `thelook.orders` AS t2\\n  ON t1.id = t2.user_id\\n  GROUP BY\\n    t1.gender,\\n    t2.status;\",\"description\":\"Determine the distribution of order statuses across different user genders.\"},{\"sql\":\"SELECT\\n    p.department,\\n    SUM(ii.cost * ii.id) / SUM(ii.id) AS weighted_avg_cost\\n  FROM\\n    `thelook.products` p\\n  JOIN\\n    `thelook.inventory_items` ii ON p.id = ii.product_id\\n  GROUP BY\\n    p.department;\",\"description\":\"Find the average cost of products in each department, weighted by the number of inventory items for each product.\"},{\"sql\":\"SELECT\\n    ii.product_brand,\\n    AVG(oi.sale_price) AS avg_sale_price\\n  FROM\\n    `thelook.order_items` oi\\n  JOIN\\n    `thelook.inventory_items` ii ON oi.inventory_item_id = ii.id\\n  GROUP BY\\n    ii.product_brand\\nORDER BY\\n  avg_sale_price DESC\\nLIMIT 5;\",\"description\":\"Identify the top 5 product brands with the highest average sale price in order items.\"},{\"sql\":\"WITH UserTotalOrderValue AS (\\n  SELECT\\n      o.user_id,\\n      SUM(oi.sale_price) AS total_order_value\\n    FROM\\n      `thelook.orders` o\\n    JOIN\\n      `thelook.order_items` oi ON o.order_id = oi.order_id\\n    GROUP BY\\n      o.user_id\\n  )\\nSELECT\\n    APPROX_QUANTILES(total_order_value, 2)[OFFSET(1)] AS median_total_order_value\\n  FROM\\n    UserTotalOrderValue;\",\"description\":\"Calculate the total order value (TOV) for each user, and then find the median TOV across all users.\"},{\"sql\":\"SELECT\\n    dc.name,\\n    AVG(TIMESTAMP_DIFF(o.delivered_at, o.created_at, DAY)) AS avg_delivery_time\\n  FROM\\n    `thelook.orders` o\\n  JOIN\\n    `thelook.order_items` oi ON o.order_id = oi.order_id\\n  JOIN\\n    `thelook.inventory_items` ii ON oi.inventory_item_id = ii.id\\n  JOIN\\n    `thelook.distribution_centers` dc ON ii.product_distribution_center_id = dc.id\\n  WHERE o.delivered_at IS NOT NULL\\n  GROUP BY\\n    dc.name;\",\"description\":\"Determine the average number of days between order creation and delivery, segmented by the distribution center associated with the products in the order.\"},{\"sql\":\"WITH monthly_tov AS (\\n  SELECT\\n    FORMAT_DATE('%Y-%m', DATE(o.created_at)) AS order_month,\\n    ii.product_category,\\n    SUM(oi.sale_price) AS monthly_tov\\n  FROM\\n    `thelook.orders` o\\n  JOIN\\n    `thelook.order_items` oi ON o.order_id = oi.order_id\\n  JOIN\\n    `thelook.inventory_items` ii ON oi.inventory_item_id = ii.id\\n  GROUP BY 1, 2\\n)\\nSELECT\\n  this_year.order_month,\\n  this_year.product_category,\\n  this_year.monthly_tov,\\n  last_year.monthly_tov AS last_year_tov,\\n  (this_year.monthly_tov - last_year.monthly_tov) / last_year.monthly_tov AS year_over_year_growth\\nFROM\\n  monthly_tov this_year\\nLEFT JOIN\\n  monthly_tov last_year ON this_year.product_category = last_year.product_category\\n  AND FORMAT_DATE('%m', PARSE_DATE('%Y-%m', this_year.order_month)) = FORMAT_DATE('%m', PARSE_DATE('%Y-%m', last_year.order_month))\\n  AND CAST(FORMAT_DATE('%Y', PARSE_DATE('%Y-%m', this_year.order_month)) AS INT64) = CAST(FORMAT_DATE('%Y', PARSE_DATE('%Y-%m', last_year.order_month)) AS INT64) + 1\\nORDER BY 2, 1;\",\"description\":\"What is the year-over-year growth rate of total order value for each product category?\"},{\"sql\":\"WITH age_groups AS (\\n  SELECT\\n    o.order_id,\\n    CASE\\n      WHEN u.age < 25 THEN 'Under 25'\\n      WHEN u.age BETWEEN 25 AND 35 THEN '25-35'\\n      WHEN u.age BETWEEN 36 AND 50 THEN '36-50'\\n      ELSE 'Over 50'\\n    END AS age_group,\\n    o.created_at,\\n    o.num_of_item\\n  FROM\\n    `thelook.orders` o\\n  JOIN\\n    `thelook.users` u ON o.user_id = u.id\\n)\\nSELECT\\n  FORMAT_DATE('%Y-%m', DATE(created_at)) AS order_month,\\n  age_group,\\n  AVG(num_of_item) AS avg_items_per_order\\nFROM\\n  age_groups\\nGROUP BY 1, 2\\nORDER BY 2, 1;\",\"description\":\"What is the trend of average number of items per order over time, segmented by user age group?\"},{\"sql\":\"WITH order_times AS (\\n    SELECT\\n        order_id,\\n        user_id,\\n        created_at,\\n        delivered_at,\\n        TIMESTAMP_DIFF(delivered_at, created_at, DAY) AS delivery_time_days\\n    FROM\\n        `thelook.orders`\\n    WHERE delivered_at IS NOT NULL\\n),\\naverage_delivery_times AS (\\n    SELECT\\n        AVG(delivery_time_days) AS avg_delivery_time,\\n        STDDEV(delivery_time_days) AS std_delivery_time\\n    FROM\\n        order_times\\n),\\nanomalous_delivery_times AS (\\n    SELECT\\n        order_times.order_id,\\n        order_times.user_id,\\n        order_times.created_at,\\n        order_times.delivered_at,\\n        order_times.delivery_time_days,\\n        average_delivery_times.avg_delivery_time,\\n        average_delivery_times.std_delivery_time\\n    FROM\\n        order_times\\n    CROSS JOIN\\n        average_delivery_times\\n    WHERE\\n        order_times.delivery_time_days < average_delivery_times.avg_delivery_time - (3 * average_delivery_times.std_delivery_time)\\n)\\nSELECT\\n    order_id,\\n    user_id,\\n    created_at,\\n    delivered_at,\\n    delivery_time_days,\\n    avg_delivery_time,\\n    std_delivery_time\\nFROM\\n    anomalous_delivery_times\\nORDER BY\\n    delivery_time_days ASC;\",\"description\":\"Detect users with unusually low delivered_at timestamps compared to created_at timestamps in orders, which might indicate data entry errors or fraudulent orders where delivery is prematurely marked.\"},{\"sql\":\"WITH user_ip_events AS (\\n    SELECT\\n        user_id,\\n        ip_address,\\n        TIMESTAMP_TRUNC(created_at, HOUR) AS event_hour,\\n        COUNT(*) AS event_count\\n    FROM\\n        `thelook.events`\\n    WHERE user_id IS NOT NULL\\n    GROUP BY\\n        user_id,\\n        ip_address,\\n        event_hour\\n),\\naverage_ip_events AS (\\n    SELECT\\n        AVG(event_count) AS avg_event_count,\\n        STDDEV(event_count) AS std_event_count\\n    FROM\\n        user_ip_events\\n),\\nanomalous_ip_events AS (\\n    SELECT\\n        user_ip_events.user_id,\\n        user_ip_events.ip_address,\\n        user_ip_events.event_hour,\\n        user_ip_events.event_count,\\n        average_ip_events.avg_event_count,\\n        average_ip_events.std_event_count\\n    FROM\\n        user_ip_events\\n    CROSS JOIN\\n        average_ip_events\\n    WHERE\\n        user_ip_events.event_count > average_ip_events.avg_event_count + (3 * average_ip_events.std_event_count)\\n)\\nSELECT\\n    user_id,\\n    ip_address,\\n    event_hour,\\n    event_count,\\n    avg_event_count,\\n    std_event_count\\nFROM\\n    anomalous_ip_events\\nORDER BY\\n    event_count DESC;\",\"description\":\"Identify users with unusually high numbers of events originating from the same IP address within a short time frame, suggesting potential bot activity or account sharing.\"}],\"dataset_business_glossary\":[{\"title\":\"Age\",\"description\":\"The number of years a user has lived. For example, a user who is 30 years old has an age of 30.\"},{\"title\":\"Brand\",\"description\":\"The name under which a particular product or service is marketed. Example: Nike, Apple.\"},{\"title\":\"Cart\",\"description\":\"A virtual shopping cart where users add products they intend to purchase.\"},{\"title\":\"Category\",\"description\":\"A group of products or services that are similar to each other. Example: Electronics, Clothing.\"},{\"title\":\"City\",\"description\":\"The city in which a user or distribution center is located. Example: New York, London.\"},{\"title\":\"Cost\",\"description\":\"The amount of money spent to produce, acquire, or maintain a product or service.\"},{\"title\":\"Country\",\"description\":\"The nation in which a user or distribution center is located. Example: United States, China.\"},{\"title\":\"Customer Lifetime Value (CLTV)\",\"description\":\"A prediction of the net profit attributed to the entire future relationship with a customer. It helps businesses understand the potential long-term value of their customers.\"},{\"title\":\"Customer\",\"description\":\"An individual or entity that purchases goods or services from a business.\"},{\"title\":\"Department\",\"description\":\"A section within a retail organization that specializes in a particular type of product. Example: Women's Clothing, Electronics.\"},{\"title\":\"Delivered At\",\"description\":\"The timestamp indicating when an order or order item was received by the customer.\"},{\"title\":\"Distribution Center\",\"description\":\"A warehouse or facility where products are stored before being shipped to customers or retail locations.\"},{\"title\":\"Email\",\"description\":\"A user's electronic mail address. Example: john.doe@example.com.\"},{\"title\":\"Event\",\"description\":\"A user interaction or action on a website or application. Example: product view, add to cart, purchase.\"},{\"title\":\"Gender\",\"description\":\"The biological sex of a user. Example: Male, Female.\"},{\"title\":\"Geography\",\"description\":\"The location of a user or distribution center, often represented by latitude and longitude coordinates.\"},{\"title\":\"Inventory Turnover\",\"description\":\"A measure of how quickly inventory is sold or used over a period of time. It indicates the efficiency of inventory management.\"},{\"title\":\"IP Address\",\"description\":\"A unique numerical label assigned to each device connected to a computer network that uses the Internet Protocol for communication.\"},{\"title\":\"Latitude\",\"description\":\"The angular distance of a place north or south of the earth's equator.\"},{\"title\":\"Longitude\",\"description\":\"The angular distance of a place east or west of the meridian at Greenwich, England.\"},{\"title\":\"Name\",\"description\":\"The descriptive label of a product or distribution center.\"},{\"title\":\"Order\",\"description\":\"A request by a customer to purchase goods or services.\"},{\"title\":\"Order Item\",\"description\":\"A specific product included in an order.\"},{\"title\":\"Postal Code\",\"description\":\"A series of letters or digits or both, included in a postal address for the purpose of sorting mail.\"},{\"title\":\"Product\",\"description\":\"An item offered for sale.\"},{\"title\":\"Product SKU\",\"description\":\"A unique identifier for a product, used for inventory management.\"},{\"title\":\"Returned At\",\"description\":\"The timestamp indicating when an order or order item was returned by the customer.\"},{\"title\":\"Retail Price\",\"description\":\"The price at which a product is sold to customers.\"},{\"title\":\"Sale Price\",\"description\":\"The discounted price at which a product is sold to customers.\"},{\"title\":\"Session\",\"description\":\"A period of continuous interaction by a user with a website or application.\"},{\"title\":\"Shipped At\",\"description\":\"The timestamp indicating when an order or order item was sent to the customer.\"},{\"title\":\"SKU\",\"description\":\"Stock Keeping Unit, a unique identifier for each distinct product and service that can be purchased.\"},{\"title\":\"State\",\"description\":\"A region or territory within a country. Example: California, Texas.\"},{\"title\":\"Status\",\"description\":\"The current state or condition of an order or order item. Example: Shipped, Delivered, Returned.\"},{\"title\":\"Street Address\",\"description\":\"The physical location of a user.\"},{\"title\":\"Traffic Source\",\"description\":\"The origin from which a user arrives at a website or application. Example: Search Engine, Social Media.\"},{\"title\":\"User\",\"description\":\"An individual who interacts with a website or application.\"},{\"title\":\"User ID\",\"description\":\"A unique identifier for a user.\"},{\"title\":\"Website Conversion Rate\",\"description\":\"The percentage of website visitors who complete a desired action, such as making a purchase or filling out a form.\"},{\"title\":\"Average Order Value (AOV)\",\"description\":\"The average amount of money spent per order. It is calculated by dividing total revenue by the number of orders.\"},{\"title\":\"Cart Abandonment Rate\",\"description\":\"The percentage of users who add items to their cart but do not complete the purchase.\"},{\"title\":\"Fraudulent Transaction\",\"description\":\"A transaction that is unauthorized or deceptive, often involving stolen payment information.\"},{\"title\":\"Payment Gateway\",\"description\":\"A service that authorizes credit card or direct payments processing for e-businesses, online retailers, or traditional brick and mortar.\"},{\"title\":\"Promotion\",\"description\":\"A marketing activity designed to boost sales or increase brand awareness.\"},{\"title\":\"Supply Chain\",\"description\":\"The network of organizations and activities involved in producing and delivering a product or service to the end customer.\"},{\"title\":\"Vendor\",\"description\":\"A company or individual who supplies goods or services to a business.\"},{\"title\":\"Warehouse\",\"description\":\"A building used for storing goods.\"},{\"title\":\"Shipping Carrier\",\"description\":\"A company that transports goods from one location to another.\"},{\"title\":\"Customer Segmentation\",\"description\":\"Dividing customers into groups based on shared characteristics, such as demographics, behavior, or preferences.\"},{\"title\":\"Personalized Recommendation\",\"description\":\"Suggesting products or services to customers based on their past purchases, browsing history, or other data.\"},{\"title\":\"A/B Testing\",\"description\":\"Comparing two versions of a webpage, app, or other marketing asset to see which one performs better.\"},{\"title\":\"Churn Rate\",\"description\":\"The rate at which customers stop doing business with a company.\"},{\"title\":\"Referral Program\",\"description\":\"A marketing program that encourages existing customers to refer new customers to a business.\"},{\"title\":\"Loyalty Program\",\"description\":\"A marketing program that rewards customers for their repeat business.\"},{\"title\":\"Affiliate Marketing\",\"description\":\"A marketing arrangement in which a business rewards one or more affiliates for each visitor or customer brought about by the affiliate's own marketing efforts.\"},{\"title\":\"Influencer Marketing\",\"description\":\"A type of marketing that involves collaborating with influencers (individuals who have a large following on social media) to promote a product or service.\"},{\"title\":\"Content Marketing\",\"description\":\"A type of marketing that involves creating and sharing valuable, relevant, and consistent content to attract and retain a clearly defined audience.\"},{\"title\":\"Search Engine Optimization (SEO)\",\"description\":\"The process of improving the ranking of a website or webpage in search engine results pages (SERPs).\"},{\"title\":\"Pay-Per-Click (PPC) Advertising\",\"description\":\"A type of online advertising in which advertisers pay a fee each time one of their ads is clicked.\"},{\"title\":\"Social Media Marketing\",\"description\":\"The process of using social media platforms to promote a product or service.\"},{\"title\":\"Email Marketing\",\"description\":\"The process of sending commercial messages to a group of people via email.\"},{\"title\":\"Mobile Marketing\",\"description\":\"The process of reaching customers through their mobile devices.\"},{\"title\":\"Video Marketing\",\"description\":\"The process of using video to promote a product or service.\"},{\"title\":\"Analytics\",\"description\":\"The process of collecting, analyzing, and interpreting data to gain insights and improve decision-making.\"},{\"title\":\"Key Performance Indicator (KPI)\",\"description\":\"A measurable value that demonstrates how effectively a company is achieving key business objectives.\"},{\"title\":\"Return on Investment (ROI)\",\"description\":\"A performance measure used to evaluate the efficiency of an investment or compare the efficiency of a number of different investments.\"},{\"title\":\"Profit Margin\",\"description\":\"A financial ratio that measures the profitability of a company.\"},{\"title\":\"Revenue\",\"description\":\"The total amount of money a company receives from its sales.\"},{\"title\":\"Expenses\",\"description\":\"The costs that a company incurs to operate its business.\"},{\"title\":\"Assets\",\"description\":\"The resources that a company owns or controls.\"},{\"title\":\"Liabilities\",\"description\":\"The obligations that a company owes to others.\"},{\"title\":\"Equity\",\"description\":\"The owners' stake in a company.\"},{\"title\":\"Financial Statement\",\"description\":\"A summary of a company's financial performance over a period of time.\"},{\"title\":\"Balance Sheet\",\"description\":\"A financial statement that reports a company's assets, liabilities, and equity at a specific point in time.\"},{\"title\":\"Income Statement\",\"description\":\"A financial statement that reports a company's financial performance over a period of time.\"},{\"title\":\"Cash Flow Statement\",\"description\":\"A financial statement that reports a company's cash inflows and outflows over a period of time.\"},{\"title\":\"Auditing\",\"description\":\"The process of verifying the accuracy of a company's financial statements.\"},{\"title\":\"Compliance\",\"description\":\"The process of adhering to laws, regulations, and ethical standards.\"},{\"title\":\"Risk Management\",\"description\":\"The process of identifying, assessing, and mitigating risks.\"},{\"title\":\"Internal Controls\",\"description\":\"The policies and procedures that a company uses to protect its assets and prevent fraud.\"},{\"title\":\"Data Security\",\"description\":\"The process of protecting data from unauthorized access, use, disclosure, disruption, modification, or destruction.\"},{\"title\":\"Privacy\",\"description\":\"The right of individuals to control the collection, use, and disclosure of their personal information.\"},{\"title\":\"Data Governance\",\"description\":\"The process of establishing and enforcing policies and procedures for managing data.\"},{\"title\":\"Data Quality\",\"description\":\"The degree to which data is accurate, complete, consistent, timely, and relevant.\"},{\"title\":\"Metadata\",\"description\":\"Data about data.\"},{\"title\":\"Data Dictionary\",\"description\":\"A central repository of information about data, such as its name, definition, data type, and source.\"},{\"title\":\"Data Lineage\",\"description\":\"The history of data, from its origin to its current location.\"},{\"title\":\"Data Integration\",\"description\":\"The process of combining data from different sources into a unified view.\"},{\"title\":\"Data Migration\",\"description\":\"The process of moving data from one system to another.\"},{\"title\":\"Data Warehouse\",\"description\":\"A central repository of data that is used for reporting and analysis.\"},{\"title\":\"Data Lake\",\"description\":\"A central repository of data that can store structured, semi-structured, and unstructured data.\"},{\"title\":\"Big Data\",\"description\":\"Extremely large and complex datasets that are difficult to process using traditional data processing applications.\"},{\"title\":\"Cloud Computing\",\"description\":\"The delivery of computing services—including servers, storage, databases, networking, software, analytics, and intelligence—over the Internet (“the cloud”) to offer faster innovation, flexible resources, and economies of scale.\"},{\"title\":\"Machine Learning\",\"description\":\"A type of artificial intelligence that enables computers to learn from data without being explicitly programmed.\"},{\"title\":\"Artificial Intelligence (AI)\",\"description\":\"The theory and development of computer systems able to perform tasks that normally require human intelligence, such as visual perception, speech recognition, decision-making, and translation between languages.\"},{\"title\":\"Business Intelligence (BI)\",\"description\":\"The process of using data to gain insights and improve decision-making.\"},{\"title\":\"Data Visualization\",\"description\":\"The process of presenting data in a graphical format.\"},{\"title\":\"Dashboard\",\"description\":\"A visual display of key performance indicators (KPIs) and other important data.\"},{\"title\":\"Report\",\"description\":\"A document that presents data in a structured format.\"},{\"title\":\"Query\",\"description\":\"A request for data from a database.\"},{\"title\":\"Database\",\"description\":\"A structured collection of data.\"},{\"title\":\"Table\",\"description\":\"A collection of related data organized in rows and columns.\"},{\"title\":\"Column\",\"description\":\"A vertical set of data values in a table.\"},{\"title\":\"Row\",\"description\":\"A horizontal set of data values in a table.\"},{\"title\":\"Data Type\",\"description\":\"The type of data that can be stored in a column, such as text, number, or date.\"},{\"title\":\"Primary Key\",\"description\":\"A column or set of columns that uniquely identifies each row in a table.\"},{\"title\":\"Foreign Key\",\"description\":\"A column in one table that refers to the primary key in another table.\"},{\"title\":\"Join\",\"description\":\"An operation that combines data from two or more tables based on a related column.\"},{\"title\":\"Filter\",\"description\":\"An operation that selects data based on a specific criteria.\"},{\"title\":\"Sort\",\"description\":\"An operation that arranges data in a specific order.\"},{\"title\":\"Aggregate\",\"description\":\"An operation that calculates a summary value for a group of data, such as the sum, average, or count.\"},{\"title\":\"Data Mining\",\"description\":\"The process of discovering patterns and relationships in data.\"},{\"title\":\"Predictive Analytics\",\"description\":\"The process of using data to predict future outcomes.\"},{\"title\":\"Prescriptive Analytics\",\"description\":\"The process of using data to recommend actions that will optimize business outcomes.\"},{\"title\":\"Text Analytics\",\"description\":\"The process of extracting insights from text data.\"},{\"title\":\"Sentiment Analysis\",\"description\":\"The process of determining the emotional tone of text data.\"},{\"title\":\"Image Recognition\",\"description\":\"The process of identifying objects, people, places, and actions in images.\"},{\"title\":\"Speech Recognition\",\"description\":\"The process of converting spoken words into text.\"},{\"title\":\"Natural Language Processing (NLP)\",\"description\":\"The ability of a computer to understand, interpret, and generate human language.\"},{\"title\":\"Chatbot\",\"description\":\"A computer program that simulates conversation with a human.\"},{\"title\":\"Robotic Process Automation (RPA)\",\"description\":\"The use of software robots to automate repetitive tasks.\"},{\"title\":\"Blockchain\",\"description\":\"A distributed ledger technology that allows for secure, transparent, and tamper-proof transactions.\"},{\"title\":\"Internet of Things (IoT)\",\"description\":\"A network of physical devices, vehicles, home appliances, and other items embedded with electronics, software, sensors, actuators, and network connectivity that enable these objects to collect and exchange data.\"},{\"title\":\"Cybersecurity\",\"description\":\"The practice of protecting computer systems and networks from cyberattacks.\"},{\"title\":\"Cloud Security\",\"description\":\"The practice of protecting data and applications stored in the cloud.\"},{\"title\":\"Data Loss Prevention (DLP)\",\"description\":\"The practice of preventing sensitive data from leaving an organization's control.\"},{\"title\":\"Incident Response\",\"description\":\"The process of responding to and recovering from security incidents.\"},{\"title\":\"Disaster Recovery\",\"description\":\"The process of recovering from a disaster that disrupts business operations.\"},{\"title\":\"Business Continuity\",\"description\":\"The process of ensuring that business operations can continue during a disaster.\"},{\"title\":\"Supply Chain Management (SCM)\",\"description\":\"The management of the flow of goods, information, and finances as they move from suppliers to manufacturers to wholesalers to retailers to consumers.\"},{\"title\":\"Customer Relationship Management (CRM)\",\"description\":\"A technology for managing all of a company's relationships and interactions with customers and potential customers.\"},{\"title\":\"Enterprise Resource Planning (ERP)\",\"description\":\"A type of software that organizations use to manage day-to-day business activities such as accounting, procurement, project management, risk management and compliance, and supply chain operations.\"},{\"title\":\"Human Resources (HR)\",\"description\":\"The department of a business or organization that deals with the hiring, administration, and training of personnel.\"},{\"title\":\"Finance\",\"description\":\"The management of money and investments.\"},{\"title\":\"Accounting\",\"description\":\"The process of recording, classifying, and summarizing financial transactions.\"},{\"title\":\"Marketing\",\"description\":\"The process of creating, communicating, and delivering value to customers.\"},{\"title\":\"Sales\",\"description\":\"The process of selling goods or services.\"},{\"title\":\"Operations\",\"description\":\"The activities involved in producing and delivering goods or services.\"},{\"title\":\"Research and Development (R&D)\",\"description\":\"The activities that a company undertakes to innovate and introduce new products and services.\"},{\"title\":\"Legal\",\"description\":\"The department of a business or organization that deals with legal matters.\"},{\"title\":\"Compliance Officer\",\"description\":\"A person who ensures that a company is complying with all applicable laws and regulations.\"},{\"title\":\"Auditor\",\"description\":\"A person who verifies the accuracy of a company's financial statements.\"},{\"title\":\"Consultant\",\"description\":\"A person who provides expert advice to businesses.\"},{\"title\":\"Analyst\",\"description\":\"A person who analyzes data to gain insights and improve decision-making.\"},{\"title\":\"Developer\",\"description\":\"A person who writes code to create software applications.\"},{\"title\":\"Engineer\",\"description\":\"A person who designs, builds, and maintains systems and infrastructure.\"},{\"title\":\"Project Manager\",\"description\":\"A person who plans, organizes, and manages projects.\"},{\"title\":\"Business Owner\",\"description\":\"A person who owns and operates a business.\"},{\"title\":\"Executive\",\"description\":\"A person who is responsible for the overall management of a business.\"},{\"title\":\"Shareholder\",\"description\":\"A person who owns shares in a company.\"},{\"title\":\"Board of Directors\",\"description\":\"A group of people who are elected by shareholders to oversee the management of a company.\"},{\"title\":\"Stakeholder\",\"description\":\"A person or organization that has an interest in a company.\"},{\"title\":\"Competition\",\"description\":\"Other businesses that offer similar products or services.\"},{\"title\":\"Market\",\"description\":\"A group of potential customers.\"},{\"title\":\"Industry\",\"description\":\"A group of businesses that are engaged in the same type of activity.\"},{\"title\":\"Economy\",\"description\":\"The state of a country or region in terms of the production and consumption of goods and services.\"},{\"title\":\"Globalization\",\"description\":\"The process of businesses expanding their operations to other countries.\"},{\"title\":\"Sustainability\",\"description\":\"The ability to meet the needs of the present without compromising the ability of future generations to meet their own needs.\"},{\"title\":\"Ethics\",\"description\":\"Moral principles that govern a person's behavior or the conducting of an activity.\"},{\"title\":\"Corporate Social Responsibility (CSR)\",\"description\":\"A company's commitment to operating in an ethical and sustainable manner.\"},{\"title\":\"Innovation\",\"description\":\"The process of creating new ideas, products, or services.\"},{\"title\":\"Technology\",\"description\":\"The application of scientific knowledge for practical purposes.\"},{\"title\":\"Digital Transformation\",\"description\":\"The process of using digital technologies to fundamentally change how a business operates and delivers value to customers.\"},{\"title\":\"Cloud Migration\",\"description\":\"The process of moving data, applications, and other business elements from an organization's on-premise computers to the cloud, or moving them from one cloud environment to another.\"},{\"title\":\"Microservices\",\"description\":\"An architectural style that structures an application as a collection of loosely coupled services, which implement business capabilities.\"},{\"title\":\"Containerization\",\"description\":\"A form of operating system virtualization, through which applications are run in isolated user spaces, called containers, all using the same shared operating system.\"},{\"title\":\"DevOps\",\"description\":\"A set of practices that combines software development and IT operations.\"},{\"title\":\"Agile Development\",\"description\":\"A software development methodology that emphasizes iterative development, collaboration, and customer feedback.\"},{\"title\":\"Scrum\",\"description\":\"A framework for managing complex projects, especially software development, using an iterative and incremental approach.\"},{\"title\":\"Kanban\",\"description\":\"A visual system for managing workflow.\"},{\"title\":\"Lean Manufacturing\",\"description\":\"A production philosophy focused on minimizing waste and maximizing efficiency.\"},{\"title\":\"Six Sigma\",\"description\":\"A set of techniques and tools for process improvement.\"},{\"title\":\"Total Quality Management (TQM)\",\"description\":\"A management approach focused on continuous improvement of all aspects of an organization.\"},{\"title\":\"Business Process Management (BPM)\",\"description\":\"A management approach focused on improving business processes.\"},{\"title\":\"Workflow\",\"description\":\"A sequence of tasks that are performed to complete a business process.\"},{\"title\":\"Automation\",\"description\":\"The use of technology to automate tasks.\"},{\"title\":\"Robotics\",\"description\":\"The use of robots to automate tasks.\"},{\"title\":\"Artificial Intelligence (AI)\",\"description\":\"The theory and development of computer systems able to perform tasks that normally require human intelligence, such as visual perception, speech recognition, decision-making, and translation between languages.\"},{\"title\":\"Machine Learning (ML)\",\"description\":\"A type of artificial intelligence that enables computers to learn from data without being explicitly programmed.\"},{\"title\":\"Deep Learning\",\"description\":\"A type of machine learning that uses artificial neural networks with multiple layers to analyze data.\"},{\"title\":\"Neural Network\",\"description\":\"A computer system modeled on the human brain and nervous system.\"},{\"title\":\"Algorithm\",\"description\":\"A set of rules that a computer follows to solve a problem.\"},{\"title\":\"Data Structure\",\"description\":\"A way of organizing and storing data in a computer.\"},{\"title\":\"Programming Language\",\"description\":\"A formal language used to instruct a computer to perform a task.\"},{\"title\":\"Software\",\"description\":\"A set of instructions that tells a computer what to do.\"},{\"title\":\"Hardware\",\"description\":\"The physical components of a computer system.\"},{\"title\":\"Operating System\",\"description\":\"The software that manages the hardware and software resources of a computer system.\"},{\"title\":\"Network\",\"description\":\"A group of computers that are connected together.\"},{\"title\":\"Internet\",\"description\":\"A global network of computers.\"},{\"title\":\"World Wide Web (WWW)\",\"description\":\"A system of interlinked hypertext documents accessed via the Internet.\"},{\"title\":\"Website\",\"description\":\"A collection of web pages that are accessible via the Internet.\"},{\"title\":\"Web Page\",\"description\":\"A document that is displayed in a web browser.\"},{\"title\":\"Web Browser\",\"description\":\"A software application for retrieving, presenting, and traversing information resources on the World Wide Web.\"},{\"title\":\"Search Engine\",\"description\":\"A software application for finding information on the World Wide Web.\"},{\"title\":\"Social Media\",\"description\":\"Websites and applications that enable users to create and share content or to participate in social networking.\"},{\"title\":\"Mobile App\",\"description\":\"A software application designed to run on mobile devices such as smartphones and tablets.\"},{\"title\":\"Cloud Storage\",\"description\":\"A service that allows users to store data on remote servers.\"},{\"title\":\"Data Backup\",\"description\":\"A copy of data that is stored in a safe place.\"},{\"title\":\"Data Recovery\",\"description\":\"The process of restoring data that has been lost or damaged.\"},{\"title\":\"Disaster Recovery Plan\",\"description\":\"A plan for recovering from a disaster that disrupts business operations.\"},{\"title\":\"Business Continuity Plan\",\"description\":\"A plan for ensuring that business operations can continue during a disaster.\"},{\"title\":\"Cybersecurity Policy\",\"description\":\"A set of rules that govern the use of computer systems and networks to protect them from cyberattacks.\"},{\"title\":\"Privacy Policy\",\"description\":\"A statement that describes how a company collects, uses, and discloses personal information.\"},{\"title\":\"Terms of Service\",\"description\":\"A set of rules that users must agree to in order to use a website or service.\"},{\"title\":\"Intellectual Property\",\"description\":\"Creations of the mind, such as inventions; literary and artistic works; designs; and symbols, names and images used in commerce.\"},{\"title\":\"Copyright\",\"description\":\"A legal right granted to the creator of original works of authorship, including literary, dramatic, musical, and certain other intellectual works.\"},{\"title\":\"Trademark\",\"description\":\"A symbol, design, or phrase legally registered to represent a company or product.\"},{\"title\":\"Patent\",\"description\":\"A government authority or license conferring a right or title for a set period, especially the sole right to exclude others from making, using, or selling an invention.\"},{\"title\":\"Trade Secret\",\"description\":\"A formula, practice, design, instrument, or compilation of information that is not generally known or reasonably ascertainable, by which a business can obtain an economic advantage over competitors or customers.\"},{\"title\":\"Contract\",\"description\":\"A legally binding agreement between two or more parties.\"},{\"title\":\"Liability\",\"description\":\"The state of being legally responsible for something.\"},{\"title\":\"Negligence\",\"description\":\"Failure to take reasonable care to avoid causing injury or loss to another person.\"},{\"title\":\"Warranty\",\"description\":\"A written guarantee, issued to the purchaser of an article by its manufacturer, promising to repair or replace it if necessary within a specified period of time.\"},{\"title\":\"Insurance\",\"description\":\"A contract whereby one party (the insurer) undertakes to indemnify another party (the insured) against the risk of specified loss or damage.\"},{\"title\":\"Risk Assessment\",\"description\":\"The process of identifying and evaluating risks.\"},{\"title\":\"Risk Mitigation\",\"description\":\"The process of taking steps to reduce the likelihood or impact of risks.\"},{\"title\":\"Contingency Plan\",\"description\":\"A plan for dealing with unexpected events.\"},{\"title\":\"Crisis Management\",\"description\":\"The process of responding to and recovering from a crisis.\"},{\"title\":\"Public Relations (PR)\",\"description\":\"The practice of managing the spread of information between an individual or an organization and the public.\"},{\"title\":\"Reputation Management\",\"description\":\"The process of monitoring and influencing the public perception of a company or brand.\"},{\"title\":\"Customer Service\",\"description\":\"The assistance and advice provided by a company to those people who buy or use its products or services.\"},{\"title\":\"Customer Satisfaction\",\"description\":\"The degree to which customers are happy with the products and services they receive from a company.\"},{\"title\":\"Customer Loyalty\",\"description\":\"The tendency of customers to continue buying from a particular company.\"},{\"title\":\"Customer Advocacy\",\"description\":\"The act of customers recommending a company's products or services to others.\"},{\"title\":\"Net Promoter Score (NPS)\",\"description\":\"A metric that measures customer loyalty and willingness to recommend a company to others.\"},{\"title\":\"Customer Experience (CX)\",\"description\":\"The overall experience a customer has with a company.\"},{\"title\":\"User Interface (UI)\",\"description\":\"The visual elements of a website or application that allow users to interact with it.\"},{\"title\":\"User Experience (UX)\",\"description\":\"The overall experience a user has when interacting with a website or application.\"},{\"title\":\"Accessibility\",\"description\":\"The degree to which a website or application is usable by people with disabilities.\"},{\"title\":\"Usability\",\"description\":\"The ease with which a website or application can be used.\"},{\"title\":\"Performance\",\"description\":\"The speed and efficiency of a website or application.\"},{\"title\":\"Scalability\",\"description\":\"The ability of a website or application to handle increasing amounts of traffic.\"},{\"title\":\"Reliability\",\"description\":\"The ability of a website or application to function correctly and consistently.\"},{\"title\":\"Security\",\"description\":\"The measures taken to protect a website or application from cyberattacks.\"},{\"title\":\"Data Encryption\",\"description\":\"The process of converting data into a secret code to prevent unauthorized access.\"},{\"title\":\"Firewall\",\"description\":\"A security system that protects a computer network from unauthorized access.\"},{\"title\":\"Antivirus Software\",\"description\":\"A software application that protects a computer from viruses and other malware.\"},{\"title\":\"Malware\",\"description\":\"Software that is intended to damage or disable computer systems.\"},{\"title\":\"Phishing\",\"description\":\"The fraudulent practice of sending emails purporting to be from reputable companies in order to induce individuals to reveal personal information, such as passwords and credit card numbers.\"},{\"title\":\"Ransomware\",\"description\":\"A type of malware that encrypts a victim's files and demands a ransom to restore them.\"},{\"title\":\"Denial-of-Service (DoS) Attack\",\"description\":\"An attack that floods a computer system with traffic to make it unavailable to its intended users.\"},{\"title\":\"Data Breach\",\"description\":\"A security incident in which sensitive data is accessed or disclosed without authorization.\"},{\"title\":\"Identity Theft\",\"description\":\"The fraudulent acquisition and use of a person's private identifying information, usually for financial gain.\"},{\"title\":\"Fraud\",\"description\":\"Wrongful or criminal deception intended to result in financial or personal gain.\"},{\"title\":\"Insider Threat\",\"description\":\"A security risk that originates from within an organization.\"},{\"title\":\"Supply Chain Risk\",\"description\":\"The risk that a disruption in the supply chain will negatively impact a company's operations.\"},{\"title\":\"Regulatory Compliance\",\"description\":\"The process of adhering to laws, regulations, and ethical standards.\"},{\"title\":\"Sarbanes-Oxley Act (SOX)\",\"description\":\"A United States federal law that sets standards for financial reporting and disclosure.\"},{\"title\":\"General Data Protection Regulation (GDPR)\",\"description\":\"A European Union law that protects the personal data of individuals.\"},{\"title\":\"California Consumer Privacy Act (CCPA)\",\"description\":\"A California law that gives consumers more control over their personal information.\"},{\"title\":\"Health Insurance Portability and Accountability Act (HIPAA)\",\"description\":\"A United States federal law that protects the privacy of individuals' health information.\"},{\"title\":\"Payment Card Industry Data Security Standard (PCI DSS)\",\"description\":\"A set of security standards designed to protect credit card data.\"},{\"title\":\"Data Retention Policy\",\"description\":\"A policy that specifies how long data should be retained.\"},{\"title\":\"Data Disposal Policy\",\"description\":\"A policy that specifies how data should be disposed of.\"},{\"title\":\"Incident Response Plan\",\"description\":\"A plan for responding to and recovering from security incidents.\"},{\"title\":\"Business Continuity Plan\",\"description\":\"A plan for ensuring that business operations can continue during a disaster.\"},{\"title\":\"Disaster Recovery Plan\",\"description\":\"A plan for recovering from a disaster that disrupts business operations.\"},{\"title\":\"Employee Training\",\"description\":\"Training that is provided to employees to help them perform their jobs effectively and safely.\"},{\"title\":\"Security Awareness Training\",\"description\":\"Training that is provided to employees to help them understand and avoid security risks.\"},{\"title\":\"Ethics Training\",\"description\":\"Training that is provided to employees to help them understand and adhere to ethical standards.\"},{\"title\":\"Code of Conduct\",\"description\":\"A set of rules that govern the behavior of employees.\"},{\"title\":\"Whistleblower Policy\",\"description\":\"A policy that protects employees who report wrongdoing.\"},{\"title\":\"Open Door Policy\",\"description\":\"A policy that allows employees to communicate directly with management.\"},{\"title\":\"Employee Handbook\",\"description\":\"A document that contains information about a company's policies and procedures.\"},{\"title\":\"Performance Review\",\"description\":\"A process for evaluating an employee's performance.\"},{\"title\":\"Compensation\",\"description\":\"The money and benefits that an employee receives for their work.\"},{\"title\":\"Benefits\",\"description\":\"Non-wage compensation provided to employees, such as health insurance, paid time off, and retirement plans.\"},{\"title\":\"Recruitment\",\"description\":\"The process of finding and hiring new employees.\"},{\"title\":\"Onboarding\",\"description\":\"The process of integrating new employees into a company.\"},{\"title\":\"Training and Development\",\"description\":\"The process of providing employees with the skills and knowledge they need to succeed in their jobs.\"},{\"title\":\"Succession Planning\",\"description\":\"The process of identifying and developing future leaders.\"},{\"title\":\"Employee Relations\",\"description\":\"The relationship between a company and its employees.\"},{\"title\":\"Labor Relations\",\"description\":\"The relationship between a company and its labor union.\"},{\"title\":\"Collective Bargaining\",\"description\":\"The process of negotiating a contract between a company and its labor union.\"},{\"title\":\"Grievance Procedure\",\"description\":\"A process for resolving disputes between a company and its employees.\"},{\"title\":\"Termination\",\"description\":\"The process of ending an employee's employment.\"},{\"title\":\"Unemployment Insurance\",\"description\":\"A government program that provides benefits to workers who have lost their jobs.\"},{\"title\":\"Workers' Compensation\",\"description\":\"A government program that provides benefits to workers who have been injured on the job.\"},{\"title\":\"Equal Employment Opportunity (EEO)\",\"description\":\"The principle that all individuals should have equal opportunities in employment, regardless of their race, color, religion, sex, national origin, age, disability, or genetic information.\"},{\"title\":\"Affirmative Action\",\"description\":\"A set of policies and practices designed to promote equal employment opportunities for members of historically underrepresented groups.\"},{\"title\":\"Diversity and Inclusion\",\"description\":\"The practice of creating a workplace that is welcoming and inclusive of people from all backgrounds.\"},{\"title\":\"Work-Life Balance\",\"description\":\"The ability to balance work and personal life.\"},{\"title\":\"Employee Engagement\",\"description\":\"The degree to which employees are passionate about their work and committed to their company.\"},{\"title\":\"Employee Satisfaction\",\"description\":\"The degree to which employees are happy with their jobs.\"},{\"title\":\"Employee Turnover\",\"description\":\"The rate at which employees leave a company.\"},{\"title\":\"Absenteeism\",\"description\":\"The practice of employees being absent from work.\"},{\"title\":\"Presenteeism\",\"description\":\"The practice of employees being present at work but not fully engaged or productive.\"},{\"title\":\"Stress\",\"description\":\"A state of mental or emotional strain or tension resulting from adverse or demanding circumstances.\"},{\"title\":\"Burnout\",\"description\":\"A state of emotional, physical, and mental exhaustion caused by prolonged or excessive stress.\"},{\"title\":\"Wellness Program\",\"description\":\"A program that promotes employee health and well-being.\"},{\"title\":\"Employee Assistance Program (EAP)\",\"description\":\"A program that provides confidential counseling and support services to employees.\"},{\"title\":\"Ergonomics\",\"description\":\"The study of people's efficiency in their working environment.\"},{\"title\":\"Occupational Safety and Health Administration (OSHA)\",\"description\":\"A government agency that sets and enforces workplace safety standards.\"},{\"title\":\"Hazard Communication\",\"description\":\"The process of informing employees about the hazards of chemicals in the workplace.\"},{\"title\":\"Personal Protective Equipment (PPE)\",\"description\":\"Equipment that is worn to protect employees from hazards in the workplace.\"},{\"title\":\"Emergency Preparedness\",\"description\":\"The process of preparing for emergencies in the workplace.\"},{\"title\":\"Evacuation Plan\",\"description\":\"A plan for evacuating employees from the workplace in the event of an emergency.\"},{\"title\":\"First Aid\",\"description\":\"The provision of immediate care to an injured or ill person.\"},{\"title\":\"Cardiopulmonary Resuscitation (CPR)\",\"description\":\"A life-saving technique that is used to revive someone who has stopped breathing or whose heart has stopped beating.\"},{\"title\":\"Automated External Defibrillator (AED)\",\"description\":\"A portable device that delivers an electric shock to the heart to restore a normal heart rhythm.\"},{\"title\":\"Workplace Violence\",\"description\":\"Violence or the threat of violence against workers in the workplace.\"},{\"title\":\"Active Shooter\",\"description\":\"A person who is actively engaged in killing or attempting to kill people in a confined and populated area.\"},{\"title\":\"Security Guard\",\"description\":\"A person who is employed to protect property and people.\"},{\"title\":\"Surveillance Camera\",\"description\":\"A camera that is used to monitor activity in a particular area.\"},{\"title\":\"Access Control\",\"description\":\"The process of restricting access to a particular area or resource.\"},{\"title\":\"Background Check\",\"description\":\"A process of verifying a person's identity and criminal history.\"},{\"title\":\"Drug Testing\",\"description\":\"The process of testing employees for the presence of drugs.\"},{\"title\":\"Alcohol Testing\",\"description\":\"The process of testing employees for the presence of alcohol.\"},{\"title\":\"Workplace Investigation\",\"description\":\"An investigation into an incident that has occurred in the workplace.\"},{\"title\":\"Disciplinary Action\",\"description\":\"Action that is taken against an employee for violating company policy.\"},{\"title\":\"Termination\",\"description\":\"The process of ending an employee's employment.\"},{\"title\":\"Legal Compliance\",\"description\":\"The process of adhering to laws, regulations, and ethical standards.\"},{\"title\":\"Risk Management\",\"description\":\"The process of identifying, assessing, and mitigating risks.\"},{\"title\":\"Insurance\",\"description\":\"A contract whereby one party (the insurer) undertakes to indemnify another party (the insured) against the risk of specified loss or damage.\"},{\"title\":\"Workers' Compensation\",\"description\":\"A government program that provides benefits to workers who have been injured on the job.\"},{\"title\":\"Unemployment Insurance\",\"description\":\"A government program that provides benefits to workers who have lost their jobs.\"},{\"title\":\"Social Security\",\"description\":\"A government program that provides benefits to retirees, disabled workers, and survivors of deceased workers.\"},{\"title\":\"Medicare\",\"description\":\"A government program that provides health insurance to people age 65 and older and to certain disabled people.\"},{\"title\":\"Medicaid\",\"description\":\"A government program that provides health insurance to low-income people.\"},{\"title\":\"Affordable Care Act (ACA)\",\"description\":\"A United States federal law that expands access to health insurance.\"},{\"title\":\"Employee Retirement Income Security Act (ERISA)\",\"description\":\"A United States federal law that sets standards for employee benefit plans.\"},{\"title\":\"Family and Medical Leave Act (FMLA)\",\"description\":\"A United States federal law that allows employees to take unpaid leave for family and medical reasons.\"},{\"title\":\"Fair Labor Standards Act (FLSA)\",\"description\":\"A United States federal law that sets minimum wage, overtime pay, and child labor standards.\"},{\"title\":\"National Labor Relations Act (NLRA)\",\"description\":\"A United States federal law that protects the rights of workers to form unions and bargain collectively.\"},{\"title\":\"Title VII of the Civil Rights Act of 1964\",\"description\":\"A United States federal law that prohibits discrimination in employment based on race, color, religion, sex, or national origin.\"},{\"title\":\"Age Discrimination in Employment Act (ADEA)\",\"description\":\"A United States federal law that protects workers age 40 and older from age discrimination.\"},{\"title\":\"Americans with Disabilities Act (ADA)\",\"description\":\"A United States federal law that prohibits discrimination against people with disabilities.\"},{\"title\":\"Genetic Information Nondiscrimination Act (GINA)\",\"description\":\"A United States federal law that prohibits discrimination in employment based on genetic information.\"},{\"title\":\"Immigration Reform and Control Act (IRCA)\",\"description\":\"A United States federal law that prohibits employers from knowingly hiring undocumented workers.\"},{\"title\":\"Occupational Safety and Health Act (OSH Act)\",\"description\":\"A United States federal law that sets and enforces workplace safety standards.\"},{\"title\":\"Consolidated Omnibus Budget Reconciliation Act (COBRA)\",\"description\":\"A United States federal law that allows employees to continue their health insurance coverage after they leave their jobs.\"},{\"title\":\"Health Insurance Portability and Accountability Act (HIPAA)\",\"description\":\"A United States federal law that protects the privacy of individuals' health information.\"},{\"title\":\"Sarbanes-Oxley Act (SOX)\",\"description\":\"A United States federal law that sets standards for financial reporting and disclosure.\"},{\"title\":\"Dodd-Frank Wall Street Reform and Consumer Protection Act\",\"description\":\"A United States federal law that regulates the financial industry.\"},{\"title\":\"Foreign Corrupt Practices Act (FCPA)\",\"description\":\"A United States federal law that prohibits U.S. companies from bribing foreign officials.\"},{\"title\":\"General Data Protection Regulation (GDPR)\",\"description\":\"A European Union law that protects the personal data of individuals.\"},{\"title\":\"California Consumer Privacy Act (CCPA)\",\"description\":\"A California law that gives consumers more control over their personal information.\"},{\"title\":\"Payment Card Industry Data Security Standard (PCI DSS)\",\"description\":\"A set of security standards designed to protect credit card data.\"},{\"title\":\"Data Retention Policy\",\"description\":\"A policy that specifies how long data should be retained.\"},{\"title\":\"Data Disposal Policy\",\"description\":\"A policy that specifies how data should be disposed of.\"},{\"title\":\"Incident Response Plan\",\"description\":\"A plan for responding to and recovering from security incidents.\"},{\"title\":\"Business Continuity Plan\",\"description\":\"A plan for ensuring that business operations can continue during a disaster.\"},{\"title\":\"Disaster Recovery Plan\",\"description\":\"A plan for recovering from a disaster that disrupts business operations.\"},{\"title\":\"Employee Training\",\"description\":\"Training that is provided to employees to help them perform their jobs effectively and safely.\"},{\"title\":\"Security Awareness Training\",\"description\":\"Training that is provided to employees to help them understand and avoid security risks.\"},{\"title\":\"Ethics Training\",\"description\":\"Training that is provided to employees to help them understand and adhere to ethical standards.\"},{\"title\":\"Code of Conduct\",\"description\":\"A set of rules that govern the behavior of employees.\"},{\"title\":\"Whistleblower Policy\",\"description\":\"A policy that protects employees who report wrongdoing.\"},{\"title\":\"Open Door Policy\",\"description\":\"A policy that allows employees to communicate directly with management.\"},{\"title\":\"Employee Handbook\",\"description\":\"A document that contains information about a company's policies and procedures.\"},{\"title\":\"Performance Review\",\"description\":\"A process for evaluating an employee's performance.\"},{\"title\":\"Compensation\",\"description\":\"The money and benefits that an employee receives for their work.\"},{\"title\":\"Benefits\",\"description\":\"Non-wage compensation provided to employees, such as health insurance, paid time off, and retirement plans.\"},{\"title\":\"Recruitment\",\"description\":\"The process of finding and hiring new employees.\"},{\"title\":\"Onboarding\",\"description\":\"The process of integrating new employees into a company.\"},{\"title\":\"Training and Development\",\"description\":\"The process of providing employees with the skills and knowledge they need to succeed in their jobs.\"},{\"title\":\"Succession Planning\",\"description\":\"The process of identifying and developing future leaders.\"},{\"title\":\"Employee Relations\",\"description\":\"The relationship between a company and its employees.\"},{\"title\":\"Labor Relations\",\"description\":\"The relationship between a company and its labor union.\"},{\"title\":\"Collective Bargaining\",\"description\":\"The process of negotiating a contract between a company and its labor union.\"},{\"title\":\"Grievance Procedure\",\"description\":\"A process for resolving disputes between a company and its employees.\"},{\"title\":\"Termination\",\"description\":\"The process of ending an employee's employment.\"},{\"title\":\"Unemployment Insurance\",\"description\":\"A government program that provides benefits to workers who have lost their jobs.\"},{\"title\":\"Workers' Compensation\",\"description\":\"A government program that provides benefits to workers who have been injured on the job.\"},{\"title\":\"Equal Employment Opportunity (EEO)\",\"description\":\"The principle that all individuals should have equal opportunities in employment, regardless of their race, color, religion, sex, national origin, age, disability, or genetic information.\"},{\"title\":\"Affirmative Action\",\"description\":\"A set of policies and practices designed to promote equal employment opportunities for members of historically underrepresented groups.\"},{\"title\":\"Diversity and Inclusion\",\"description\":\"The practice of creating a workplace that is welcoming and inclusive of people from all backgrounds.\"},{\"title\":\"Work-Life Balance\",\"description\":\"The ability to balance work and personal life.\"},{\"title\":\"Employee Engagement\",\"description\":\"The degree to which employees are passionate about their work and committed to their company.\"},{\"title\":\"Employee Satisfaction\",\"description\":\"The degree to which employees are happy with their jobs.\"},{\"title\":\"Employee Turnover\",\"description\":\"The rate at which employees leave a company.\"},{\"title\":\"Absenteeism\",\"description\":\"The practice of employees being absent from work.\"},{\"title\":\"Presenteeism\",\"description\":\"The practice of employees being present at work but not fully engaged or productive.\"},{\"title\":\"Stress\",\"description\":\"A state of mental or emotional strain or tension resulting from adverse or demanding circumstances.\"},{\"title\":\"Burnout\",\"description\":\"A state of emotional, physical, and mental exhaustion caused by prolonged or excessive stress.\"},{\"title\":\"Wellness Program\",\"description\":\"A program that promotes employee health and well-being.\"},{\"title\":\"Employee Assistance Program (EAP)\",\"description\":\"A program that provides confidential counseling and support services to employees.\"},{\"title\":\"Ergonomics\",\"description\":\"The study of people's efficiency in their working environment.\"},{\"title\":\"Occupational Safety and Health Administration (OSHA)\",\"description\":\"A government agency that sets and enforces workplace safety standards.\"},{\"title\":\"Hazard Communication\",\"description\":\"The process of informing employees about the hazards of chemicals in the workplace.\"},{\"title\":\"Personal Protective Equipment (PPE)\",\"description\":\"Equipment that is worn to protect employees from hazards in the workplace.\"},{\"title\":\"Emergency Preparedness\",\"description\":\"The process of preparing for emergencies in the workplace.\"},{\"title\":\"Evacuation Plan\",\"description\":\"A plan for evacuating employees from the workplace in the event of an emergency.\"},{\"title\":\"First Aid\",\"description\":\"The provision of immediate care to an injured or ill person.\"},{\"title\":\"Cardiopulmonary Resuscitation (CPR)\",\"description\":\"A life-saving technique that is used to revive someone who has stopped breathing or whose heart has stopped beating.\"},{\"title\":\"Automated External Defibrillator (AED)\",\"description\":\"A portable device that delivers an electric shock to the heart to restore a normal heart rhythm.\"},{\"title\":\"Workplace Violence\",\"description\":\"Violence or the threat of violence against workers in the workplace.\"},{\"title\":\"Active Shooter\",\"description\":\"A person who is actively engaged in killing or attempting to kill people in a confined and populated area.\"},{\"title\":\"Security Guard\",\"description\":\"A person who is employed to protect property and people.\"},{\"title\":\"Surveillance Camera\",\"description\":\"A camera that is used to monitor activity in a particular area.\"},{\"title\":\"Access Control\",\"description\":\"The process of restricting access to a particular area or resource.\"},{\"title\":\"Background Check\",\"description\":\"A process of verifying a person's identity and criminal history.\"},{\"title\":\"Drug Testing\",\"description\":\"The process of testing employees for the presence of drugs.\"},{\"title\":\"Alcohol Testing\",\"description\":\"The process of testing employees for the presence of alcohol.\"},{\"title\":\"Workplace Investigation\",\"description\":\"An investigation into an incident that has occurred in the workplace.\"},{\"title\":\"Disciplinary Action\",\"description\":\"Action that is taken against an employee for violating company policy.\"},{\"title\":\"Termination\",\"description\":\"The process of ending an employee's employment.\"},{\"title\":\"Legal Compliance\",\"description\":\"The process of adhering to laws, regulations, and ethical standards.\"},{\"title\":\"Risk Management\",\"description\":\"The process of identifying, assessing, and mitigating risks.\"},{\"title\":\"Insurance\",\"description\":\"A contract whereby one party (the insurer) undertakes to indemnify another party (the insured) against the risk of specified loss or damage.\"},{\"title\":\"Workers' Compensation\",\"description\":\"A government program that provides benefits to workers who have been injured on the job.\"},{\"title\":\"Unemployment Insurance\",\"description\":\"A government program that provides benefits to workers who have lost their jobs.\"},{\"title\":\"Social Security\",\"description\":\"A government program that provides benefits to retirees, disabled workers, and survivors of deceased workers.\"},{\"title\":\"Medicare\",\"description\":\"A government program that provides health insurance to people age 65 and older and to certain disabled people.\"},{\"title\":\"Medicaid\",\"description\":\"A government program that provides health insurance to low-income people.\"},{\"title\":\"Affordable Care Act (ACA)\",\"description\":\"A United States federal law that expands access to health insurance.\"},{\"title\":\"Employee Retirement Income Security Act (ERISA)\",\"description\":\"A United States federal law that sets standards for employee benefit plans.\"},{\"title\":\"Family and Medical Leave Act (FMLA)\",\"description\":\"A United States federal law that allows employees to take unpaid leave for family and medical reasons.\"},{\"title\":\"Fair Labor Standards Act (FLSA)\",\"description\":\"A United States federal law that sets minimum wage, overtime pay, and child labor standards.\"},{\"title\":\"National Labor Relations Act (NLRA)\",\"description\":\"A United States federal law that protects the rights of workers to form unions and bargain collectively.\"},{\"title\":\"Title VII of the Civil Rights Act of 1964\",\"description\":\"A United States federal law that prohibits discrimination in employment based on race, color, religion, sex, or national origin.\"},{\"title\":\"Age Discrimination in Employment Act (ADEA)\",\"description\":\"A United States federal law that protects workers age 40 and older from age discrimination.\"},{\"title\":\"Americans with Disabilities Act (ADA)\",\"description\":\"A United States federal law that prohibits discrimination against people with disabilities.\"},{\"title\":\"Genetic Information Nondiscrimination Act (GINA)\",\"description\":\"A United States federal law that prohibits discrimination in employment based on genetic information.\"},{\"title\":\"Immigration Reform and Control Act (IRCA)\",\"description\":\"A United States federal law that prohibits employers from knowingly hiring undocumented workers.\"}],\"dataset_tables\":[{\"name\":\"ai-learning-agents.thelook.events\",\"overview\":\"This table stores records of user interactions and activities on a website or application. It captures various details associated with each event. The data includes information about the user, the event itself, and the context in which it occurred. This allows for analysis of user behavior, tracking of key performance indicators, and identification of trends. The table supports investigations into user journeys and event patterns.\",\"fields\":[{\"name\":\"id\",\"description\":\"Unique identifier for the event.\"},{\"name\":\"traffic_source\",\"description\":\"The origin or source of the website traffic.\"},{\"name\":\"city\",\"description\":\"The city from which the event originated.\"},{\"name\":\"uri\",\"description\":\"The specific web address or resource being accessed.\"},{\"name\":\"user_id\",\"description\":\"Unique identifier for the user.\"},{\"name\":\"event_type\",\"description\":\"The category or type of user event that occurred.\"},{\"name\":\"session_id\",\"description\":\"Unique identifier for the user's session.\"},{\"name\":\"created_at\",\"description\":\"Timestamp indicating when the event occurred.\"},{\"name\":\"ip_address\",\"description\":\"The IP address of the user who triggered the event.\"},{\"name\":\"postal_code\",\"description\":\"The postal code associated with the event's location.\"},{\"name\":\"sequence_number\",\"description\":\"The order of the event within a user session.\"},{\"name\":\"browser\",\"description\":\"The web browser used by the user.\"},{\"name\":\"state\",\"description\":\"The state or status associated with the event.\"}],\"queries\":[{\"sql\":\"SELECT traffic_source, COUNT(DISTINCT user_id) AS unique_users FROM `thelook.events` WHERE sequence_number > 5 GROUP BY traffic_source ORDER BY unique_users DESC;\",\"description\":\"Identify the traffic sources with the highest number of unique users who have a sequence number greater than 5, indicating highly engaged users from those sources.\"},{\"sql\":\"SELECT browser, STDDEV_POP(sequence_number) AS std_dev_sequence_number FROM `thelook.events` GROUP BY browser ORDER BY std_dev_sequence_number DESC;\",\"description\":\"Identify the browsers with the highest standard deviation in event sequence numbers, indicating variability in user behavior within those browsers.\"},{\"sql\":\"SELECT city, COUNT(DISTINCT user_id) AS unique_users, AVG(sequence_number) AS avg_sequence_number FROM `thelook.events` GROUP BY city ORDER BY unique_users DESC LIMIT 5;\",\"description\":\"Identify the top 5 cities with the highest number of unique users and their corresponding average event sequence number.\"},{\"sql\":\"SELECT postal_code, COUNT(*) AS event_count, AVG(sequence_number) AS avg_sequence_number FROM `thelook.events` GROUP BY postal_code ORDER BY event_count DESC LIMIT 3;\",\"description\":\"Identify the top 3 postal codes with the highest number of events, and calculate the average sequence number for events originating from those postal codes.\"},{\"sql\":\"SELECT browser, AVG(sequence_number) AS avg_sequence_number FROM `thelook.events` GROUP BY browser;\",\"description\":\"Calculate the average sequence number of events for each user, grouped by browser type, to understand user engagement patterns across different browsers.\"},{\"sql\":\"SELECT traffic_source, AVG(event_count) AS avg_events_per_session FROM (SELECT traffic_source, session_id, COUNT(*) AS event_count FROM `thelook.events` GROUP BY traffic_source, session_id) GROUP BY traffic_source;\",\"description\":\"Calculate the average number of events per session, grouped by traffic source, to understand user engagement levels from different sources.\"},{\"sql\":\"SELECT browser, traffic_source, COUNT(*) AS event_count, COUNT(*) * 100 / (SELECT COUNT(*) FROM `thelook.events`) AS percentage FROM `thelook.events` GROUP BY browser, traffic_source ORDER BY event_count DESC;\",\"description\":\"Calculate the number of events for each browser, traffic_source combination, and then determine the percentage of total events each combination represents.\"},{\"sql\":\"SELECT EXTRACT(HOUR FROM created_at) AS hour_of_day, AVG(sequence_number) AS avg_sequence_number FROM `thelook.events` GROUP BY hour_of_day ORDER BY hour_of_day;\",\"description\":\"Calculate the average sequence number for each user, grouped by the hour of the day the event occurred, to identify peak activity times.\"},{\"sql\":\"SELECT browser, APPROX_QUANTILES(sequence_number, 100)[OFFSET(90)] AS percentile_90 FROM `thelook.events` GROUP BY browser;\",\"description\":\"Calculate the 90th percentile of sequence numbers for each browser, providing a measure of high engagement levels within each browser.\"},{\"sql\":\"SELECT\\n  traffic_source,\\n  VAR_POP(sequence_number) AS sequence_number_variance\\nFROM\\n  `thelook.events`\\nGROUP BY\\n  traffic_source;\",\"description\":\"Calculate the population variance of the sequence number of events for each traffic source to understand the spread of user interaction within different traffic channels.\"},{\"sql\":\"SELECT user_id, APPROX_QUANTILES(sequence_number, 2)[OFFSET(1)] AS median_sequence_number FROM `thelook.events` GROUP BY user_id;\",\"description\":\"Calculate the median sequence number for each user, providing a robust measure of user engagement that is less sensitive to outliers.\"},{\"sql\":\"SELECT\\n  city,\\n  AVG(events_per_user) AS avg_events_per_user\\nFROM (\\n  SELECT\\n    city,\\n    user_id,\\n    COUNT(*) AS events_per_user\\n  FROM\\n    `thelook.events`\\n  GROUP BY\\n    city,\\n    user_id\\n)\\nGROUP BY\\n  city\\nORDER BY\\n  avg_events_per_user DESC\\nLIMIT 5;\",\"description\":\"Identify the top 5 cities with the highest average number of events per user to find the most active locations.\"},{\"sql\":\"SELECT EXTRACT(DAYOFWEEK FROM created_at) AS day_of_week, COUNT(*) * 100 / (SELECT COUNT(*) FROM `thelook.events`) AS percentage FROM `thelook.events` GROUP BY day_of_week ORDER BY day_of_week;\",\"description\":\"Calculate the percentage of events that occur on each day of the week, to identify the busiest days for website traffic.\"},{\"sql\":\"SELECT user_id, MIN(created_at) AS first_event, MAX(created_at) AS last_event FROM `thelook.events` GROUP BY user_id;\",\"description\":\"Find the minimum and maximum created_at timestamps for each user, to determine the duration of their activity on the platform.\"},{\"sql\":\"SELECT\\n  browser,\\n  AVG(sequence_number) AS avg_sequence_number\\nFROM\\n  `thelook.events`\\nGROUP BY\\n  browser\\nORDER BY\\n  avg_sequence_number DESC\\nLIMIT 1;\",\"description\":\"Find the browser with the maximum average sequence number to identify the browser with the most engaged users.\"},{\"sql\":\"SELECT\\n  AVG(event_count) AS avg_events_per_session,\\n  STDDEV_SAMP(event_count) AS stddev_events_per_session\\nFROM (\\n  SELECT\\n    session_id,\\n    COUNT(*) AS event_count\\n  FROM\\n    `thelook.events`\\n  GROUP BY\\n    session_id\\n);\",\"description\":\"Calculate the average number of events per session and the standard deviation to understand session activity.\"},{\"sql\":\"SELECT traffic_source, COUNT(*) * 100 / (SELECT COUNT(*) FROM `thelook.events`) AS percentage FROM `thelook.events` GROUP BY traffic_source;\",\"description\":\"Determine the percentage of events originating from each traffic source, providing insights into the effectiveness of different marketing channels.\"},{\"sql\":\"SELECT browser, event_type, COUNT(*) AS event_count, ROW_NUMBER() OVER(PARTITION BY browser ORDER BY COUNT(*) DESC) AS rn FROM `thelook.events` GROUP BY browser, event_type QUALIFY rn = 1;\",\"description\":\"Determine the most common event type for each browser, providing insights into how different browsers are used on the platform.\"},{\"sql\":\"SELECT CORR(sequence_number, user_id) FROM `thelook.events`;\",\"description\":\"Calculate the correlation between the sequence number and user ID to understand if there's a relationship between user ID and event sequence within sessions.\"},{\"sql\":\"SELECT state, event_type, COUNT(*) AS event_count FROM `thelook.events` GROUP BY state, event_type ORDER BY state, event_count DESC;\",\"description\":\"Determine the distribution of event types across different states, providing insights into regional variations in user behavior.\"},{\"sql\":\"SELECT city, AVG(sequence_number) AS avg_sequence_number FROM `thelook.events` WHERE user_id > 100 GROUP BY city ORDER BY avg_sequence_number DESC LIMIT 5;\",\"description\":\"Identify the top 5 cities with the highest average event sequence number for users with user IDs greater than 100.\"},{\"sql\":\"SELECT browser, traffic_source, AVG(event_count) AS avg_events_per_user FROM (SELECT browser, traffic_source, user_id, COUNT(*) AS event_count FROM `thelook.events` GROUP BY browser, traffic_source, user_id) GROUP BY browser, traffic_source;\",\"description\":\"Determine the average number of events per user, broken down by browser and traffic source, to understand user engagement across different channels and browsers.\"},{\"sql\":\"SELECT state, event_type, AVG(sequence_number) AS avg_sequence_number FROM `thelook.events` GROUP BY state, event_type;\",\"description\":\"Determine the average sequence number for each event type, grouped by state, to understand how user engagement varies across different event types and regions.\"},{\"sql\":\"SELECT browser, uri, COUNT(*) AS uri_count, ROW_NUMBER() OVER(PARTITION BY browser ORDER BY COUNT(*) DESC) AS rn FROM `thelook.events` GROUP BY browser, uri QUALIFY rn <= 3;\",\"description\":\"Determine the top 3 most frequent URI values for each browser, providing insights into the most popular pages visited by users of different browsers.\"},{\"sql\":\"SELECT\\n  CORR(sequence_number, user_id) AS correlation_coefficient\\nFROM\\n  `thelook.events`;\",\"description\":\"Calculate the correlation between the sequence number of an event within a session and the user ID to understand if user behavior changes over the course of a session.\"},{\"sql\":\"SELECT\\n  browser,\\n  AVG(sequence_number) AS avg_sequence_number,\\n  STDDEV_SAMP(sequence_number) AS stddev_sequence_number\\nFROM\\n  `thelook.events`\\nGROUP BY\\n  browser;\",\"description\":\"Determine the average sequence number of events for each browser and calculate the standard deviation to understand the consistency of user interaction across different browsers.\"},{\"sql\":\"SELECT\\n  COVAR_SAMP(user_id, sequence_number) AS covariance\\nFROM\\n  `thelook.events`;\",\"description\":\"Calculate the sample covariance between user ID and sequence number to understand the relationship between user and event order within a session.\"},{\"sql\":\"SELECT\\n  traffic_source,\\n  AVG(sequence_number) AS avg_sequence_number\\nFROM\\n  `thelook.events`\\nGROUP BY\\n  traffic_source\\nORDER BY\\n  avg_sequence_number ASC\\nLIMIT 1;\",\"description\":\"Determine the traffic source with the minimum average sequence number to identify the least engaged traffic channel.\"}],\"ddl\":\"CREATE TABLE `ai-learning-agents.thelook.events`\\n(\\n  id INT64 OPTIONS(description=\\\"Unique identifier for the event.\\\"),\\n  user_id INT64 OPTIONS(description=\\\"Unique identifier for the user.\\\"),\\n  sequence_number INT64 OPTIONS(description=\\\"The order of the event within a user session.\\\"),\\n  session_id STRING OPTIONS(description=\\\"Unique identifier for the user's session.\\\"),\\n  created_at TIMESTAMP OPTIONS(description=\\\"Timestamp indicating when the event occurred.\\\"),\\n  ip_address STRING OPTIONS(description=\\\"The IP address of the user who triggered the event.\\\"),\\n  city STRING OPTIONS(description=\\\"The city from which the event originated.\\\"),\\n  state STRING OPTIONS(description=\\\"The state or status associated with the event.\\\"),\\n  postal_code STRING OPTIONS(description=\\\"The postal code associated with the event's location.\\\"),\\n  browser STRING OPTIONS(description=\\\"The web browser used by the user.\\\"),\\n  traffic_source STRING OPTIONS(description=\\\"The origin or source of the website traffic.\\\"),\\n  uri STRING OPTIONS(description=\\\"The specific web address or resource being accessed.\\\"),\\n  event_type STRING OPTIONS(description=\\\"The category or type of user event that occurred.\\\")\\n)\\nOPTIONS(\\n  description=\\\"This table stores records of user activity on a website or application. It captures various events triggered by user interactions. The data includes details about the user's location, session, and browser. This information is used to understand user behavior and track website traffic.\\\",\\n  labels=[(\\\"dataplex-data-documentation-published-location\\\", \\\"us-central1\\\"), (\\\"dataplex-dp-published-scan\\\", \\\"ab20d79d1-33b8-4810-b06f-14a5280cbb00\\\"), (\\\"dataplex-dp-published-project\\\", \\\"ai-learning-agents\\\"), (\\\"dataplex-dp-published-location\\\", \\\"us-central1\\\"), (\\\"dataplex-data-documentation-published-project\\\", \\\"ai-learning-agents\\\"), (\\\"dataplex-data-documentation-published-scan\\\", \\\"a5f1f8396-cfad-4bc8-a25d-187c34201858\\\")]\\n);\",\"row_count\":2425480,\"size_bytes\":385142492},{\"name\":\"ai-learning-agents.thelook.distribution_centers\",\"overview\":\"This table stores information about the locations of distribution centers. It provides a central repository for managing distribution center data. The table facilitates spatial analysis and mapping of these centers. It supports the identification and management of distribution center locations.\",\"fields\":[{\"name\":\"name\",\"description\":\"Name of the distribution center.\"},{\"name\":\"latitude\",\"description\":\"Latitude coordinate of the distribution center.\"},{\"name\":\"distribution_center_geom\",\"description\":\"Geographical location of the distribution center.\"},{\"name\":\"longitude\",\"description\":\"Longitude coordinate of the distribution center.\"},{\"name\":\"id\",\"description\":\"Unique identifier for the distribution center.\"}],\"queries\":[{\"sql\":\"SELECT `name`, (SELECT AVG(latitude) FROM `thelook.distribution_centers`) - (SELECT AVG(latitude) FROM `thelook.distribution_centers` WHERE id != a.id) AS latitude_difference FROM `thelook.distribution_centers` a ORDER BY latitude_difference DESC LIMIT 1;\",\"description\":\"Find the distribution center that, if removed, would result in the largest change in the average latitude of all remaining distribution centers.\"},{\"sql\":\"WITH distances AS (\\n  SELECT\\n    a.id,\\n    MIN(ST_Distance(a.distribution_center_geom, b.distribution_center_geom)) AS min_distance\\n  FROM\\n    `thelook.distribution_centers` AS a\\n  JOIN\\n    `thelook.distribution_centers` AS b\\n  ON a.id != b.id\\n  GROUP BY\\n    a.id\\n)\\nSELECT\\n  id,\\n  min_distance\\nFROM\\n  distances\\nWHERE\\n  min_distance > (\\n    SELECT\\n      AVG(min_distance) + 2 * STDDEV(min_distance)\\n    FROM\\n      distances);\",\"description\":\"Find distribution centers whose distance to the nearest other distribution center is an outlier compared to the distances between all centers.\"},{\"sql\":\"SELECT\\n  a.id AS id1,\\n  b.id AS id2,\\n  ST_Distance(a.distribution_center_geom, b.distribution_center_geom) AS distance\\nFROM\\n  `thelook.distribution_centers` AS a\\nJOIN\\n  `thelook.distribution_centers` AS b\\nON a.id < b.id\\nWHERE\\n  ST_Distance(a.distribution_center_geom, b.distribution_center_geom) < (\\n    SELECT\\n      APPROX_QUANTILES(ST_Distance(c.distribution_center_geom, d.distribution_center_geom), 100)[OFFSET(5)]\\n    FROM\\n      `thelook.distribution_centers` AS c\\n    JOIN\\n      `thelook.distribution_centers` AS d\\n    ON c.id < d.id)\\nLIMIT 100;\",\"description\":\"Identify distribution centers that are unusually close to each other, suggesting potential data duplication or errors.\"},{\"sql\":\"WITH center_stats AS (\\n  SELECT\\n    ST_GeogPoint(AVG(longitude), AVG(latitude)) AS avg_location\\n  FROM\\n    `thelook.distribution_centers`\\n),\\n  distances AS (\\n  SELECT\\n    id,\\n    ST_Distance(distribution_center_geom, (\\n      SELECT\\n        avg_location\\n      FROM\\n        center_stats)) AS distance_from_average\\n  FROM\\n    `thelook.distribution_centers`\\n)\\nSELECT\\n  id,\\n  distance_from_average\\nFROM\\n  distances\\nWHERE\\n  distance_from_average > (\\n    SELECT\\n      AVG(distance_from_average) + 2 * STDDEV(distance_from_average)\\n    FROM\\n      distances);\",\"description\":\"Identify distribution centers that are geographical outliers based on distance from the average center location.\"},{\"sql\":\"WITH lat_stats AS (\\n  SELECT\\n    APPROX_QUANTILES(latitude, 100)[OFFSET(50)] AS median_latitude,\\n    STDDEV(latitude) AS stddev_latitude\\n  FROM\\n    `thelook.distribution_centers`\\n)\\nSELECT\\n  id,\\n  latitude\\nFROM\\n  `thelook.distribution_centers`\\nCROSS JOIN\\n  lat_stats\\nWHERE\\n  ABS(latitude - median_latitude) > 2 * stddev_latitude;\",\"description\":\"Find distribution centers with latitudes significantly deviating from the median latitude.\"},{\"sql\":\"SELECT CORR(latitude, longitude) FROM `thelook.distribution_centers`;\",\"description\":\"Calculate the correlation between the latitude and longitude of the distribution centers.\"},{\"sql\":\"SELECT CORR(latitude, longitude) AS lat_long_correlation FROM `thelook.distribution_centers`;\",\"description\":\"Calculate the Pearson correlation coefficient between latitude and longitude to identify any linear relationship in distribution center placement.\"},{\"sql\":\"WITH longitude_quartiles AS (\\n  SELECT\\n    APPROX_QUANTILES(longitude, 4) AS longitude_quantiles\\n  FROM\\n    `thelook.distribution_centers`\\n)\\nSELECT\\n  id,\\n  longitude\\nFROM\\n  `thelook.distribution_centers`\\nCROSS JOIN\\n  longitude_quartiles\\nWHERE\\n  longitude < longitude_quantiles[OFFSET(1)]\\n  OR longitude > longitude_quantiles[OFFSET(3)];\",\"description\":\"Identify distribution centers whose longitude is outside the interquartile range.\"},{\"sql\":\"SELECT `name` FROM `thelook.distribution_centers` WHERE latitude < (SELECT APPROX_QUANTILES(latitude, 4)[OFFSET(1)] FROM `thelook.distribution_centers`) - 1.5 * ((SELECT APPROX_QUANTILES(latitude, 4)[OFFSET(3)] FROM `thelook.distribution_centers`) - (SELECT APPROX_QUANTILES(latitude, 4)[OFFSET(1)] FROM `thelook.distribution_centers`)) OR latitude > (SELECT APPROX_QUANTILES(latitude, 4)[OFFSET(3)] FROM `thelook.distribution_centers`) + 1.5 * ((SELECT APPROX_QUANTILES(latitude, 4)[OFFSET(3)] FROM `thelook.distribution_centers`) - (SELECT APPROX_QUANTILES(latitude, 4)[OFFSET(1)] FROM `thelook.distribution_centers`));\",\"description\":\"Find the distribution centers that are outliers based on their latitude, using the interquartile range (IQR) method.\"},{\"sql\":\"SELECT `name` FROM `thelook.distribution_centers` WHERE latitude > (SELECT AVG(latitude) + STDDEV_POP(latitude) FROM `thelook.distribution_centers`);\",\"description\":\"Identify distribution centers that have a latitude greater than the average latitude plus one standard deviation.\"},{\"sql\":\"SELECT `name`, ST_DISTANCE(distribution_center_geom, (SELECT ST_GEOGPOINT(AVG(longitude), AVG(latitude)) FROM `thelook.distribution_centers`)) as distance_from_center FROM `thelook.distribution_centers`;\",\"description\":\"Calculate the distance of each distribution center from the geographic center of all distribution centers.\"},{\"sql\":\"SELECT a.`name`, AVG(ST_DISTANCE(a.distribution_center_geom, b.distribution_center_geom)) AS avg_distance FROM `thelook.distribution_centers` a JOIN `thelook.distribution_centers` b ON a.id != b.id GROUP BY a.`name`;\",\"description\":\"Calculate the average distance of each distribution center to all other distribution centers.\"},{\"sql\":\"SELECT ST_AREA(ST_CONVEXHULL(ST_UNION_AGG(distribution_center_geom))) FROM `thelook.distribution_centers`;\",\"description\":\"Calculate the area of the convex hull containing all distribution centers.\"},{\"sql\":\"SELECT STDDEV_POP(latitude) AS latitude_std_dev, STDDEV_POP(longitude) AS longitude_std_dev FROM `thelook.distribution_centers`;\",\"description\":\"Calculate the population standard deviation of latitude and longitude to understand the geographical spread of distribution centers.\"},{\"sql\":\"SELECT VAR_POP(latitude) AS latitude_variance, VAR_POP(longitude) AS longitude_variance FROM `thelook.distribution_centers`;\",\"description\":\"Calculate the population variance of latitude and longitude to understand the spread of distribution centers.\"},{\"sql\":\"SELECT COVAR_SAMP(latitude, longitude) AS lat_long_covariance FROM `thelook.distribution_centers`;\",\"description\":\"Calculate the sample covariance between latitude and longitude of the distribution centers.\"},{\"sql\":\"SELECT STDDEV_POP(latitude) FROM `thelook.distribution_centers`;\",\"description\":\"Calculate the standard deviation of the latitudes of all distribution centers.\"},{\"sql\":\"SELECT a.`name` AS dc1, b.`name` AS dc2 FROM `thelook.distribution_centers` a JOIN `thelook.distribution_centers` b ON ST_DWITHIN(a.distribution_center_geom, b.distribution_center_geom, 5000) WHERE a.id != b.id;\",\"description\":\"Identify distribution centers that are within a 5km radius of each other.\"},{\"sql\":\"SELECT\\n  name,\\n  latitude,\\n  longitude,\\n  AVG(latitude) OVER (ORDER BY longitude ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING) AS avg_latitude_nearby\\nFROM `thelook.distribution_centers`;\",\"description\":\"Calculate the average latitude of the 3 closest distribution centers based on longitude.\"},{\"sql\":\"WITH avg_latitude AS (\\n  SELECT AVG(latitude) AS avg_lat FROM `thelook.distribution_centers`\\n)\\nSELECT\\n  name,\\n  latitude,\\n  longitude,\\n  latitude - (SELECT avg_lat FROM avg_latitude) AS latitude_diff_from_avg\\nFROM `thelook.distribution_centers`;\",\"description\":\"Calculate the difference in latitude between each distribution center and the average latitude of all distribution centers.\"},{\"sql\":\"WITH min_latitude AS (\\n  SELECT MIN(latitude) AS min_lat FROM `thelook.distribution_centers`\\n)\\nSELECT\\n  name,\\n  latitude,\\n  longitude,\\n  SQRT(POW((latitude - (SELECT min_lat FROM min_latitude)), 2) + POW(longitude, 2)) AS distance_from_min_latitude\\nFROM `thelook.distribution_centers`;\",\"description\":\"Calculate the distance of each distribution center from the distribution center with the lowest latitude.\"},{\"sql\":\"SELECT `name` FROM `thelook.distribution_centers` ORDER BY ST_DISTANCE(distribution_center_geom, ST_GEOGPOINT(-118.2437, 34.0522)) ASC LIMIT 1;\",\"description\":\"Find the distribution center closest to a specific point (e.g., latitude 34.0522, longitude -118.2437).\"},{\"sql\":\"SELECT\\n  name,\\n  latitude,\\n  longitude,\\n  ABS(latitude - 34.0522) AS latitude_difference\\nFROM `thelook.distribution_centers`\\nORDER BY latitude_difference\\nLIMIT 1;\",\"description\":\"Find the distribution center with the latitude closest to a specific latitude value (e.g., 34.0522).\"},{\"sql\":\"SELECT `name` FROM `thelook.distribution_centers` ORDER BY ABS(latitude - (SELECT AVG(latitude) FROM `thelook.distribution_centers`)) LIMIT 1;\",\"description\":\"Find the distribution center with the latitude closest to the average latitude.\"},{\"sql\":\"SELECT `name` FROM `thelook.distribution_centers` ORDER BY ABS(latitude - (SELECT AVG(latitude) FROM `thelook.distribution_centers`)) LIMIT 1;\",\"description\":\"Find the distribution center with the latitude closest to the average latitude.\"},{\"sql\":\"SELECT\\n  name,\\n  latitude,\\n  longitude,\\n  SUM(latitude) OVER (ORDER BY longitude) AS cumulative_latitude\\nFROM `thelook.distribution_centers`;\",\"description\":\"Calculate the cumulative sum of latitude values, ordered by longitude.\"},{\"sql\":\"SELECT\\n  name,\\n  latitude,\\n  longitude,\\n  LEAD(latitude) OVER (ORDER BY longitude) AS next_latitude\\nFROM `thelook.distribution_centers`;\",\"description\":\"Get the latitude of the next distribution center when ordered by longitude.\"},{\"sql\":\"SELECT APPROX_QUANTILES(latitude, 2)[OFFSET(1)] AS median_latitude, APPROX_QUANTILES(longitude, 2)[OFFSET(1)] AS median_longitude FROM `thelook.distribution_centers`;\",\"description\":\"Calculate the median latitude and longitude of all distribution centers.\"},{\"sql\":\"SELECT AVG(latitude) AS avg_latitude, AVG(longitude) AS avg_longitude FROM `thelook.distribution_centers`;\",\"description\":\"Calculate the average latitude and longitude of all distribution centers.\"},{\"sql\":\"SELECT\\n  name,\\n  latitude,\\n  longitude,\\n  RANK() OVER (ORDER BY latitude) AS latitude_rank\\nFROM `thelook.distribution_centers`;\",\"description\":\"Rank distribution centers based on their latitude.\"}],\"ddl\":\"CREATE TABLE `ai-learning-agents.thelook.distribution_centers`\\n(\\n  id INT64 OPTIONS(description=\\\"Unique identifier for the distribution center.\\\"),\\n  name STRING OPTIONS(description=\\\"Name of the distribution center.\\\"),\\n  latitude FLOAT64 OPTIONS(description=\\\"Latitude coordinate of the distribution center.\\\"),\\n  longitude FLOAT64 OPTIONS(description=\\\"Longitude coordinate of the distribution center.\\\"),\\n  distribution_center_geom GEOGRAPHY OPTIONS(description=\\\"Geographical location of the distribution center.\\\")\\n)\\nOPTIONS(\\n  description=\\\"This table stores information about distribution centers. It includes location data for each center. The data allows for spatial analysis and mapping. It also supports identifying and managing distribution center locations.\\\",\\n  labels=[(\\\"dataplex-data-documentation-published-location\\\", \\\"us-central1\\\"), (\\\"dataplex-data-documentation-published-project\\\", \\\"ai-learning-agents\\\"), (\\\"dataplex-data-documentation-published-scan\\\", \\\"add9d8061-6552-4d49-81bc-2bc3943a5b79\\\"), (\\\"dataplex-dp-published-project\\\", \\\"ai-learning-agents\\\"), (\\\"dataplex-dp-published-location\\\", \\\"us-central1\\\"), (\\\"dataplex-dp-published-scan\\\", \\\"a2886da71-0f35-4192-8742-bd9b1ffc4ddd\\\")]\\n);\",\"row_count\":10,\"size_bytes\":809},{\"name\":\"ai-learning-agents.thelook.inventory_items\",\"overview\":\"This table tracks the inventory of products. It records details about each item, including its cost and retail price. The table also associates each item with a specific product and distribution center. This allows for analysis of inventory levels and product performance.\",\"fields\":[{\"name\":\"id\",\"description\":\"Unique identifier for the inventory item.\"},{\"name\":\"sold_at\",\"description\":\"Timestamp indicating when the inventory item was sold.\"},{\"name\":\"product_brand\",\"description\":\"Brand of the product.\"},{\"name\":\"product_category\",\"description\":\"Category of the product.\"},{\"name\":\"created_at\",\"description\":\"Timestamp indicating when the inventory item was created.\"},{\"name\":\"product_distribution_center_id\",\"description\":\"Identifier for the distribution center where the product is located.\"},{\"name\":\"product_sku\",\"description\":\"Stock keeping unit for the product.\"},{\"name\":\"cost\",\"description\":\"Cost of the inventory item.\"},{\"name\":\"product_name\",\"description\":\"Name of the product.\"},{\"name\":\"product_retail_price\",\"description\":\"Retail price of the product.\"},{\"name\":\"product_id\",\"description\":\"Identifier for the product.\"},{\"name\":\"product_department\",\"description\":\"Department the product belongs to.\"}],\"queries\":[{\"sql\":\"SELECT\\n    product_distribution_center_id,\\n    AVG(product_retail_price) AS avg_retail_price\\n  FROM\\n    `thelook.inventory_items`\\n  GROUP BY\\n    product_distribution_center_id\\n  HAVING\\n    AVG(product_retail_price) < (SELECT AVG(product_retail_price) FROM `thelook.inventory_items`) * 0.5;\",\"description\":\"Find distribution centers with unusually low average product retail price compared to the overall average, indicating potential clearance events or pricing discrepancies.\"},{\"sql\":\"SELECT product_category FROM `thelook.inventory_items` GROUP BY product_category HAVING AVG(cost) > AVG(product_retail_price);\",\"description\":\"Identify product categories where the average cost is greater than the average retail price.\"},{\"sql\":\"SELECT product_distribution_center_id, CORR(product_retail_price, cost) AS price_cost_correlation FROM `thelook.inventory_items` GROUP BY product_distribution_center_id;\",\"description\":\"Calculate the correlation between product retail price and cost for each product distribution center.\"},{\"sql\":\"SELECT\\n  product_category,\\n  COVAR_POP(product_retail_price, cost) AS price_cost_covariance\\nFROM\\n  `thelook.inventory_items`\\nWHERE created_at BETWEEN TIMESTAMP('2022-01-01 00:00:00 UTC') AND TIMESTAMP('2022-12-31 23:59:59 UTC')\\nGROUP BY\\n  product_category;\",\"description\":\"Calculate the covariance between product retail price and cost for each product category.\"},{\"sql\":\"SELECT\\n  CORR(product_retail_price, cost) AS price_cost_correlation\\nFROM\\n  `thelook.inventory_items`\\nWHERE created_at BETWEEN TIMESTAMP('2022-01-01 00:00:00 UTC') AND TIMESTAMP('2022-12-31 23:59:59 UTC');\",\"description\":\"Calculate the correlation between product retail price and cost to understand pricing strategy.\"},{\"sql\":\"SELECT product_category, AVG(CASE WHEN sold_at IS NOT NULL THEN product_retail_price ELSE NULL END) - AVG(CASE WHEN sold_at IS NULL THEN product_retail_price ELSE NULL END) AS price_difference FROM `thelook.inventory_items` GROUP BY product_category;\",\"description\":\"Calculate the difference between the average retail price of sold and unsold items for each product category.\"},{\"sql\":\"WITH PricePercentiles AS (SELECT APPROX_QUANTILES(product_retail_price, 100)[OFFSET(75)] AS percentile_75 FROM `thelook.inventory_items`) SELECT i.product_distribution_center_id, SUM(i.cost) AS total_cost FROM `thelook.inventory_items` i, PricePercentiles p WHERE i.product_retail_price > p.percentile_75 GROUP BY i.product_distribution_center_id;\",\"description\":\"Calculate the total cost for each product distribution center, considering only products with a retail price above the 75th percentile of all retail prices.\"},{\"sql\":\"WITH AvgPrices AS (SELECT product_distribution_center_id, product_department, AVG(product_retail_price) AS avg_price FROM `thelook.inventory_items` WHERE EXTRACT(YEAR FROM created_at) = 2021 GROUP BY 1, 2) SELECT product_department, product_distribution_center_id, avg_price FROM (SELECT product_department, product_distribution_center_id, avg_price, ROW_NUMBER() OVER (PARTITION BY product_department ORDER BY avg_price DESC) AS rn FROM AvgPrices) WHERE rn = 1 ORDER BY product_department;\",\"description\":\"Find the product distribution center with the maximum average product retail price for each product department in the year 2021.\"},{\"sql\":\"SELECT product_department, SUM(cost) AS total_cost FROM `thelook.inventory_items` WHERE created_at BETWEEN TIMESTAMP('2022-10-01 00:00:00') AND TIMESTAMP('2022-12-31 23:59:59') GROUP BY 1 ORDER BY 2 DESC LIMIT 5;\",\"description\":\"Identify the top 5 product departments with the highest total cost of inventory items created in the last quarter of 2022.\"},{\"sql\":\"SELECT\\n  product_distribution_center_id,\\n  VAR_SAMP(product_retail_price) AS price_variance\\nFROM\\n  `thelook.inventory_items`\\nWHERE created_at BETWEEN TIMESTAMP('2022-01-01 00:00:00 UTC') AND TIMESTAMP('2022-12-31 23:59:59 UTC')\\nGROUP BY\\n  product_distribution_center_id\\nORDER BY\\n  price_variance DESC\\nLIMIT 1;\",\"description\":\"Find the product distribution center with the highest variance in product retail price.\"},{\"sql\":\"SELECT product_department, created_at, AVG(cost) OVER (PARTITION BY product_department ORDER BY created_at ASC ROWS BETWEEN 6 PRECEDING AND CURRENT ROW) AS moving_average_cost FROM `thelook.inventory_items`;\",\"description\":\"Calculate the moving average of the cost over a 7-day window, partitioned by product department, ordered by the creation date.\"},{\"sql\":\"SELECT sold_at, product_category, cost, SUM(cost) OVER (PARTITION BY product_category ORDER BY sold_at) AS cumulative_cost FROM `thelook.inventory_items` WHERE sold_at BETWEEN TIMESTAMP('2019-01-01 00:00:00') AND TIMESTAMP('2022-12-31 23:59:59') ORDER BY sold_at, product_category;\",\"description\":\"Calculate the cumulative sum of the cost of items sold over time, partitioned by product category.\"},{\"sql\":\"SELECT product_distribution_center_id FROM `thelook.inventory_items` GROUP BY product_distribution_center_id HAVING COUNT(DISTINCT product_category) > (SELECT AVG(category_count) FROM (SELECT product_distribution_center_id, COUNT(DISTINCT product_category) AS category_count FROM `thelook.inventory_items` GROUP BY product_distribution_center_id));\",\"description\":\"Find the product distribution centers where the number of distinct product categories is greater than the average number of distinct product categories across all distribution centers.\"},{\"sql\":\"SELECT product_brand, SUM(product_retail_price) AS total_retail_value FROM `thelook.inventory_items` WHERE sold_at IS NOT NULL GROUP BY product_brand ORDER BY total_retail_value DESC LIMIT 3;\",\"description\":\"Identify the top 3 product brands with the highest total retail value of sold items.\"},{\"sql\":\"SELECT product_category FROM `thelook.inventory_items` GROUP BY product_category HAVING COUNT(DISTINCT product_brand) > 5;\",\"description\":\"Find the product categories with a count of distinct product brands greater than 5.\"},{\"sql\":\"SELECT product_category, product_brand, SUM(cost) AS total_cost FROM `thelook.inventory_items` GROUP BY product_category, product_brand ORDER BY total_cost DESC;\",\"description\":\"Calculate the total cost of inventory items for each product category and brand combination.\"},{\"sql\":\"SELECT product_distribution_center_id, AVG(cost) AS average_cost FROM `thelook.inventory_items` GROUP BY product_distribution_center_id ORDER BY average_cost DESC LIMIT 1;\",\"description\":\"Find the product distribution center with the highest average cost of inventory items.\"},{\"sql\":\"SELECT product_category, STDDEV_POP(product_retail_price) AS retail_price_std_dev FROM `thelook.inventory_items` GROUP BY product_category;\",\"description\":\"Calculate the standard deviation of retail prices for each product category.\"},{\"sql\":\"SELECT product_department, APPROX_QUANTILES(product_retail_price, 100)[OFFSET(90)] AS percentile_90 FROM `thelook.inventory_items` GROUP BY product_department;\",\"description\":\"Calculate the 90th percentile of product retail prices for each product department.\"},{\"sql\":\"SELECT product_department, COUNTIF(sold_at IS NOT NULL) / COUNT(*) AS percentage_sold FROM `thelook.inventory_items` GROUP BY product_department;\",\"description\":\"Calculate the percentage of items sold for each product department.\"},{\"sql\":\"SELECT product_department, AVG(cost) AS average_cost FROM `thelook.inventory_items` WHERE created_at >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 30 DAY) GROUP BY product_department;\",\"description\":\"Calculate the average cost of products for each department, only considering items created in the last 30 days.\"},{\"sql\":\"SELECT product_name, MAX(product_retail_price) AS max_price FROM `thelook.inventory_items` GROUP BY product_name ORDER BY max_price DESC LIMIT 5;\",\"description\":\"Find the top 5 product names with the highest product retail price.\"},{\"sql\":\"SELECT\\n  product_brand,\\n  STDDEV_SAMP(cost) AS cost_std_dev\\nFROM\\n  `thelook.inventory_items`\\nWHERE created_at BETWEEN TIMESTAMP('2022-01-01 00:00:00 UTC') AND TIMESTAMP('2022-12-31 23:59:59 UTC')\\nGROUP BY\\n  product_brand;\",\"description\":\"Calculate the sample standard deviation of the cost for each product brand.\"},{\"sql\":\"SELECT\\n  product_category,\\n  AVG(product_retail_price) AS avg_price\\nFROM\\n  `thelook.inventory_items`\\nWHERE created_at BETWEEN TIMESTAMP('2022-01-01 00:00:00 UTC') AND TIMESTAMP('2022-12-31 23:59:59 UTC')\\nGROUP BY\\n  product_category\\nORDER BY\\n  avg_price DESC\\nLIMIT 5;\",\"description\":\"Find the top 5 product categories with the highest average product retail price.\"},{\"sql\":\"SELECT FORMAT_DATE('%Y-%m', DATE(created_at)) AS month, product_category, AVG(product_retail_price) AS avg_retail_price FROM `thelook.inventory_items` WHERE created_at BETWEEN TIMESTAMP('2019-01-01 00:00:00') AND TIMESTAMP('2022-12-31 23:59:59') GROUP BY 1, 2 ORDER BY 1, 2;\",\"description\":\"Calculate the monthly average retail price of products sold, grouped by product category.\"},{\"sql\":\"SELECT product_category, APPROX_QUANTILES(product_retail_price, 2)[OFFSET(1)] AS median_retail_price FROM `thelook.inventory_items` GROUP BY product_category ORDER BY median_retail_price DESC LIMIT 1;\",\"description\":\"Determine the product category with the highest median retail price.\"},{\"sql\":\"SELECT product_category, product_brand, MAX(product_retail_price) - MIN(product_retail_price) AS price_range FROM `thelook.inventory_items` GROUP BY product_category, product_brand ORDER BY price_range DESC LIMIT 1;\",\"description\":\"Determine the product category and brand combination with the largest difference between the maximum and minimum retail price.\"},{\"sql\":\"SELECT product_brand, SUM(CASE WHEN sold_at IS NOT NULL THEN 1 ELSE 0 END) / COUNT(*) AS sold_ratio FROM `thelook.inventory_items` GROUP BY product_brand ORDER BY sold_ratio DESC LIMIT 1;\",\"description\":\"Determine the product brand with the highest ratio of sold items to total items.\"},{\"sql\":\"SELECT product_category FROM `thelook.inventory_items` GROUP BY product_category HAVING MIN(product_retail_price) > (SELECT AVG(cost) FROM `thelook.inventory_items`);\",\"description\":\"Determine the product categories where the minimum retail price is greater than the average cost across all products.\"},{\"sql\":\"SELECT\\n  product_department,\\n  product_category,\\n  AVG(product_retail_price) AS avg_retail_price\\nFROM\\n  `thelook.inventory_items`\\nWHERE created_at BETWEEN TIMESTAMP('2022-01-01 00:00:00 UTC') AND TIMESTAMP('2022-12-31 23:59:59 UTC')\\nGROUP BY\\n  product_department,\\n  product_category;\",\"description\":\"Determine the average product retail price by product department and product category.\"}],\"ddl\":\"CREATE TABLE `ai-learning-agents.thelook.inventory_items`\\n(\\n  id INT64 OPTIONS(description=\\\"Unique identifier for the inventory item.\\\"),\\n  product_id INT64 OPTIONS(description=\\\"Identifier for the product.\\\"),\\n  created_at TIMESTAMP OPTIONS(description=\\\"Timestamp indicating when the inventory item was created.\\\"),\\n  sold_at TIMESTAMP OPTIONS(description=\\\"Timestamp indicating when the inventory item was sold.\\\"),\\n  cost FLOAT64 OPTIONS(description=\\\"Cost of the inventory item.\\\"),\\n  product_category STRING OPTIONS(description=\\\"Category of the product.\\\"),\\n  product_name STRING OPTIONS(description=\\\"Name of the product.\\\"),\\n  product_brand STRING OPTIONS(description=\\\"Brand of the product.\\\"),\\n  product_retail_price FLOAT64 OPTIONS(description=\\\"Retail price of the product.\\\"),\\n  product_department STRING OPTIONS(description=\\\"Department the product belongs to.\\\"),\\n  product_sku STRING OPTIONS(description=\\\"Stock keeping unit for the product.\\\"),\\n  product_distribution_center_id INT64 OPTIONS(description=\\\"Identifier for the distribution center where the product is located.\\\")\\n)\\nOPTIONS(\\n  description=\\\"This table tracks the inventory of products. It records details about each item, including its cost and retail price. The table also associates each item with a specific product and distribution center. This allows for analysis of inventory levels and product performance.\\\",\\n  labels=[(\\\"dataplex-data-documentation-published-location\\\", \\\"us-central1\\\"), (\\\"dataplex-data-documentation-published-project\\\", \\\"ai-learning-agents\\\"), (\\\"dataplex-data-documentation-published-scan\\\", \\\"ada6bf718-997a-49c9-9c39-420e79abe1cc\\\")]\\n);\",\"row_count\":489838,\"size_bytes\":81275603},{\"name\":\"ai-learning-agents.thelook.orders\",\"overview\":\"This table stores information about customer orders. It tracks the status of each order throughout its lifecycle. The table records timestamps for when an order was created, shipped, delivered, and potentially returned. It also includes data related to the user who placed the order.\",\"fields\":[{\"name\":\"user_id\",\"description\":\"Unique identifier for the user who placed the order.\"},{\"name\":\"delivered_at\",\"description\":\"Timestamp indicating when the order was delivered.\"},{\"name\":\"created_at\",\"description\":\"Timestamp indicating when the order was created.\"},{\"name\":\"shipped_at\",\"description\":\"Timestamp indicating when the order was shipped.\"},{\"name\":\"status\",\"description\":\"Status of the order.\"},{\"name\":\"returned_at\",\"description\":\"Timestamp indicating when the order was returned.\"},{\"name\":\"order_id\",\"description\":\"Unique identifier for the order.\"},{\"name\":\"gender\",\"description\":\"Gender of the user who placed the order.\"},{\"name\":\"num_of_item\",\"description\":\"Number of items in the order.\"}],\"queries\":[{\"sql\":\"SELECT\\n  user_id,\\n  COUNT(*) AS order_count\\nFROM\\n  `thelook.orders`\\nWHERE created_at BETWEEN TIMESTAMP('2022-01-01 00:00:00 UTC') AND TIMESTAMP('2022-12-31 23:59:59 UTC')\\nGROUP BY\\n  user_id\\nHAVING\\n  COUNT(*) > (SELECT AVG(order_count) * 3 FROM (SELECT user_id, COUNT(*) AS order_count FROM `thelook.orders` WHERE created_at BETWEEN TIMESTAMP('2022-01-01 00:00:00 UTC') AND TIMESTAMP('2022-12-31 23:59:59 UTC') GROUP BY user_id));\",\"description\":\"Identify users whose order creation timestamps are clustered within a very short time frame, suggesting potential bot activity.\"},{\"sql\":\"SELECT\\n  order_id,\\n  TIMESTAMP_DIFF(shipped_at, created_at, DAY) AS shipping_time_days\\nFROM\\n  `thelook.orders`\\nWHERE shipped_at IS NOT NULL\\nAND created_at IS NOT NULL\\nAND\\n  TIMESTAMP_DIFF(shipped_at, created_at, DAY) > (SELECT AVG(TIMESTAMP_DIFF(shipped_at, created_at, DAY)) * 2 FROM `thelook.orders` WHERE shipped_at IS NOT NULL AND created_at IS NOT NULL);\",\"description\":\"Find orders that took significantly longer to ship than the average shipping time, indicating potential logistical anomalies.\"},{\"sql\":\"SELECT\\n  user_id,\\n  COUNTIF(returned_at IS NOT NULL) / COUNT(*) AS return_rate\\nFROM\\n  `thelook.orders`\\nGROUP BY\\n  user_id\\nHAVING\\n  COUNTIF(returned_at IS NOT NULL) / COUNT(*) > (SELECT AVG(CAST(returned_at IS NOT NULL as INT64)) FROM `thelook.orders`);\",\"description\":\"Identify users with a significantly higher return rate compared to the average return rate across all users.\"},{\"sql\":\"SELECT\\n  order_id,\\n  user_id,\\n  num_of_item\\nFROM\\n  `thelook.orders` AS t1\\nWHERE\\n  num_of_item < (SELECT AVG(num_of_item) * 0.5 FROM `thelook.orders` AS t2 WHERE t1.user_id = t2.user_id);\",\"description\":\"Find orders where the number of items is significantly lower than the average number of items for that user, potentially indicating an error or unusual behavior.\"},{\"sql\":\"SELECT\\n  gender,\\n  AVG(num_of_item) AS avg_items\\nFROM\\n  `thelook.orders`\\nWHERE gender IS NOT NULL\\nGROUP BY\\n  gender\\nHAVING\\n  AVG(num_of_item) > (SELECT AVG(num_of_item) * 1.5 FROM `thelook.orders`);\",\"description\":\"Find gender segments with unusually high average number of items purchased compared to the overall average.\"},{\"sql\":\"SELECT\\n  user_id,\\n  AVG(num_of_item) AS avg_items_per_order\\nFROM\\n  `thelook.orders`\\nWHERE\\n  status = 'Complete'\\nGROUP BY\\n  user_id\\nHAVING\\n  AVG(num_of_item) > (SELECT AVG(num_of_item) * 2 FROM `thelook.orders` WHERE status = 'Complete');\",\"description\":\"Identify users with an unusually high number of items per order compared to the average, considering only completed orders.\"},{\"sql\":\"SELECT\\n  order_id,\\n  TIMESTAMP_DIFF(delivered_at, shipped_at, DAY) AS delivery_time_days\\nFROM\\n  `thelook.orders`\\nWHERE delivered_at IS NOT NULL AND shipped_at IS NOT NULL\\nAND\\n  TIMESTAMP_DIFF(delivered_at, shipped_at, DAY) > (SELECT APPROX_QUANTILES(TIMESTAMP_DIFF(delivered_at, shipped_at, DAY), 100)[OFFSET(50)] FROM `thelook.orders` WHERE delivered_at IS NOT NULL AND shipped_at IS NOT NULL);\",\"description\":\"Identify orders with an unusually long delivery time compared to the median delivery time.\"},{\"sql\":\"SELECT\\n  CORR(num_of_item, TIMESTAMP_DIFF(delivered_at, created_at, DAY)) AS delivery_correlation\\nFROM\\n  `thelook.orders`\\nWHERE created_at BETWEEN TIMESTAMP('2022-01-01 00:00:00 UTC') AND TIMESTAMP('2022-12-31 23:59:59 UTC');\",\"description\":\"Calculate the correlation between the number of items in an order and the time it takes for the order to be delivered.\"},{\"sql\":\"SELECT CORR(num_of_item, TIMESTAMP_DIFF(delivered_at, shipped_at, DAY)) AS correlation FROM `thelook.orders` WHERE shipped_at IS NOT NULL AND delivered_at IS NOT NULL;\",\"description\":\"Calculate the correlation between the number of items and the time difference between shipped and delivered timestamps.\"},{\"sql\":\"WITH monthly_avg AS (\\n  SELECT FORMAT_DATE('%Y-%m', DATE(created_at)) AS order_month, gender, AVG(num_of_item) AS avg_items\\n  FROM `thelook.orders`\\n  WHERE created_at BETWEEN TIMESTAMP('2019-01-01 00:00:00 UTC') AND TIMESTAMP('2022-12-31 23:59:59 UTC')\\n  GROUP BY 1, 2\\n)\\nSELECT order_month, gender, avg_items,\\n       avg_items - LAG(avg_items) OVER (PARTITION BY gender ORDER BY order_month) AS diff_from_prev_month\\nFROM monthly_avg\\nORDER BY order_month, gender;\",\"description\":\"Calculate the difference in average order size between genders from one month to the next.\"},{\"sql\":\"SELECT gender, COUNTIF(status = 'Returned') / COUNT(*) AS return_rate FROM `thelook.orders` WHERE EXTRACT(YEAR FROM created_at) = 2022 GROUP BY gender;\",\"description\":\"Calculate the return rate (returned orders / total orders) for each gender, only considering orders created in the year 2022.\"},{\"sql\":\"SELECT gender, STDDEV_POP(num_of_item) AS std_dev_items FROM `thelook.orders` GROUP BY gender;\",\"description\":\"Calculate the standard deviation of the number of items ordered, grouped by gender.\"},{\"sql\":\"SELECT\\n  gender,\\n  status,\\n  VAR_SAMP(num_of_item) AS item_variance\\nFROM\\n  `thelook.orders`\\nWHERE created_at BETWEEN TIMESTAMP('2022-01-01 00:00:00 UTC') AND TIMESTAMP('2022-12-31 23:59:59 UTC')\\nGROUP BY\\n  gender,\\n  status;\",\"description\":\"Calculate the sample variance of the number of items ordered, grouped by gender and order status.\"},{\"sql\":\"SELECT FORMAT_DATE('%Y-%m', DATE(created_at)) AS order_month, gender, COUNT(order_id) AS order_count\\nFROM `thelook.orders`\\nWHERE created_at BETWEEN TIMESTAMP('2019-01-01 00:00:00 UTC') AND TIMESTAMP('2022-12-31 23:59:59 UTC')\\nGROUP BY 1, 2\\nORDER BY 1, 2;\",\"description\":\"Calculate the monthly order volume trend for each gender.\"},{\"sql\":\"SELECT gender, AVG(num_of_item) AS avg_items FROM `thelook.orders` WHERE delivered_at BETWEEN created_at AND TIMESTAMP_ADD(created_at, INTERVAL 30 DAY) GROUP BY gender;\",\"description\":\"Calculate the average number of items ordered by gender for orders that were delivered within 30 days of creation.\"},{\"sql\":\"SELECT gender, COUNTIF(TIMESTAMP_DIFF(shipped_at, created_at, DAY) <= 5) / COUNT(*) AS percentage_shipped_within_5_days FROM `thelook.orders` WHERE shipped_at IS NOT NULL GROUP BY gender;\",\"description\":\"Calculate the percentage of orders shipped within 5 days of creation, broken down by gender.\"},{\"sql\":\"SELECT AVG(TIMESTAMP_DIFF(delivered_at, shipped_at, HOUR)) AS avg_delivery_time_hours FROM `thelook.orders` WHERE shipped_at IS NOT NULL AND delivered_at IS NOT NULL AND num_of_item > 2;\",\"description\":\"Calculate the average time difference between shipped and delivered timestamps, in hours, for orders with more than 2 items.\"},{\"sql\":\"SELECT gender, AVG(num_of_item) AS avg_items FROM `thelook.orders` WHERE EXTRACT(DAYOFWEEK FROM created_at) IN (1, 7) GROUP BY gender;\",\"description\":\"Calculate the average number of items ordered by gender for orders that were created on weekends (Saturday and Sunday).\"},{\"sql\":\"SELECT AVG(num_of_item) AS avg_items FROM `thelook.orders` WHERE shipped_at IS NOT NULL AND delivered_at IS NULL;\",\"description\":\"Calculate the average number of items for orders that were shipped but not delivered.\"},{\"sql\":\"SELECT status, APPROX_QUANTILES(num_of_item, 2)[OFFSET(1)] AS median_items FROM `thelook.orders` GROUP BY status;\",\"description\":\"Calculate the median number of items ordered for each order status.\"},{\"sql\":\"SELECT status, AVG(num_of_item) AS avg_items FROM `thelook.orders` GROUP BY status ORDER BY avg_items DESC LIMIT 3;\",\"description\":\"Identify the top 3 order statuses with the highest average number of items.\"},{\"sql\":\"SELECT\\n  gender,\\n  MAX(num_of_item) AS max_items,\\n  MIN(num_of_item) AS min_items,\\n  AVG(num_of_item) AS avg_items\\nFROM\\n  `thelook.orders`\\nWHERE created_at BETWEEN TIMESTAMP('2022-01-01 00:00:00 UTC') AND TIMESTAMP('2022-12-31 23:59:59 UTC')\\nGROUP BY\\n  gender;\",\"description\":\"Find the maximum and minimum number of items ordered in a single order, as well as the average order value, for each gender.\"},{\"sql\":\"SELECT gender, AVG(num_of_item) AS avg_items FROM `thelook.orders` WHERE status != 'Returned' GROUP BY gender;\",\"description\":\"Calculate the average number of items ordered for each gender, considering only orders that were not returned.\"},{\"sql\":\"SELECT\\n  gender,\\n  COUNTIF(status = 'Returned') / COUNT(*) AS return_rate\\nFROM\\n  `thelook.orders`\\nWHERE created_at BETWEEN TIMESTAMP('2022-01-01 00:00:00 UTC') AND TIMESTAMP('2022-12-31 23:59:59 UTC')\\nGROUP BY\\n  gender;\",\"description\":\"Calculate the percentage of orders that are returned, grouped by gender.\"},{\"sql\":\"SELECT gender, AVG(TIMESTAMP_DIFF(delivered_at, created_at, DAY)) AS avg_delivery_time FROM `thelook.orders` WHERE delivered_at IS NOT NULL GROUP BY gender;\",\"description\":\"Calculate the average time difference between order creation and delivery, in days, for each gender.\"},{\"sql\":\"SELECT\\n  gender,\\n  AVG(TIMESTAMP_DIFF(shipped_at, created_at, DAY)) AS avg_shipping_time\\nFROM\\n  `thelook.orders`\\nWHERE created_at BETWEEN TIMESTAMP('2022-01-01 00:00:00 UTC') AND TIMESTAMP('2022-12-31 23:59:59 UTC') AND shipped_at IS NOT NULL\\nGROUP BY\\n  gender;\",\"description\":\"Calculate the average time difference between order creation and shipping, grouped by gender.\"},{\"sql\":\"SELECT FORMAT_DATE('%Y-%m', DATE(created_at)) AS order_month,\\n       SUM(CASE WHEN status = 'Returned' THEN 1 ELSE 0 END) / COUNT(order_id) AS return_rate\\nFROM `thelook.orders`\\nWHERE created_at BETWEEN TIMESTAMP('2019-01-01 00:00:00 UTC') AND TIMESTAMP('2022-12-31 23:59:59 UTC')\\nGROUP BY 1\\nORDER BY 1;\",\"description\":\"Identify the percentage of orders returned each month.\"},{\"sql\":\"SELECT FORMAT_DATE('%Y-%m-%d', DATE(created_at)) AS order_date,\\n       COUNT(order_id) OVER (ORDER BY created_at) AS cumulative_orders\\nFROM `thelook.orders`\\nWHERE created_at BETWEEN TIMESTAMP('2019-01-01 00:00:00 UTC') AND TIMESTAMP('2022-12-31 23:59:59 UTC')\\nORDER BY order_date;\",\"description\":\"Calculate the cumulative sum of orders over time.\"},{\"sql\":\"SELECT status, MIN(num_of_item) AS min_items, MAX(num_of_item) AS max_items FROM `thelook.orders` GROUP BY status;\",\"description\":\"Find the minimum and maximum number of items ordered for each order status.\"},{\"sql\":\"SELECT gender, COUNTIF(status = 'Returned') / COUNT(*) AS return_rate FROM `thelook.orders` GROUP BY gender;\",\"description\":\"Determine the percentage of orders that were returned, broken down by gender.\"}],\"ddl\":\"CREATE TABLE `ai-learning-agents.thelook.orders`\\n(\\n  order_id INT64 OPTIONS(description=\\\"Unique identifier for the order.\\\"),\\n  user_id INT64 OPTIONS(description=\\\"Unique identifier for the user who placed the order.\\\"),\\n  status STRING OPTIONS(description=\\\"Status of the order.\\\"),\\n  gender STRING OPTIONS(description=\\\"Gender of the user who placed the order.\\\"),\\n  created_at TIMESTAMP OPTIONS(description=\\\"Timestamp indicating when the order was created.\\\"),\\n  returned_at TIMESTAMP OPTIONS(description=\\\"Timestamp indicating when the order was returned.\\\"),\\n  shipped_at TIMESTAMP OPTIONS(description=\\\"Timestamp indicating when the order was shipped.\\\"),\\n  delivered_at TIMESTAMP OPTIONS(description=\\\"Timestamp indicating when the order was delivered.\\\"),\\n  num_of_item INT64 OPTIONS(description=\\\"Number of items in the order.\\\")\\n)\\nOPTIONS(\\n  description=\\\"This table stores information about customer orders. It tracks the status of each order throughout its lifecycle. The table records timestamps for when an order was created, shipped, delivered, and potentially returned. It also includes data related to the user who placed the order.\\\",\\n  labels=[(\\\"dataplex-data-documentation-published-location\\\", \\\"us-central1\\\"), (\\\"dataplex-data-documentation-published-project\\\", \\\"ai-learning-agents\\\"), (\\\"dataplex-data-documentation-published-scan\\\", \\\"ab06ef464-2420-4997-b3c0-7cfa94bdad28\\\")]\\n);\",\"row_count\":125105,\"size_bytes\":6762580},{\"name\":\"ai-learning-agents.thelook.users\",\"overview\":\"This table stores user information. It includes demographic details and geographic location. The table also tracks the source from which users originate. This data can be used for user segmentation and targeted marketing efforts.\",\"fields\":[{\"name\":\"first_name\",\"description\":\"First name of the user.\"},{\"name\":\"longitude\",\"description\":\"Longitude coordinate of the user's location.\"},{\"name\":\"traffic_source\",\"description\":\"Source from which the user originated.\"},{\"name\":\"created_at\",\"description\":\"Timestamp when the user account was created.\"},{\"name\":\"id\",\"description\":\"Unique identifier for the user.\"},{\"name\":\"postal_code\",\"description\":\"Postal code of the user's address.\"},{\"name\":\"user_geom\",\"description\":\"Geographic data representing the user's location.\"},{\"name\":\"age\",\"description\":\"Age of the user.\"},{\"name\":\"city\",\"description\":\"City of the user.\"},{\"name\":\"email\",\"description\":\"Email address of the user.\"},{\"name\":\"gender\",\"description\":\"Gender of the user.\"},{\"name\":\"state\",\"description\":\"State of the user.\"},{\"name\":\"country\",\"description\":\"Country of the user.\"},{\"name\":\"last_name\",\"description\":\"Last name of the user.\"},{\"name\":\"latitude\",\"description\":\"Latitude coordinate of the user's location.\"},{\"name\":\"street_address\",\"description\":\"Street address of the user.\"}],\"queries\":[{\"sql\":\"WITH StateAgeStats AS (\\n  SELECT\\n    state,\\n    AVG(age) AS avg_age,\\n    STDDEV(age) AS std_age\\n  FROM\\n    `thelook.users`\\n  GROUP BY\\n    state\\n)\\nSELECT\\n  u.id,\\n  u.age,\\n  u.state,\\n  (u.age - s.avg_age) / s.std_age AS z_score\\nFROM\\n  `thelook.users` u\\nJOIN\\n  StateAgeStats s ON u.state = s.state\\nWHERE s.std_age > 0 AND ABS((u.age - s.avg_age) / s.std_age) > 3;\",\"description\":\"Identify users with unusual age given their location (state) using z-score.\"},{\"sql\":\"SELECT CORR(age, latitude) AS age_latitude_correlation FROM `thelook.users`;\",\"description\":\"Calculate the correlation between user age and their latitude to understand if there's a geographical distribution bias based on age.\"},{\"sql\":\"SELECT traffic_source, STDDEV_POP(age) AS age_stddev FROM `thelook.users` GROUP BY traffic_source ORDER BY age_stddev DESC LIMIT 1;\",\"description\":\"Identify the traffic source with the highest standard deviation of user ages.\"},{\"sql\":\"SELECT ST_DISTANCE( (SELECT ST_GEOGPOINT(AVG(longitude), AVG(latitude)) FROM `thelook.users` WHERE country = 'China'), (SELECT ST_GEOGPOINT(AVG(longitude), AVG(latitude)) FROM `thelook.users` WHERE country = 'United States')) AS distance;\",\"description\":\"Calculate the distance between the average user location in China and the average user location in the United States.\"},{\"sql\":\"SELECT country, VAR_POP(age) AS age_variance FROM `thelook.users` WHERE country IN ('China', 'United States', 'Brasil') GROUP BY country;\",\"description\":\"Calculate the population variance of user ages, grouped by country, filtering for users in China, United States, and Brasil.\"},{\"sql\":\"SELECT\\n    id,\\n    latitude,\\n    country\\n  FROM\\n    `thelook.users`\\nWHERE latitude > (SELECT APPROX_QUANTILES(latitude, 100)[OFFSET(50)] FROM `thelook.users` WHERE country = 'China') + (2 * (SELECT STDDEV(latitude) FROM `thelook.users` WHERE country = 'China'))\\nAND country = 'China'\\nUNION ALL\\nSELECT\\n    id,\\n    latitude,\\n    country\\n  FROM\\n    `thelook.users`\\nWHERE latitude > (SELECT APPROX_QUANTILES(latitude, 100)[OFFSET(50)] FROM `thelook.users` WHERE country = 'United States') + (2 * (SELECT STDDEV(latitude) FROM `thelook.users` WHERE country = 'United States'))\\nAND country = 'United States'\\nUNION ALL\\nSELECT\\n    id,\\n    latitude,\\n    country\\n  FROM\\n    `thelook.users`\\nWHERE latitude > (SELECT APPROX_QUANTILES(latitude, 100)[OFFSET(50)] FROM `thelook.users` WHERE country = 'Brasil') + (2 * (SELECT STDDEV(latitude) FROM `thelook.users` WHERE country = 'Brasil'))\\nAND country = 'Brasil';\",\"description\":\"Find users whose latitude is significantly different from the median latitude for their country.\"},{\"sql\":\"SELECT\\n    id,\\n    longitude,\\n    city\\n  FROM\\n    `thelook.users`\\nWHERE longitude > (SELECT APPROX_QUANTILES(longitude, 100)[OFFSET(50)] FROM `thelook.users` WHERE city = 'Shanghai') + (2 * (SELECT STDDEV(longitude) FROM `thelook.users` WHERE city = 'Shanghai'))\\nAND city = 'Shanghai'\\nUNION ALL\\nSELECT\\n    id,\\n    longitude,\\n    city\\n  FROM\\n    `thelook.users`\\nWHERE longitude > (SELECT APPROX_QUANTILES(longitude, 100)[OFFSET(50)] FROM `thelook.users` WHERE city = 'Beijing') + (2 * (SELECT STDDEV(longitude) FROM `thelook.users` WHERE city = 'Beijing'))\\nAND city = 'Beijing'\\nUNION ALL\\nSELECT\\n    id,\\n    longitude,\\n    city\\n  FROM\\n    `thelook.users`\\nWHERE longitude > (SELECT APPROX_QUANTILES(longitude, 100)[OFFSET(50)] FROM `thelook.users` WHERE city = 'Seoul') + (2 * (SELECT STDDEV(longitude) FROM `thelook.users` WHERE city = 'Seoul'))\\nAND city = 'Seoul';\",\"description\":\"Find users whose longitude is an outlier compared to the median longitude for their city.\"},{\"sql\":\"WITH CountryAverages AS (SELECT country, AVG(latitude) AS avg_lat, AVG(longitude) AS avg_lon FROM `thelook.users` GROUP BY country), GlobalAverage AS (SELECT AVG(latitude) AS global_lat, AVG(longitude) AS global_lon FROM `thelook.users`) SELECT ca.country, ST_DISTANCE(ST_GEOGPOINT(ca.avg_lon, ca.avg_lat), ST_GEOGPOINT(ga.global_lon, ga.global_lat)) AS distance_from_global_average FROM CountryAverages ca, GlobalAverage ga;\",\"description\":\"Calculate the average latitude and longitude for each country, and then calculate the distance between each country's average location and the global average location.\"},{\"sql\":\"SELECT\\n    id,\\n    age,\\n    gender\\n  FROM\\n    `thelook.users`\\nWHERE age > (SELECT AVG(age) FROM `thelook.users` WHERE gender = 'F') + (2 * (SELECT STDDEV(age) FROM `thelook.users` WHERE gender = 'F'))\\nAND gender = 'F'\\nUNION ALL\\nSELECT\\n    id,\\n    age,\\n    gender\\n  FROM\\n    `thelook.users`\\nWHERE age > (SELECT AVG(age) FROM `thelook.users` WHERE gender = 'M') + (2 * (SELECT STDDEV(age) FROM `thelook.users` WHERE gender = 'M'))\\nAND gender = 'M';\",\"description\":\"Identify users whose age is an outlier compared to the average age for their gender.\"},{\"sql\":\"SELECT state, SUM(age * user_count) / SUM(user_count) AS weighted_average_age FROM (SELECT state, AVG(age) AS age, COUNT(*) AS user_count FROM `thelook.users` GROUP BY state) GROUP BY state;\",\"description\":\"Calculate the average age of users in each state, weighted by the number of users in that state.\"},{\"sql\":\"SELECT city, traffic_source, AVG(age) AS average_age FROM `thelook.users` WHERE age > 26 GROUP BY city, traffic_source;\",\"description\":\"Calculate the average age of users for each combination of city and traffic source, only considering users older than 26.\"},{\"sql\":\"SELECT state, AVG(age) AS average_age FROM `thelook.users` GROUP BY state HAVING AVG(age) > (SELECT AVG(age) FROM `thelook.users`);\",\"description\":\"Find the states where the average user age is above the overall average user age.\"},{\"sql\":\"SELECT country, COUNT(*), AVG(age) FROM `thelook.users` GROUP BY country HAVING COUNT(*) > 1000;\",\"description\":\"Calculate the number of users in each country, and the average age of users in each country, only for countries where the number of users is greater than 1000.\"},{\"sql\":\"SELECT state, MAX(age) - MIN(age) AS age_difference FROM `thelook.users` GROUP BY state ORDER BY age_difference DESC LIMIT 3;\",\"description\":\"Find the top 3 states with the largest difference between the maximum and minimum user age.\"},{\"sql\":\"SELECT state, gender, age, COUNT(*) AS age_count FROM `thelook.users` GROUP BY state, gender, age ORDER BY state, gender, age_count DESC;\",\"description\":\"Identify the most common age for each gender in each state.\"},{\"sql\":\"SELECT COVAR_SAMP(age, longitude) AS age_longitude_covariance FROM `thelook.users`;\",\"description\":\"Calculate the sample covariance between user age and longitude.\"},{\"sql\":\"SELECT country, FORMAT_DATETIME('%Y-%m-%d', created_at) AS date, COUNT(id) AS daily_users, SUM(COUNT(id)) OVER (PARTITION BY country ORDER BY created_at) AS cumulative_users FROM `thelook.users` GROUP BY country, date, created_at ORDER BY country, created_at;\",\"description\":\"Calculate the cumulative sum of users created over time, partitioned by country.\"},{\"sql\":\"SELECT gender, traffic_source, AVG(age) AS average_age FROM `thelook.users` GROUP BY gender, traffic_source;\",\"description\":\"Calculate the average age of users for each gender and traffic source.\"},{\"sql\":\"SELECT state, APPROX_QUANTILES(age, 2)[OFFSET(1)] AS median_age FROM `thelook.users` GROUP BY state;\",\"description\":\"Calculate the median age of users for each state.\"},{\"sql\":\"SELECT country, MAX(age) - MIN(age) AS age_range FROM `thelook.users` GROUP BY country;\",\"description\":\"Calculate the age range (max age - min age) for each country.\"},{\"sql\":\"SELECT postal_code, AVG(age) AS average_age FROM `thelook.users` GROUP BY postal_code ORDER BY average_age DESC LIMIT 5;\",\"description\":\"Find the top 5 postal codes with the highest average age of users.\"},{\"sql\":\"SELECT traffic_source, AVG(age) AS average_age, STDDEV_SAMP(age) AS age_std_dev FROM `thelook.users` GROUP BY traffic_source;\",\"description\":\"Find the average age of users for each traffic source, and the standard deviation of ages within each traffic source.\"},{\"sql\":\"SELECT country, AVG(latitude) AS avg_latitude, AVG(longitude) AS avg_longitude, COUNT(*) AS user_count FROM `thelook.users` GROUP BY country;\",\"description\":\"Calculate the average latitude and longitude for users in each country, and the number of users in each country.\"},{\"sql\":\"SELECT gender, APPROX_QUANTILES(age, 4)[OFFSET(1)] AS age_25th_percentile, APPROX_QUANTILES(age, 4)[OFFSET(2)] AS age_50th_percentile, APPROX_QUANTILES(age, 4)[OFFSET(3)] AS age_75th_percentile FROM `thelook.users` GROUP BY gender;\",\"description\":\"Calculate the 25th, 50th, and 75th percentile of user ages for each gender.\"},{\"sql\":\"SELECT traffic_source, AVG(age) AS average_age FROM `thelook.users` GROUP BY traffic_source ORDER BY average_age DESC LIMIT 3;\",\"description\":\"Find the top 3 traffic sources with the highest average user age.\"},{\"sql\":\"SELECT country, traffic_source, AVG(age) AS average_age FROM `thelook.users` GROUP BY country, traffic_source;\",\"description\":\"Calculate the average age of users by country and traffic source.\"},{\"sql\":\"WITH avg_ages AS (SELECT city, gender, AVG(age) AS avg_age FROM `thelook.users` GROUP BY city, gender) SELECT a.city, a.avg_age AS female_avg_age, b.avg_age AS male_avg_age, a.avg_age - b.avg_age AS age_difference FROM avg_ages a JOIN avg_ages b ON a.city = b.city AND a.gender = 'F' AND b.gender = 'M';\",\"description\":\"Calculate the difference in average age between male and female users for each city.\"},{\"sql\":\"SELECT state, gender, COUNT(*) / (SELECT COUNT(*) FROM `thelook.users` AS u2 WHERE u2.state = u1.state) AS percentage FROM `thelook.users` AS u1 GROUP BY state, gender;\",\"description\":\"Find the percentage of male and female users in each state.\"},{\"sql\":\"SELECT country, COUNTIF(traffic_source = 'Search') / COUNT(*) AS search_percentage FROM `thelook.users` GROUP BY country;\",\"description\":\"Calculate the percentage of users in each country who use 'Search' as their traffic source.\"},{\"sql\":\"SELECT city, AVG(latitude) AS average_latitude FROM `thelook.users` GROUP BY city ORDER BY average_latitude DESC LIMIT 3;\",\"description\":\"Find the top 3 cities with the highest average latitude.\"}],\"ddl\":\"CREATE TABLE `ai-learning-agents.thelook.users`\\n(\\n  id INT64 OPTIONS(description=\\\"Unique identifier for the user.\\\"),\\n  first_name STRING OPTIONS(description=\\\"First name of the user.\\\"),\\n  last_name STRING OPTIONS(description=\\\"Last name of the user.\\\"),\\n  email STRING OPTIONS(description=\\\"Email address of the user.\\\"),\\n  age INT64 OPTIONS(description=\\\"Age of the user.\\\"),\\n  gender STRING OPTIONS(description=\\\"Gender of the user.\\\"),\\n  state STRING OPTIONS(description=\\\"State of the user.\\\"),\\n  street_address STRING OPTIONS(description=\\\"Street address of the user.\\\"),\\n  postal_code STRING OPTIONS(description=\\\"Postal code of the user's address.\\\"),\\n  city STRING OPTIONS(description=\\\"City of the user.\\\"),\\n  country STRING OPTIONS(description=\\\"Country of the user.\\\"),\\n  latitude FLOAT64 OPTIONS(description=\\\"Latitude coordinate of the user's location.\\\"),\\n  longitude FLOAT64 OPTIONS(description=\\\"Longitude coordinate of the user's location.\\\"),\\n  traffic_source STRING OPTIONS(description=\\\"Source from which the user originated.\\\"),\\n  created_at TIMESTAMP OPTIONS(description=\\\"Timestamp when the user account was created.\\\"),\\n  user_geom GEOGRAPHY OPTIONS(description=\\\"Geographic data representing the user's location.\\\")\\n)\\nOPTIONS(\\n  description=\\\"This table stores user information. It includes demographic details and geographic location. The table also tracks the source from which users originate. This data can be used for user segmentation and targeted marketing efforts.\\\",\\n  labels=[(\\\"dataplex-data-documentation-published-location\\\", \\\"us-central1\\\"), (\\\"dataplex-dp-published-scan\\\", \\\"ac26a7027-1ec9-4ebe-a5e6-c0a41ab6108d\\\"), (\\\"dataplex-dp-published-project\\\", \\\"ai-learning-agents\\\"), (\\\"dataplex-dp-published-location\\\", \\\"us-central1\\\"), (\\\"dataplex-data-documentation-published-project\\\", \\\"ai-learning-agents\\\"), (\\\"dataplex-data-documentation-published-scan\\\", \\\"a62faff99-c9a5-4687-a4fa-8687859916ec\\\")]\\n);\",\"row_count\":100000,\"size_bytes\":19813856},{\"name\":\"ai-learning-agents.thelook.users_view\",\"overview\":\"This table stores user information. It includes details that can be used for user segmentation and demographic analysis. The data allows for geographic analysis of users. The table also tracks the source from which users originated. This information supports marketing and customer relationship management efforts.\",\"fields\":[{\"name\":\"email\",\"description\":\"The email address of the user.\"},{\"name\":\"first_name\",\"description\":\"The first name of the user.\"},{\"name\":\"age\",\"description\":\"The age of the user.\"},{\"name\":\"latitude\",\"description\":\"The latitude coordinate of the user's location.\"},{\"name\":\"state\",\"description\":\"The state where the user resides.\"},{\"name\":\"street_address\",\"description\":\"The street address of the user.\"},{\"name\":\"gender\",\"description\":\"The gender of the user.\"},{\"name\":\"id\",\"description\":\"A unique identifier for the user.\"},{\"name\":\"user_geom\",\"description\":\"A geographic point representing the user's location.\"},{\"name\":\"traffic_source\",\"description\":\"The source from which the user originated.\"},{\"name\":\"country\",\"description\":\"The country where the user resides.\"},{\"name\":\"created_at\",\"description\":\"The timestamp when the user's record was created.\"},{\"name\":\"city\",\"description\":\"The city where the user resides.\"},{\"name\":\"last_name\",\"description\":\"The last name of the user.\"},{\"name\":\"postal_code\",\"description\":\"The postal code of the user's address.\"},{\"name\":\"longitude\",\"description\":\"The longitude coordinate of the user's location.\"}],\"queries\":[{\"sql\":\"SELECT\\n  state,\\n  AVG(age) AS avg_age\\nFROM\\n  `thelook.users_view`\\nGROUP BY\\n  state\\nHAVING\\n  AVG(age) > (SELECT AVG(age) + STDDEV(age) FROM `thelook.users_view`) OR AVG(age) < (SELECT AVG(age) - STDDEV(age) FROM `thelook.users_view`);\",\"description\":\"Identify states with unusually high or low average user age compared to the overall average age.\"},{\"sql\":\"SELECT\\n  CORR(age, latitude) AS age_latitude_correlation\\nFROM\\n  `thelook.users_view`;\",\"description\":\"Calculate the correlation between user age and their latitude to see if there's a geographic age trend.\"},{\"sql\":\"SELECT\\n  traffic_source,\\n  COUNT(*) AS traffic_source_count\\nFROM\\n  `thelook.users_view`\\nGROUP BY\\n  traffic_source\\nHAVING\\n  traffic_source_count < (SELECT APPROX_QUANTILES(count, 100)[OFFSET(5)] FROM (SELECT COUNT(*) AS count FROM `thelook.users_view` GROUP BY traffic_source));\",\"description\":\"Identify users with rare traffic sources compared to the overall distribution of traffic sources.\"},{\"sql\":\"SELECT\\n  id,\\n  first_name,\\n  last_name,\\n  LENGTH(first_name) + LENGTH(last_name) AS full_name_length\\nFROM\\n  `thelook.users_view`\\nWHERE\\n  LENGTH(first_name) + LENGTH(last_name) > (SELECT AVG(LENGTH(first_name) + LENGTH(last_name)) + 2 * STDDEV(LENGTH(first_name) + LENGTH(last_name)) FROM `thelook.users_view`);\",\"description\":\"Find users with unusually long names compared to the average name length.\"},{\"sql\":\"SELECT\\n  traffic_source,\\n  COVAR_SAMP(age, longitude) AS age_longitude_covariance\\nFROM\\n  `thelook.users_view`\\nGROUP BY\\n  traffic_source;\",\"description\":\"Calculate the covariance between user age and longitude, grouped by traffic source.\"},{\"sql\":\"SELECT traffic_source FROM `thelook.users_view` GROUP BY traffic_source HAVING COUNT(DISTINCT state) > 5;\",\"description\":\"Find the traffic sources that have users in more than 5 different states.\"},{\"sql\":\"SELECT country, MAX(user_count) AS max_user_count FROM (SELECT country, gender, COUNT(*) AS user_count FROM `thelook.users_view` GROUP BY country, gender) GROUP BY country;\",\"description\":\"Calculate the number of users for each gender and country combination, and then find the maximum number of users for each country across all genders.\"},{\"sql\":\"SELECT\\n  traffic_source,\\n  state,\\n  AVG(age) AS average_age,\\n  STDDEV_SAMP(age) AS age_std_dev\\nFROM\\n  `thelook.users_view`\\nGROUP BY\\n  traffic_source,\\n  state;\",\"description\":\"Find the average age of users by traffic source and state, along with the standard deviation of ages within each group.\"},{\"sql\":\"SELECT traffic_source, STDDEV_POP(age) AS age_std_dev FROM `thelook.users_view` GROUP BY traffic_source ORDER BY age_std_dev DESC LIMIT 1;\",\"description\":\"Identify the traffic source with the highest standard deviation in user age.\"},{\"sql\":\"SELECT traffic_source, APPROX_QUANTILES(age, 100)[OFFSET(90)] AS age_90th_percentile FROM `thelook.users_view` GROUP BY traffic_source;\",\"description\":\"Calculate the 90th percentile of user ages for each traffic source.\"},{\"sql\":\"SELECT city, COUNT(*) AS user_count FROM `thelook.users_view` GROUP BY city HAVING COUNT(*) > (SELECT AVG(user_count) FROM (SELECT city, COUNT(*) AS user_count FROM `thelook.users_view` GROUP BY city));\",\"description\":\"Find the cities with a user count greater than the average user count across all cities.\"},{\"sql\":\"SELECT state, AVG(age) AS average_age FROM `thelook.users_view` GROUP BY state HAVING COUNT(*) > 100;\",\"description\":\"Calculate the average age of users for each state, only including states with more than 100 users.\"},{\"sql\":\"SELECT traffic_source, gender, AVG(age) AS average_age FROM `thelook.users_view` GROUP BY traffic_source, gender;\",\"description\":\"Calculate the average age of users for each combination of traffic source and gender.\"},{\"sql\":\"SELECT country, age, COUNT(*) AS user_count FROM `thelook.users_view` GROUP BY country, age ORDER BY country, age;\",\"description\":\"Calculate the distribution of user ages by country.\"},{\"sql\":\"SELECT country, APPROX_QUANTILES(age, 2)[OFFSET(1)] AS median_age FROM `thelook.users_view` GROUP BY country;\",\"description\":\"Calculate the median age of users for each country.\"},{\"sql\":\"SELECT country, MAX(age) - MIN(age) AS age_range FROM `thelook.users_view` GROUP BY country;\",\"description\":\"Calculate the difference between the maximum and minimum age for each country.\"},{\"sql\":\"SELECT\\n  city,\\n  AVG(longitude) AS avg_longitude\\nFROM\\n  `thelook.users_view`\\nGROUP BY\\n  city\\nORDER BY\\n  avg_longitude DESC\\nLIMIT 5;\",\"description\":\"Find the cities with the top 5 highest average user longitudes.\"},{\"sql\":\"SELECT\\n  state,\\n  MAX(age) - MIN(age) AS age_range\\nFROM\\n  `thelook.users_view`\\nGROUP BY\\n  state;\",\"description\":\"Calculate the difference between the maximum and minimum age for each state.\"},{\"sql\":\"SELECT city, APPROX_TOP_COUNT(gender, 1)[OFFSET(0)].value AS most_common_gender FROM `thelook.users_view` GROUP BY city;\",\"description\":\"Find the most common gender in each city.\"},{\"sql\":\"SELECT\\n  gender,\\n  VAR_SAMP(age) AS age_variance\\nFROM\\n  `thelook.users_view`\\nGROUP BY\\n  gender;\",\"description\":\"Calculate the variance of user ages for each gender.\"},{\"sql\":\"SELECT state, AVG(latitude) AS avg_latitude, AVG(longitude) AS avg_longitude FROM `thelook.users_view` GROUP BY state;\",\"description\":\"Find the average latitude and longitude for users in each state.\"},{\"sql\":\"SELECT postal_code, COUNT(*) AS user_count FROM `thelook.users_view` GROUP BY postal_code ORDER BY user_count DESC LIMIT 5;\",\"description\":\"Find the top 5 postal codes with the most users.\"},{\"sql\":\"SELECT EXTRACT(MONTH FROM created_at) AS month, gender, COUNT(*) AS user_count FROM `thelook.users_view` GROUP BY month, gender ORDER BY month, gender;\",\"description\":\"Calculate the number of users created each month, grouped by gender.\"},{\"sql\":\"SELECT FORMAT_DATETIME('%Y-%m', created_at) AS creation_month, COUNT(*) AS user_count FROM `thelook.users_view` GROUP BY creation_month ORDER BY creation_month;\",\"description\":\"Calculate the number of users created each month.\"},{\"sql\":\"SELECT country, MIN(created_at) AS first_user, MAX(created_at) AS last_user FROM `thelook.users_view` GROUP BY country;\",\"description\":\"Find the first and last user created in each country.\"},{\"sql\":\"SELECT state, first_name, last_name, age, RANK() OVER (PARTITION BY state ORDER BY age DESC) AS age_rank FROM `thelook.users_view`;\",\"description\":\"Rank users within each state based on their age.\"},{\"sql\":\"SELECT FORMAT_DATETIME('%Y-%m-%d', created_at) AS creation_date, COUNT(*) OVER (ORDER BY created_at ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_users FROM `thelook.users_view`;\",\"description\":\"Calculate the cumulative sum of users created over time.\"},{\"sql\":\"SELECT city, AVG(age) AS average_age FROM `thelook.users_view` GROUP BY city ORDER BY average_age DESC LIMIT 3;\",\"description\":\"Determine the top 3 cities with the highest average user age.\"},{\"sql\":\"SELECT state, COUNT(*) * 100.0 / (SELECT COUNT(*) FROM `thelook.users_view`) AS percentage FROM `thelook.users_view` GROUP BY state ORDER BY percentage DESC;\",\"description\":\"Find the percentage of users in each state, ordered by percentage in descending order.\"},{\"sql\":\"SELECT gender, MIN(age) AS min_age, MAX(age) AS max_age FROM `thelook.users_view` GROUP BY gender;\",\"description\":\"Determine the age range (min and max age) for each gender.\"}],\"ddl\":null,\"row_count\":null,\"size_bytes\":null},{\"name\":\"ai-learning-agents.thelook.products\",\"overview\":\"This table stores comprehensive details about products. It includes information on product categorization and branding. The table also contains pricing and cost data. This data can be used for inventory management and sales analysis.\",\"fields\":[{\"name\":\"name\",\"description\":\"Name of the product.\"},{\"name\":\"category\",\"description\":\"Category that the product belongs to.\"},{\"name\":\"department\",\"description\":\"Department that the product belongs to.\"},{\"name\":\"retail_price\",\"description\":\"Retail price of the product.\"},{\"name\":\"brand\",\"description\":\"Brand of the product.\"},{\"name\":\"id\",\"description\":\"Unique identifier for the product.\"},{\"name\":\"sku\",\"description\":\"Stock keeping unit of the product.\"},{\"name\":\"cost\",\"description\":\"Cost of the product.\"},{\"name\":\"distribution_center_id\",\"description\":\"Unique identifier for the distribution center where the product is stocked.\"}],\"queries\":[{\"sql\":\"SELECT\\n  id,\\n  name,\\n  retail_price,\\n  cost\\nFROM\\n  `thelook.products`\\nWHERE\\n  retail_price < cost * 0.5;\",\"description\":\"Identify products where the retail price is significantly lower than the cost, indicating a potential pricing error or clearance sale.\"},{\"sql\":\"SELECT\\n  distribution_center_id,\\n  AVG(cost) AS avg_cost\\nFROM\\n  `thelook.products`\\nGROUP BY\\n  distribution_center_id\\nHAVING\\n  AVG(cost) > (SELECT AVG(cost) + 2 * STDDEV(cost) FROM `thelook.products`);\",\"description\":\"Identify distribution centers with unusually high average product costs compared to other distribution centers.\"},{\"sql\":\"SELECT\\n  brand,\\n  AVG(cost) AS avg_cost\\nFROM\\n  `thelook.products`\\nGROUP BY\\n  brand\\nHAVING\\n  AVG(cost) > (SELECT AVG(cost) + 2*STDDEV(cost) FROM `thelook.products`);\",\"description\":\"Find brands with a significantly higher average cost than the overall average cost across all products.\"},{\"sql\":\"SELECT department FROM `thelook.products` GROUP BY department HAVING STDDEV(retail_price) > 0.1 * AVG(retail_price);\",\"description\":\"Identify the departments where the standard deviation of retail prices is greater than 10% of the average retail price for that department.\"},{\"sql\":\"SELECT category FROM `thelook.products` GROUP BY category HAVING ABS(AVG(retail_price) - (SELECT AVG(retail_price) FROM `thelook.products`)) > (SELECT STDDEV(retail_price) FROM `thelook.products`);\",\"description\":\"Identify the categories where the average retail price is more than one standard deviation away from the overall average retail price.\"},{\"sql\":\"SELECT department, SUM(retail_price * product_count) / SUM(product_count) AS weighted_avg_price FROM (SELECT department, category, AVG(retail_price) AS retail_price, COUNT(*) AS product_count FROM `thelook.products` GROUP BY department, category) GROUP BY department;\",\"description\":\"Calculate the weighted average retail price for each department, weighted by the number of products in each category within that department.\"},{\"sql\":\"SELECT department, AVG(retail_price) AS avg_retail_price, AVG(retail_price) / (SELECT AVG(retail_price) FROM `thelook.products`) AS percentage_contribution FROM `thelook.products` GROUP BY department;\",\"description\":\"Calculate the average retail price for each department, and then determine the percentage contribution of each department's average retail price to the overall average retail price across all departments.\"},{\"sql\":\"SELECT brand, department, AVG(cost) AS avg_cost, AVG(retail_price) AS avg_retail_price, (AVG(retail_price) - AVG(cost)) / AVG(cost) AS percentage_difference FROM `thelook.products` GROUP BY brand, department;\",\"description\":\"Calculate the average cost and retail price for each brand and department combination, and then determine the percentage difference between the average retail price and average cost.\"},{\"sql\":\"SELECT department FROM `thelook.products` GROUP BY department HAVING MAX(retail_price) - MIN(retail_price) > (SELECT AVG(retail_price) FROM `thelook.products`);\",\"description\":\"Find the departments where the difference between the maximum and minimum retail price is greater than the average retail price across all products.\"},{\"sql\":\"WITH BrandMedian AS (SELECT brand, APPROX_QUANTILES(retail_price, 2)[OFFSET(1)] AS median_price FROM `thelook.products` GROUP BY brand), OverallPercentiles AS (SELECT APPROX_QUANTILES(retail_price, 100)[OFFSET(75)] AS percentile_75 FROM `thelook.products`) SELECT bm.brand FROM BrandMedian bm, OverallPercentiles op WHERE bm.median_price > op.percentile_75;\",\"description\":\"Calculate the median retail price for each brand, and then find the brands where the median retail price is above the 75th percentile of all retail prices.\"},{\"sql\":\"SELECT\\n  CORR(retail_price, cost) AS price_cost_correlation\\nFROM\\n  `thelook.products`;\",\"description\":\"Calculate the correlation between retail price and cost to understand the pricing strategy.\"},{\"sql\":\"WITH AvgRetail AS (SELECT brand, AVG(retail_price) AS avg_retail FROM `thelook.products` GROUP BY brand ORDER BY avg_retail DESC LIMIT 3) SELECT ar.brand, APPROX_QUANTILES(p.cost, 2)[OFFSET(1)] AS median_cost FROM `thelook.products` p JOIN AvgRetail ar ON p.brand = ar.brand GROUP BY ar.brand;\",\"description\":\"Find the top 3 brands with the highest average retail price, and for each of these brands, calculate the median cost.\"},{\"sql\":\"SELECT category FROM `thelook.products` GROUP BY category HAVING MAX(retail_price) > 2 * MIN(retail_price);\",\"description\":\"Find the categories where the maximum retail price is more than twice the minimum retail price within that category.\"},{\"sql\":\"SELECT id, name, department, retail_price, PERCENT_RANK() OVER (PARTITION BY department ORDER BY retail_price) AS price_percentile FROM `thelook.products`;\",\"description\":\"Calculate the retail price percentile for each product within its department.\"},{\"sql\":\"SELECT department, name, retail_price FROM (SELECT department, name, retail_price, DENSE_RANK() OVER (PARTITION BY department ORDER BY retail_price DESC) AS rank_num FROM `thelook.products`) WHERE rank_num <= 5;\",\"description\":\"Find the top 5 most expensive products (based on retail price) in each department.\"},{\"sql\":\"SELECT department, AVG(POW(retail_price - avg_price, 3)) / POW(STDDEV(retail_price), 3) AS skewness FROM (SELECT department, retail_price, AVG(retail_price) OVER (PARTITION BY department) AS avg_price FROM `thelook.products`) GROUP BY department;\",\"description\":\"Calculate the skewness of retail prices for each department.\"},{\"sql\":\"SELECT\\n    p.department,\\n    AVG(p.cost) AS avg_cost,\\n    ANY_VALUE(p.name HAVING MAX p.retail_price) AS product_with_max_price\\n  FROM\\n    `thelook.products` p\\n  GROUP BY\\n    p.department\\nORDER BY avg_cost DESC\\nLIMIT 1;\",\"description\":\"Find the department with the highest average cost and the product with the maximum retail price within that department.\"},{\"sql\":\"SELECT\\n  COVAR_POP(retail_price, cost) AS retail_price_cost_covariance\\nFROM\\n  `thelook.products`;\",\"description\":\"Calculate the population covariance between retail price and cost.\"},{\"sql\":\"SELECT retail_price, CUME_DIST() OVER (ORDER BY retail_price) AS cumulative_distribution FROM `thelook.products`;\",\"description\":\"Calculate the cumulative distribution of retail prices across all products, showing the percentage of products with a retail price less than or equal to a given price.\"},{\"sql\":\"SELECT category, name, retail_price, RANK() OVER (PARTITION BY category ORDER BY retail_price DESC) AS price_rank FROM `thelook.products`;\",\"description\":\"Rank products within each category based on their retail price, and determine the product with the highest retail price in each category.\"},{\"sql\":\"WITH DepartmentMedians AS (SELECT department, PERCENTILE_CONT(retail_price, 0.5) OVER (PARTITION BY department) AS median_price FROM `thelook.products` GROUP BY department, retail_price), ProductDistances AS (SELECT p.name, p.department, p.retail_price, ABS(p.retail_price - dm.median_price) AS price_distance FROM `thelook.products` p JOIN DepartmentMedians dm ON p.department = dm.department) SELECT name, department, retail_price FROM ProductDistances QUALIFY ROW_NUMBER() OVER (PARTITION BY department ORDER BY price_distance) = 1;\",\"description\":\"Find the product with the retail price closest to the median retail price for each department.\"},{\"sql\":\"SELECT name, brand, retail_price, AVG(retail_price) OVER (PARTITION BY brand ORDER BY id ROWS BETWEEN 2 PRECEDING AND CURRENT ROW) AS moving_average_price FROM `thelook.products`;\",\"description\":\"Calculate a moving average of retail prices for each brand, considering the previous two products.\"},{\"sql\":\"SELECT brand FROM `thelook.products` GROUP BY brand HAVING COUNT(DISTINCT category) > 3;\",\"description\":\"Identify the brands that have products in more than 3 categories.\"},{\"sql\":\"SELECT\\n  id,\\n  name,\\n  retail_price,\\n  cost,\\n  retail_price - cost AS price_difference\\nFROM\\n  `thelook.products`\\nWHERE\\n  retail_price - cost > (SELECT AVG(retail_price - cost) + 2 * STDDEV(retail_price - cost) FROM `thelook.products`);\",\"description\":\"Identify products with a large difference between their retail price and cost, potentially indicating high-margin items or pricing errors.\"},{\"sql\":\"SELECT department, category, MAX(retail_price) - MIN(retail_price) AS price_range FROM `thelook.products` GROUP BY department, category;\",\"description\":\"Calculate the difference between the maximum and minimum retail price for each category within each department.\"},{\"sql\":\"SELECT department, APPROX_QUANTILES(retail_price, 4)[OFFSET(3)] - APPROX_QUANTILES(retail_price, 4)[OFFSET(1)] AS iqr FROM `thelook.products` GROUP BY department;\",\"description\":\"Calculate the interquartile range (IQR) of retail prices for each department.\"},{\"sql\":\"SELECT\\n  brand,\\n  MAX(retail_price) - MIN(retail_price) AS price_range\\nFROM\\n  `thelook.products`\\nGROUP BY\\n  brand;\",\"description\":\"Calculate the difference between the maximum and minimum retail price for each brand.\"},{\"sql\":\"SELECT\\n  APPROX_QUANTILES(retail_price, 4) AS retail_price_quantiles\\nFROM\\n  `thelook.products`;\",\"description\":\"Calculate the 25th, 50th, and 75th percentile of retail prices across all products.\"},{\"sql\":\"SELECT\\n  category,\\n  AVG(retail_price) AS avg_retail_price,\\n  COUNT(DISTINCT brand) AS distinct_brands\\nFROM\\n  `thelook.products`\\nGROUP BY\\n  category;\",\"description\":\"Calculate the average retail price for each category, and the number of distinct brands within each category.\"},{\"sql\":\"SELECT department, AVG(retail_price) AS avg_retail_price, FIRST_VALUE(name) OVER (PARTITION BY department ORDER BY retail_price DESC) AS most_expensive_product FROM `thelook.products` GROUP BY department, name, retail_price;\",\"description\":\"Calculate the average retail price of products within each department and identify the product with the highest retail price in each department.\"}],\"ddl\":\"CREATE TABLE `ai-learning-agents.thelook.products`\\n(\\n  id INT64 OPTIONS(description=\\\"Unique identifier for the product.\\\"),\\n  cost FLOAT64 OPTIONS(description=\\\"Cost of the product.\\\"),\\n  category STRING OPTIONS(description=\\\"Category that the product belongs to.\\\"),\\n  name STRING OPTIONS(description=\\\"Name of the product.\\\"),\\n  brand STRING OPTIONS(description=\\\"Brand of the product.\\\"),\\n  retail_price FLOAT64 OPTIONS(description=\\\"Retail price of the product.\\\"),\\n  department STRING OPTIONS(description=\\\"Department that the product belongs to.\\\"),\\n  sku STRING OPTIONS(description=\\\"Stock keeping unit of the product.\\\"),\\n  distribution_center_id INT64 OPTIONS(description=\\\"Unique identifier for the distribution center where the product is stocked.\\\")\\n)\\nOPTIONS(\\n  description=\\\"This table stores comprehensive details about products. It includes information on product categorization and branding. The table also contains pricing and cost data. This data can be used for inventory management and sales analysis.\\\",\\n  labels=[(\\\"dataplex-data-documentation-published-location\\\", \\\"us-central1\\\"), (\\\"dataplex-data-documentation-published-project\\\", \\\"ai-learning-agents\\\"), (\\\"dataplex-data-documentation-published-scan\\\", \\\"af1451be0-1392-405e-a88b-bc58600cb0e7\\\"), (\\\"dataplex-dp-published-project\\\", \\\"ai-learning-agents\\\"), (\\\"dataplex-dp-published-location\\\", \\\"us-central1\\\"), (\\\"dataplex-dp-published-scan\\\", \\\"ab58cf10a-1ccc-40eb-95b0-563f48b162e3\\\")]\\n);\",\"row_count\":29120,\"size_bytes\":4285975},{\"name\":\"ai-learning-agents.thelook.order_items\",\"overview\":\"This table tracks individual items within customer orders. It records the timestamps for when each item was created, shipped, delivered, and potentially returned. The table also stores the sale price for each item. It provides a comprehensive view of the lifecycle of each item in an order.\",\"fields\":[{\"name\":\"id\",\"description\":\"Unique identifier for the order item.\"},{\"name\":\"order_id\",\"description\":\"Identifier for the order to which the item belongs.\"},{\"name\":\"product_id\",\"description\":\"Identifier for the product associated with the order item.\"},{\"name\":\"returned_at\",\"description\":\"Timestamp indicating when the order item was returned.\"},{\"name\":\"status\",\"description\":\"Status of the order item.\"},{\"name\":\"user_id\",\"description\":\"Identifier for the user who placed the order.\"},{\"name\":\"inventory_item_id\",\"description\":\"Identifier for the inventory item associated with the order item.\"},{\"name\":\"sale_price\",\"description\":\"The price at which the order item was sold.\"},{\"name\":\"shipped_at\",\"description\":\"Timestamp indicating when the order item was shipped.\"},{\"name\":\"created_at\",\"description\":\"Timestamp indicating when the order item was created.\"},{\"name\":\"delivered_at\",\"description\":\"Timestamp indicating when the order item was delivered.\"}],\"queries\":[{\"sql\":\"SELECT user_id, COUNT(returned_at) AS return_count FROM `thelook.order_items` GROUP BY user_id HAVING COUNT(returned_at) > (SELECT AVG(return_count) FROM (SELECT user_id, COUNT(returned_at) AS return_count FROM `thelook.order_items` GROUP BY user_id));\",\"description\":\"Find users who have a significantly higher number of returned items compared to the average number of returned items across all users.\"},{\"sql\":\"SELECT product_id, AVG(sale_price) AS avg_sale_price FROM `thelook.order_items` GROUP BY product_id HAVING AVG(sale_price) > (SELECT APPROX_QUANTILES(sale_price, 100)[OFFSET(50)] FROM `thelook.order_items`);\",\"description\":\"Identify products with unusually high average sale prices compared to the median sale price across all products.\"},{\"sql\":\"SELECT id, created_at, delivered_at, TIMESTAMP_DIFF(delivered_at, created_at, DAY) AS delivery_time_days FROM `thelook.order_items` WHERE delivered_at IS NOT NULL AND TIMESTAMP_DIFF(delivered_at, created_at, DAY) > (SELECT APPROX_QUANTILES(TIMESTAMP_DIFF(delivered_at, created_at, DAY), 100)[OFFSET(50)] FROM `thelook.order_items` WHERE delivered_at IS NOT NULL);\",\"description\":\"Identify order items where the difference between the created_at and delivered_at timestamps is significantly larger than the median difference, indicating unusually long delivery times.\"},{\"sql\":\"WITH DailyAvg AS (\\n    SELECT DATE(created_at) AS order_date, AVG(sale_price) AS avg_daily_price\\n    FROM `thelook.order_items`\\n    WHERE created_at BETWEEN TIMESTAMP('2022-01-01 00:00:00') AND TIMESTAMP('2022-01-31 23:59:59')\\n    GROUP BY 1\\n),\\nOverallStats AS (\\n    SELECT PERCENTILE_CONT(avg_daily_price, 0.75) OVER() AS percentile_75\\n    FROM DailyAvg\\n)\\nSELECT da.order_date, da.avg_daily_price\\nFROM DailyAvg da, OverallStats os\\nWHERE da.avg_daily_price > os.percentile_75\\nORDER BY da.order_date;\",\"description\":\"Calculate the daily average sale price and identify days where the average sale price exceeds the 75th percentile of all sale prices.\"},{\"sql\":\"WITH ProductReturns AS (\\n    SELECT product_id,\\n           SUM(CASE WHEN returned_at IS NOT NULL THEN 1 ELSE 0 END) AS returned_count,\\n           COUNT(id) AS total_count\\n    FROM `thelook.order_items`\\n    WHERE created_at BETWEEN TIMESTAMP('2022-01-01 00:00:00') AND TIMESTAMP('2022-12-31 23:59:59')\\n    GROUP BY product_id\\n)\\nSELECT product_id, (returned_count / total_count) AS return_rate\\nFROM ProductReturns\\nORDER BY return_rate DESC\\nLIMIT 10;\",\"description\":\"Identify the products with the highest return rates by calculating the ratio of returned items to total items sold for each product.\"},{\"sql\":\"SELECT id, sale_price FROM `thelook.order_items` WHERE sale_price > (SELECT APPROX_QUANTILES(sale_price, 100)[OFFSET(50)] FROM `thelook.order_items` WHERE status = 'Complete') AND status = 'Complete';\",\"description\":\"Identify order items with unusually high sale prices compared to the median sale price, considering items with 'Complete' status.\"},{\"sql\":\"SELECT id, sale_price FROM `thelook.order_items` WHERE sale_price < (SELECT AVG(sale_price) FROM `thelook.order_items` WHERE status = 'Processing') AND status = 'Processing';\",\"description\":\"Find order items with sale prices significantly below the average sale price for items with 'Processing' status.\"},{\"sql\":\"SELECT user_id, SUM(sale_price) AS total_returned_sales FROM `thelook.order_items` WHERE returned_at IS NOT NULL GROUP BY user_id ORDER BY total_returned_sales DESC LIMIT 3;\",\"description\":\"Identify the top 3 users with the highest total sale price of returned items.\"},{\"sql\":\"SELECT user_id, COUNTIF(returned_at IS NOT NULL) / COUNT(*) AS return_ratio FROM `thelook.order_items` GROUP BY user_id;\",\"description\":\"Calculate the ratio of returned items to total items for each user.\"},{\"sql\":\"SELECT DATE(created_at) AS order_date, product_id, AVG(sale_price) OVER (PARTITION BY product_id ORDER BY DATE(created_at) ROWS BETWEEN 29 PRECEDING AND CURRENT ROW) AS rolling_avg_sale_price\\nFROM `thelook.order_items`\\nWHERE created_at BETWEEN TIMESTAMP('2022-01-01 00:00:00') AND TIMESTAMP('2022-03-31 23:59:59')\\nORDER BY product_id, order_date;\",\"description\":\"Calculate the rolling 30-day average of sale prices for each product.\"},{\"sql\":\"SELECT status, AVG(sale_price) AS avg_sale_price FROM `thelook.order_items` WHERE created_at >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 30 DAY) GROUP BY status;\",\"description\":\"Calculate the average sale price for each status, considering only items created in the last 30 days.\"},{\"sql\":\"SELECT AVG(TIMESTAMP_DIFF(returned_at, created_at, DAY)) AS avg_return_time FROM `thelook.order_items` WHERE returned_at IS NOT NULL;\",\"description\":\"Calculate the average time difference between created_at and returned_at for returned items.\"},{\"sql\":\"SELECT\\n  status,\\n  VAR_POP(sale_price) AS sale_price_variance\\nFROM\\n  `thelook.order_items`\\nGROUP BY\\n  status;\",\"description\":\"Calculate the population variance of sale prices, grouped by the order status, to see how price varies across different order statuses.\"},{\"sql\":\"SELECT\\n  COUNTIF(sale_price > 69.949997) * 100.0 / COUNT(*) AS percentage_above_75th_percentile\\nFROM\\n  `thelook.order_items`;\",\"description\":\"Calculate the percentage of items with a sale price above the 75th percentile of sale prices.\"},{\"sql\":\"SELECT AVG(sale_price) FROM `thelook.order_items` WHERE shipped_at IS NOT NULL AND delivered_at IS NULL;\",\"description\":\"Calculate the average sale price for order items that were shipped but not yet delivered.\"},{\"sql\":\"SELECT status, APPROX_QUANTILES(sale_price, 2)[OFFSET(1)] AS median_sale_price FROM `thelook.order_items` GROUP BY status;\",\"description\":\"Calculate the median sale price for each order status.\"},{\"sql\":\"SELECT DISTINCT product_id FROM `thelook.order_items` WHERE sale_price BETWEEN (SELECT PERCENTILE_CONT(sale_price, 0.25) OVER() FROM `thelook.order_items` LIMIT 1) AND (SELECT PERCENTILE_CONT(sale_price, 0.75) OVER() FROM `thelook.order_items` LIMIT 1);\",\"description\":\"Find the products with a sale price between the 25th and 75th percentile.\"},{\"sql\":\"SELECT AVG(TIMESTAMP_DIFF(delivered_at, shipped_at, DAY)) AS avg_delivery_time FROM `thelook.order_items` WHERE status = 'Complete' AND delivered_at IS NOT NULL AND shipped_at IS NOT NULL;\",\"description\":\"Calculate the average time difference between shipped and delivered dates for complete orders.\"},{\"sql\":\"SELECT product_id, MAX(sale_price) - MIN(sale_price) AS price_range FROM `thelook.order_items` GROUP BY product_id;\",\"description\":\"Calculate the difference between the maximum and minimum sale price for each product.\"},{\"sql\":\"SELECT AVG(DATETIME_DIFF(DATETIME(shipped_at), DATETIME(created_at), DAY)) AS avg_shipping_time_days\\nFROM `thelook.order_items`\\nWHERE created_at BETWEEN TIMESTAMP('2022-01-01 00:00:00') AND TIMESTAMP('2022-12-31 23:59:59') AND shipped_at IS NOT NULL;\",\"description\":\"Calculate the time difference between the created_at and shipped_at timestamps for each order item and determine the average shipping time.\"},{\"sql\":\"SELECT product_id, STDDEV_POP(sale_price) AS price_std_dev FROM `thelook.order_items` GROUP BY product_id ORDER BY price_std_dev DESC LIMIT 5;\",\"description\":\"Find the product IDs with the highest standard deviation in sale price.\"},{\"sql\":\"SELECT COUNTIF(sale_price > (SELECT PERCENTILE_CONT(sale_price, 0.75) OVER() FROM `thelook.order_items` LIMIT 1)) / COUNT(*) AS percentage FROM `thelook.order_items`;\",\"description\":\"Determine the percentage of orders with a sale price greater than the 75th percentile.\"},{\"sql\":\"SELECT order_id FROM `thelook.order_items` WHERE sale_price > 2 * (SELECT AVG(sale_price) FROM `thelook.order_items`);\",\"description\":\"Find the order IDs where the sale price is more than twice the average sale price.\"},{\"sql\":\"SELECT CORR(user_id, sale_price) FROM `thelook.order_items`;\",\"description\":\"Calculate the correlation between user ID and sale price.\"},{\"sql\":\"SELECT COUNTIF(TIMESTAMP_DIFF(shipped_at, created_at, DAY) <= 7) / COUNT(*) AS percentage FROM `thelook.order_items` WHERE shipped_at IS NOT NULL;\",\"description\":\"Determine the percentage of orders that were shipped within 7 days of creation.\"},{\"sql\":\"SELECT order_id FROM `thelook.order_items` WHERE sale_price > (SELECT APPROX_QUANTILES(sale_price, 2)[OFFSET(1)] FROM `thelook.order_items`) GROUP BY order_id HAVING COUNT(*) > 3;\",\"description\":\"Identify the order IDs with more than 3 items having a sale price above the median sale price.\"},{\"sql\":\"SELECT product_id, AVG(sale_price) AS avg_sale_price FROM `thelook.order_items` WHERE delivered_at IS NOT NULL GROUP BY product_id ORDER BY avg_sale_price DESC LIMIT 5;\",\"description\":\"Find the top 5 product IDs with the highest average sale price for items that were eventually delivered.\"},{\"sql\":\"SELECT COUNTIF(shipped_at IS NOT NULL) / COUNT(*) AS percentage FROM `thelook.order_items` WHERE sale_price < (SELECT PERCENTILE_CONT(sale_price, 0.25) OVER() FROM `thelook.order_items` LIMIT 1);\",\"description\":\"Determine the percentage of orders with a sale price below the 25th percentile that were shipped.\"},{\"sql\":\"SELECT DISTINCT user_id FROM `thelook.order_items` WHERE sale_price > 900;\",\"description\":\"Find the user IDs with at least one order item having a sale price greater than 900.\"},{\"sql\":\"SELECT COUNT(DISTINCT order_id) FROM `thelook.order_items` WHERE order_id IN (SELECT order_id FROM `thelook.order_items` GROUP BY order_id HAVING MIN(status) = 'Complete' AND MAX(status) = 'Complete');\",\"description\":\"Determine the number of orders where all items have a status of 'Complete'.\"}],\"ddl\":\"CREATE TABLE `ai-learning-agents.thelook.order_items`\\n(\\n  id INT64 OPTIONS(description=\\\"Unique identifier for the order item.\\\"),\\n  order_id INT64 OPTIONS(description=\\\"Identifier for the order to which the item belongs.\\\"),\\n  user_id INT64 OPTIONS(description=\\\"Identifier for the user who placed the order.\\\"),\\n  product_id INT64 OPTIONS(description=\\\"Identifier for the product associated with the order item.\\\"),\\n  inventory_item_id INT64 OPTIONS(description=\\\"Identifier for the inventory item associated with the order item.\\\"),\\n  status STRING OPTIONS(description=\\\"Status of the order item.\\\"),\\n  created_at TIMESTAMP OPTIONS(description=\\\"Timestamp indicating when the order item was created.\\\"),\\n  shipped_at TIMESTAMP OPTIONS(description=\\\"Timestamp indicating when the order item was shipped.\\\"),\\n  delivered_at TIMESTAMP OPTIONS(description=\\\"Timestamp indicating when the order item was delivered.\\\"),\\n  returned_at TIMESTAMP OPTIONS(description=\\\"Timestamp indicating when the order item was returned.\\\"),\\n  sale_price FLOAT64 OPTIONS(description=\\\"The price at which the order item was sold.\\\")\\n)\\nOPTIONS(\\n  description=\\\"This table stores data about individual items within customer orders. It tracks when each item was ordered, shipped, and delivered. The table also includes pricing information for each item. It provides a record of the status of each item in an order.\\\",\\n  labels=[(\\\"dataplex-data-documentation-published-location\\\", \\\"us-central1\\\"), (\\\"dataplex-dp-published-scan\\\", \\\"aedb784a7-c153-4f58-b89c-a2a9da201127\\\"), (\\\"dataplex-dp-published-project\\\", \\\"ai-learning-agents\\\"), (\\\"dataplex-dp-published-location\\\", \\\"us-central1\\\"), (\\\"dataplex-data-documentation-published-project\\\", \\\"ai-learning-agents\\\"), (\\\"dataplex-data-documentation-published-scan\\\", \\\"a86a52b65-617e-4358-96b8-12353643d393\\\")]\\n);\",\"row_count\":181396,\"size_bytes\":13614998}]}))</script>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use for BQ Query Optimizer Agent"
      ],
      "metadata": {
        "id": "XyTAiO8AQFQD"
      },
      "id": "XyTAiO8AQFQD"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import storage\n",
        "\n",
        "def write_json_to_gcs(bucket_name: str, json_data: str, file_name: str) -> None:\n",
        "    \"\"\"\n",
        "    Writes a JSON string to a file in a Google Cloud Storage bucket.\n",
        "\n",
        "    Args:\n",
        "        bucket_name (str): The name of the GCS bucket.\n",
        "        json_data (str): The JSON data as a string.\n",
        "        file_name (str): The BigQuery dataset name.\n",
        "    \"\"\"\n",
        "    client = storage.Client()\n",
        "    bucket = client.bucket(bucket_name)\n",
        "    blob_name = f\"{file_name}\"\n",
        "    blob = bucket.blob(blob_name)\n",
        "    blob.upload_from_string(json_data, content_type=\"application/json\")\n",
        "    print(f\"JSON data successfully written to gs://{bucket_name}/{blob_name}\")"
      ],
      "metadata": {
        "id": "UGB6mgCNOrYk"
      },
      "id": "UGB6mgCNOrYk",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_query_optimizer_json(\n",
        "    project_id,\n",
        "    dataset_name,\n",
        "    allowlist=[],\n",
        "    blocklist=[]\n",
        ") -> dict:\n",
        "    \"\"\"Create dict of only the stuff we want to use for Query Optimizer\n",
        "        1. project_id\n",
        "        2. dataset_name\n",
        "        3. dataset_description\n",
        "        4. dataset_location\n",
        "        5. dataset_tables\n",
        "            5.a name\n",
        "            5.b overview\n",
        "            5.c ddl\n",
        "        6. dataset_relationships\n",
        "    \"\"\"\n",
        "    ds_details = (\n",
        "        KEDatasetScanHelper(PROJECT_ID, DATASET_NAME)\n",
        "        .with_table_list_constraints(allowlist, blocklist)\n",
        "        .with_table_ddls(True)\n",
        "        .with_table_counts(True)\n",
        "    ).dataset_all_details\n",
        "\n",
        "    details_dict = json.loads(ds_details.model_dump_json())\n",
        "\n",
        "    del details_dict['dataset_queries']\n",
        "    del details_dict['dataset_business_glossary']\n",
        "\n",
        "    for table in details_dict['dataset_tables']:\n",
        "        del table['fields'] # they're in the ddl\n",
        "        del table['queries']\n",
        "\n",
        "    return json.dumps(details_dict)"
      ],
      "metadata": {
        "id": "JN6N_3bQ_lgM"
      },
      "id": "JN6N_3bQ_lgM",
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Write BQKE everything to gcs bucket\n",
        "\n",
        "result_json = make_query_optimizer_json(PROJECT_ID, DATASET_NAME, blocklist=['sales'])\n",
        "write_json_to_gcs(\n",
        "    bucket_name=RESULTS_BUCKET,\n",
        "    json_data=result_json,\n",
        "    file_name=f\"QUERY_OPTIMIZER_METADATA.{PROJECT_ID}.{DATASET_NAME}.json\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWOWXXxEEUDk",
        "outputId": "77ed1811-e40a-487c-de72-54da3fbacdb4"
      },
      "id": "RWOWXXxEEUDk",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JSON data successfully written to gs://dataset_metadata_results/QUERY_OPTIMIZER_METADATA.ai-learning-agents.thelook.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example Output"
      ],
      "metadata": {
        "id": "kapNbGnfAD37"
      },
      "id": "kapNbGnfAD37"
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        " {\n",
        "  \"project_id\": \"ai-learning-agents\",\n",
        "  \"dataset_name\": \"thelook\",\n",
        "  \"dataset_location\": \"us-central1\",\n",
        "  \"dataset_description\": \"This dataset contains comprehensive information about e-commerce operations, encompassing user behavior, product details, order management, and inventory tracking. It provides a detailed view of customer interactions on the website, including browsing activity and order placements. The dataset includes granular information about products, such as pricing, category, and distribution center location. Order details are recorded, capturing the full lifecycle from creation to delivery and returns. Inventory levels and sales transactions are also tracked, allowing for analysis of product performance and supply chain efficiency. This data enables in-depth analysis of sales trends, user demographics, and operational effectiveness.\",\n",
        "  \"dataset_relationships\": [\n",
        "    {\n",
        "      \"table1\": \"ai-learning-agents.thelook.order_items\",\n",
        "      \"table2\": \"ai-learning-agents.thelook.orders\",\n",
        "      \"relationship\": \"ai-learning-agents.thelook.order_items.order_id = ai-learning-agents.thelook.orders.order_id\",\n",
        "      \"source\": \"LLM-inferred\"\n",
        "    },\n",
        "    {\n",
        "      \"table1\": \"ai-learning-agents.thelook.inventory_items\",\n",
        "      \"table2\": \"ai-learning-agents.thelook.distribution_centers\",\n",
        "      \"relationship\": \"ai-learning-agents.thelook.inventory_items.product_distribution_center_id = ai-learning-agents.thelook.distribution_centers.id\",\n",
        "      \"source\": \"LLM-inferred\"\n",
        "    },\n",
        "    {\n",
        "      \"table1\": \"ai-learning-agents.thelook.order_items\",\n",
        "      \"table2\": \"ai-learning-agents.thelook.inventory_items\",\n",
        "      \"relationship\": \"ai-learning-agents.thelook.order_items.inventory_item_id = ai-learning-agents.thelook.inventory_items.id\",\n",
        "      \"source\": \"LLM-inferred\"\n",
        "    },\n",
        "    {\n",
        "      \"table1\": \"ai-learning-agents.thelook.order_items\",\n",
        "      \"table2\": \"ai-learning-agents.thelook.products\",\n",
        "      \"relationship\": \"ai-learning-agents.thelook.order_items.product_id = ai-learning-agents.thelook.products.id\",\n",
        "      \"source\": \"LLM-inferred\"\n",
        "    },\n",
        "    {\n",
        "      \"table1\": \"ai-learning-agents.thelook.orders\",\n",
        "      \"table2\": \"ai-learning-agents.thelook.users\",\n",
        "      \"relationship\": \"ai-learning-agents.thelook.orders.user_id = ai-learning-agents.thelook.users.id\",\n",
        "      \"source\": \"LLM-inferred\"\n",
        "    },\n",
        "    {\n",
        "      \"table1\": \"ai-learning-agents.thelook.order_items\",\n",
        "      \"table2\": \"ai-learning-agents.thelook.users\",\n",
        "      \"relationship\": \"ai-learning-agents.thelook.order_items.user_id = ai-learning-agents.thelook.users.id\",\n",
        "      \"source\": \"LLM-inferred\"\n",
        "    },\n",
        "    {\n",
        "      \"table1\": \"ai-learning-agents.thelook.inventory_items\",\n",
        "      \"table2\": \"ai-learning-agents.thelook.products\",\n",
        "      \"relationship\": \"ai-learning-agents.thelook.inventory_items.product_id = ai-learning-agents.thelook.products.id\",\n",
        "      \"source\": \"LLM-inferred\"\n",
        "    },\n",
        "    {\n",
        "      \"table1\": \"ai-learning-agents.thelook.distribution_centers\",\n",
        "      \"table2\": \"ai-learning-agents.thelook.products\",\n",
        "      \"relationship\": \"ai-learning-agents.thelook.distribution_centers.id = ai-learning-agents.thelook.products.distribution_center_id\",\n",
        "      \"source\": \"LLM-inferred\"\n",
        "    },\n",
        "    {\n",
        "      \"table1\": \"ai-learning-agents.thelook.events\",\n",
        "      \"table2\": \"ai-learning-agents.thelook.users\",\n",
        "      \"relationship\": \"ai-learning-agents.thelook.events.user_id = ai-learning-agents.thelook.users.id\",\n",
        "      \"source\": \"LLM-inferred\"\n",
        "    }\n",
        "  ],\n",
        "  \"dataset_tables\": [\n",
        "    {\n",
        "      \"name\": \"ai-learning-agents.thelook.events\",\n",
        "      \"overview\": \"This table stores records of user interactions and activities on a website or application. It captures various details associated with each event. The data includes information about the user, the event itself, and the context in which it occurred. This allows for analysis of user behavior, tracking of key performance indicators, and identification of trends. The table supports investigations into user journeys and event patterns.\",\n",
        "      \"ddl\": \"CREATE TABLE `ai-learning-agents.thelook.events`\\n(\\n  id INT64 OPTIONS(description=\\\"Unique identifier for the event.\\\"),\\n  user_id INT64 OPTIONS(description=\\\"Unique identifier for the user.\\\"),\\n  sequence_number INT64 OPTIONS(description=\\\"The order of the event within a user session.\\\"),\\n  session_id STRING OPTIONS(description=\\\"Unique identifier for the user's session.\\\"),\\n  created_at TIMESTAMP OPTIONS(description=\\\"Timestamp indicating when the event occurred.\\\"),\\n  ip_address STRING OPTIONS(description=\\\"The IP address of the user who triggered the event.\\\"),\\n  city STRING OPTIONS(description=\\\"The city from which the event originated.\\\"),\\n  state STRING OPTIONS(description=\\\"The state or status associated with the event.\\\"),\\n  postal_code STRING OPTIONS(description=\\\"The postal code associated with the event's location.\\\"),\\n  browser STRING OPTIONS(description=\\\"The web browser used by the user.\\\"),\\n  traffic_source STRING OPTIONS(description=\\\"The origin or source of the website traffic.\\\"),\\n  uri STRING OPTIONS(description=\\\"The specific web address or resource being accessed.\\\"),\\n  event_type STRING OPTIONS(description=\\\"The category or type of user event that occurred.\\\")\\n)\\nOPTIONS(\\n  description=\\\"This table stores records of user activity on a website or application. It captures various events triggered by user interactions. The data includes details about the user's location, session, and browser. This information is used to understand user behavior and track website traffic.\\\",\\n  labels=[(\\\"dataplex-data-documentation-published-location\\\", \\\"us-central1\\\"), (\\\"dataplex-dp-published-scan\\\", \\\"ab20d79d1-33b8-4810-b06f-14a5280cbb00\\\"), (\\\"dataplex-dp-published-project\\\", \\\"ai-learning-agents\\\"), (\\\"dataplex-dp-published-location\\\", \\\"us-central1\\\"), (\\\"dataplex-data-documentation-published-project\\\", \\\"ai-learning-agents\\\"), (\\\"dataplex-data-documentation-published-scan\\\", \\\"a5f1f8396-cfad-4bc8-a25d-187c34201858\\\")]\\n);\",\n",
        "      \"row_count\": 2425480,\n",
        "      \"size_bytes\": 385142492\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"ai-learning-agents.thelook.distribution_centers\",\n",
        "      \"overview\": \"This table stores information about the locations of distribution centers. It provides a central repository for managing distribution center data. The table facilitates spatial analysis and mapping of these centers. It supports the identification and management of distribution center locations.\",\n",
        "      \"ddl\": \"CREATE TABLE `ai-learning-agents.thelook.distribution_centers`\\n(\\n  id INT64 OPTIONS(description=\\\"Unique identifier for the distribution center.\\\"),\\n  name STRING OPTIONS(description=\\\"Name of the distribution center.\\\"),\\n  latitude FLOAT64 OPTIONS(description=\\\"Latitude coordinate of the distribution center.\\\"),\\n  longitude FLOAT64 OPTIONS(description=\\\"Longitude coordinate of the distribution center.\\\"),\\n  distribution_center_geom GEOGRAPHY OPTIONS(description=\\\"Geographical location of the distribution center.\\\")\\n)\\nOPTIONS(\\n  description=\\\"This table stores information about distribution centers. It includes location data for each center. The data allows for spatial analysis and mapping. It also supports identifying and managing distribution center locations.\\\",\\n  labels=[(\\\"dataplex-data-documentation-published-location\\\", \\\"us-central1\\\"), (\\\"dataplex-data-documentation-published-project\\\", \\\"ai-learning-agents\\\"), (\\\"dataplex-data-documentation-published-scan\\\", \\\"add9d8061-6552-4d49-81bc-2bc3943a5b79\\\"), (\\\"dataplex-dp-published-project\\\", \\\"ai-learning-agents\\\"), (\\\"dataplex-dp-published-location\\\", \\\"us-central1\\\"), (\\\"dataplex-dp-published-scan\\\", \\\"a2886da71-0f35-4192-8742-bd9b1ffc4ddd\\\")]\\n);\",\n",
        "      \"row_count\": 10,\n",
        "      \"size_bytes\": 809\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"ai-learning-agents.thelook.inventory_items\",\n",
        "      \"overview\": \"This table tracks the inventory of products. It records details about each item, including its cost and retail price. The table also associates each item with a specific product and distribution center. This allows for analysis of inventory levels and product performance.\",\n",
        "      \"ddl\": \"CREATE TABLE `ai-learning-agents.thelook.inventory_items`\\n(\\n  id INT64 OPTIONS(description=\\\"Unique identifier for the inventory item.\\\"),\\n  product_id INT64 OPTIONS(description=\\\"Identifier for the product.\\\"),\\n  created_at TIMESTAMP OPTIONS(description=\\\"Timestamp indicating when the inventory item was created.\\\"),\\n  sold_at TIMESTAMP OPTIONS(description=\\\"Timestamp indicating when the inventory item was sold.\\\"),\\n  cost FLOAT64 OPTIONS(description=\\\"Cost of the inventory item.\\\"),\\n  product_category STRING OPTIONS(description=\\\"Category of the product.\\\"),\\n  product_name STRING OPTIONS(description=\\\"Name of the product.\\\"),\\n  product_brand STRING OPTIONS(description=\\\"Brand of the product.\\\"),\\n  product_retail_price FLOAT64 OPTIONS(description=\\\"Retail price of the product.\\\"),\\n  product_department STRING OPTIONS(description=\\\"Department the product belongs to.\\\"),\\n  product_sku STRING OPTIONS(description=\\\"Stock keeping unit for the product.\\\"),\\n  product_distribution_center_id INT64 OPTIONS(description=\\\"Identifier for the distribution center where the product is located.\\\")\\n)\\nOPTIONS(\\n  description=\\\"This table tracks the inventory of products. It records details about each item, including its cost and retail price. The table also associates each item with a specific product and distribution center. This allows for analysis of inventory levels and product performance.\\\",\\n  labels=[(\\\"dataplex-data-documentation-published-location\\\", \\\"us-central1\\\"), (\\\"dataplex-data-documentation-published-project\\\", \\\"ai-learning-agents\\\"), (\\\"dataplex-data-documentation-published-scan\\\", \\\"ada6bf718-997a-49c9-9c39-420e79abe1cc\\\")]\\n);\",\n",
        "      \"row_count\": 489838,\n",
        "      \"size_bytes\": 81275603\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"ai-learning-agents.thelook.orders\",\n",
        "      \"overview\": \"This table stores information about customer orders. It tracks the status of each order throughout its lifecycle. The table records timestamps for when an order was created, shipped, delivered, and potentially returned. It also includes data related to the user who placed the order.\",\n",
        "      \"ddl\": \"CREATE TABLE `ai-learning-agents.thelook.orders`\\n(\\n  order_id INT64 OPTIONS(description=\\\"Unique identifier for the order.\\\"),\\n  user_id INT64 OPTIONS(description=\\\"Unique identifier for the user who placed the order.\\\"),\\n  status STRING OPTIONS(description=\\\"Status of the order.\\\"),\\n  gender STRING OPTIONS(description=\\\"Gender of the user who placed the order.\\\"),\\n  created_at TIMESTAMP OPTIONS(description=\\\"Timestamp indicating when the order was created.\\\"),\\n  returned_at TIMESTAMP OPTIONS(description=\\\"Timestamp indicating when the order was returned.\\\"),\\n  shipped_at TIMESTAMP OPTIONS(description=\\\"Timestamp indicating when the order was shipped.\\\"),\\n  delivered_at TIMESTAMP OPTIONS(description=\\\"Timestamp indicating when the order was delivered.\\\"),\\n  num_of_item INT64 OPTIONS(description=\\\"Number of items in the order.\\\")\\n)\\nOPTIONS(\\n  description=\\\"This table stores information about customer orders. It tracks the status of each order throughout its lifecycle. The table records timestamps for when an order was created, shipped, delivered, and potentially returned. It also includes data related to the user who placed the order.\\\",\\n  labels=[(\\\"dataplex-data-documentation-published-location\\\", \\\"us-central1\\\"), (\\\"dataplex-data-documentation-published-project\\\", \\\"ai-learning-agents\\\"), (\\\"dataplex-data-documentation-published-scan\\\", \\\"ab06ef464-2420-4997-b3c0-7cfa94bdad28\\\")]\\n);\",\n",
        "      \"row_count\": 125105,\n",
        "      \"size_bytes\": 6762580\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"ai-learning-agents.thelook.users\",\n",
        "      \"overview\": \"This table stores user information. It includes demographic details and geographic location. The table also tracks the source from which users originate. This data can be used for user segmentation and targeted marketing efforts.\",\n",
        "      \"ddl\": \"CREATE TABLE `ai-learning-agents.thelook.users`\\n(\\n  id INT64 OPTIONS(description=\\\"Unique identifier for the user.\\\"),\\n  first_name STRING OPTIONS(description=\\\"First name of the user.\\\"),\\n  last_name STRING OPTIONS(description=\\\"Last name of the user.\\\"),\\n  email STRING OPTIONS(description=\\\"Email address of the user.\\\"),\\n  age INT64 OPTIONS(description=\\\"Age of the user.\\\"),\\n  gender STRING OPTIONS(description=\\\"Gender of the user.\\\"),\\n  state STRING OPTIONS(description=\\\"State of the user.\\\"),\\n  street_address STRING OPTIONS(description=\\\"Street address of the user.\\\"),\\n  postal_code STRING OPTIONS(description=\\\"Postal code of the user's address.\\\"),\\n  city STRING OPTIONS(description=\\\"City of the user.\\\"),\\n  country STRING OPTIONS(description=\\\"Country of the user.\\\"),\\n  latitude FLOAT64 OPTIONS(description=\\\"Latitude coordinate of the user's location.\\\"),\\n  longitude FLOAT64 OPTIONS(description=\\\"Longitude coordinate of the user's location.\\\"),\\n  traffic_source STRING OPTIONS(description=\\\"Source from which the user originated.\\\"),\\n  created_at TIMESTAMP OPTIONS(description=\\\"Timestamp when the user account was created.\\\"),\\n  user_geom GEOGRAPHY OPTIONS(description=\\\"Geographic data representing the user's location.\\\")\\n)\\nOPTIONS(\\n  description=\\\"This table stores user information. It includes demographic details and geographic location. The table also tracks the source from which users originate. This data can be used for user segmentation and targeted marketing efforts.\\\",\\n  labels=[(\\\"dataplex-data-documentation-published-location\\\", \\\"us-central1\\\"), (\\\"dataplex-dp-published-scan\\\", \\\"ac26a7027-1ec9-4ebe-a5e6-c0a41ab6108d\\\"), (\\\"dataplex-dp-published-project\\\", \\\"ai-learning-agents\\\"), (\\\"dataplex-dp-published-location\\\", \\\"us-central1\\\"), (\\\"dataplex-data-documentation-published-project\\\", \\\"ai-learning-agents\\\"), (\\\"dataplex-data-documentation-published-scan\\\", \\\"a62faff99-c9a5-4687-a4fa-8687859916ec\\\")]\\n);\",\n",
        "      \"row_count\": 100000,\n",
        "      \"size_bytes\": 19813856\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"ai-learning-agents.thelook.users_view\",\n",
        "      \"overview\": \"This table stores user information. It includes details that can be used for user segmentation and demographic analysis. The data allows for geographic analysis of users. The table also tracks the source from which users originated. This information supports marketing and customer relationship management efforts.\",\n",
        "      \"ddl\": null,\n",
        "      \"row_count\": null,\n",
        "      \"size_bytes\": null\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"ai-learning-agents.thelook.products\",\n",
        "      \"overview\": \"This table stores comprehensive details about products. It includes information on product categorization and branding. The table also contains pricing and cost data. This data can be used for inventory management and sales analysis.\",\n",
        "      \"ddl\": \"CREATE TABLE `ai-learning-agents.thelook.products`\\n(\\n  id INT64 OPTIONS(description=\\\"Unique identifier for the product.\\\"),\\n  cost FLOAT64 OPTIONS(description=\\\"Cost of the product.\\\"),\\n  category STRING OPTIONS(description=\\\"Category that the product belongs to.\\\"),\\n  name STRING OPTIONS(description=\\\"Name of the product.\\\"),\\n  brand STRING OPTIONS(description=\\\"Brand of the product.\\\"),\\n  retail_price FLOAT64 OPTIONS(description=\\\"Retail price of the product.\\\"),\\n  department STRING OPTIONS(description=\\\"Department that the product belongs to.\\\"),\\n  sku STRING OPTIONS(description=\\\"Stock keeping unit of the product.\\\"),\\n  distribution_center_id INT64 OPTIONS(description=\\\"Unique identifier for the distribution center where the product is stocked.\\\")\\n)\\nOPTIONS(\\n  description=\\\"This table stores comprehensive details about products. It includes information on product categorization and branding. The table also contains pricing and cost data. This data can be used for inventory management and sales analysis.\\\",\\n  labels=[(\\\"dataplex-data-documentation-published-location\\\", \\\"us-central1\\\"), (\\\"dataplex-data-documentation-published-project\\\", \\\"ai-learning-agents\\\"), (\\\"dataplex-data-documentation-published-scan\\\", \\\"af1451be0-1392-405e-a88b-bc58600cb0e7\\\"), (\\\"dataplex-dp-published-project\\\", \\\"ai-learning-agents\\\"), (\\\"dataplex-dp-published-location\\\", \\\"us-central1\\\"), (\\\"dataplex-dp-published-scan\\\", \\\"ab58cf10a-1ccc-40eb-95b0-563f48b162e3\\\")]\\n);\",\n",
        "      \"row_count\": 29120,\n",
        "      \"size_bytes\": 4285975\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"ai-learning-agents.thelook.order_items\",\n",
        "      \"overview\": \"This table tracks individual items within customer orders. It records the timestamps for when each item was created, shipped, delivered, and potentially returned. The table also stores the sale price for each item. It provides a comprehensive view of the lifecycle of each item in an order.\",\n",
        "      \"ddl\": \"CREATE TABLE `ai-learning-agents.thelook.order_items`\\n(\\n  id INT64 OPTIONS(description=\\\"Unique identifier for the order item.\\\"),\\n  order_id INT64 OPTIONS(description=\\\"Identifier for the order to which the item belongs.\\\"),\\n  user_id INT64 OPTIONS(description=\\\"Identifier for the user who placed the order.\\\"),\\n  product_id INT64 OPTIONS(description=\\\"Identifier for the product associated with the order item.\\\"),\\n  inventory_item_id INT64 OPTIONS(description=\\\"Identifier for the inventory item associated with the order item.\\\"),\\n  status STRING OPTIONS(description=\\\"Status of the order item.\\\"),\\n  created_at TIMESTAMP OPTIONS(description=\\\"Timestamp indicating when the order item was created.\\\"),\\n  shipped_at TIMESTAMP OPTIONS(description=\\\"Timestamp indicating when the order item was shipped.\\\"),\\n  delivered_at TIMESTAMP OPTIONS(description=\\\"Timestamp indicating when the order item was delivered.\\\"),\\n  returned_at TIMESTAMP OPTIONS(description=\\\"Timestamp indicating when the order item was returned.\\\"),\\n  sale_price FLOAT64 OPTIONS(description=\\\"The price at which the order item was sold.\\\")\\n)\\nOPTIONS(\\n  description=\\\"This table stores data about individual items within customer orders. It tracks when each item was ordered, shipped, and delivered. The table also includes pricing information for each item. It provides a record of the status of each item in an order.\\\",\\n  labels=[(\\\"dataplex-data-documentation-published-location\\\", \\\"us-central1\\\"), (\\\"dataplex-dp-published-scan\\\", \\\"aedb784a7-c153-4f58-b89c-a2a9da201127\\\"), (\\\"dataplex-dp-published-project\\\", \\\"ai-learning-agents\\\"), (\\\"dataplex-dp-published-location\\\", \\\"us-central1\\\"), (\\\"dataplex-data-documentation-published-project\\\", \\\"ai-learning-agents\\\"), (\\\"dataplex-data-documentation-published-scan\\\", \\\"a86a52b65-617e-4358-96b8-12353643d393\\\")]\\n);\",\n",
        "      \"row_count\": 181396,\n",
        "      \"size_bytes\": 13614998\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "HYoYk1ld_zBW"
      },
      "id": "HYoYk1ld_zBW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Agent Prompt"
      ],
      "metadata": {
        "id": "wQdeLgR9AJl_"
      },
      "id": "wQdeLgR9AJl_"
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "You are a Google BigQuery Expert and you are highly skilled at evaluating and optimizing queries that users provide to you.\n",
        "Users provide queries to you, and you use all relevant information available to you to analyze the query and identify ways to make\n",
        "  more cost performant by minimizing the amount of data scanned and the amount of data processed.\n",
        "When a user provides a query to you, you will identify the PROJECT_ID and DATASET_NAME the query is being run on.\n",
        "If that information is not obvious from the query itself, then interact with the user to try to get that information.\n",
        "\n",
        "You will use that information in an attempt to access metadata about the dataset that the query is being run on.\n",
        "\n",
        "You will have access to a gcs storage bucket in which metadata about the dataset may exist.\n",
        "The storage bucket is \"gs://dataset_metadata_results\"\n",
        "Metadata files are named according to the following naming convention:\n",
        "    - QUERY_OPTIMIZER_METADATA.{PROJECT_ID}.{DATASET_NAME}.json\n",
        "\n",
        "Be helpful in the user interaction where you attempt to identifying PROJECT_ID and DATASET_NAME.\n",
        "You are able to suggest combinations by scanning the contents of the storage bucket and listing PROJECT_ID and DATASET_NAME pairs you have metadata for.\n",
        "\n",
        "If a matching metadata file *does not exist* in the bucket, use your best judgement to optimize the query.\n",
        "If a matching metadata file *does exist* in the bucket, use that metadata to optimize the query.\n",
        "\n",
        "If metadata exists, it will be in JSON format and will contains a wealth of information about the dataset, including:\n",
        "    - The name of the dataset\n",
        "    - The description of the dataset\n",
        "    - The location of the dataset\n",
        "    - A list of tables in the dataset\n",
        "    - The relationships between the tables in the dataset\n",
        "\n",
        "For each of the tables, you will get the following information:\n",
        "    - The name of the table\n",
        "    - The description of the table\n",
        "    - The ddl for the table\n",
        "\n",
        "Pay special attention to any table ddls that are provided.\n",
        "The table ddls will contain:\n",
        "    - Column names\n",
        "    - Column data types\n",
        "    - Column comments (e.g. column descriptions)\n",
        "    - Column constraints (e.g. NOT NULL, PRIMARY KEY, FOREIGN KEY)\n",
        "    - Column references (e.g. foreign key constraints)\n",
        "    - Table constraints (e.g. UNIQUE, PRIMARY KEY)\n",
        "    - Table references (e.g. foreign key constraints)\n",
        "    - Table comments (e.g. table descriptions)\n",
        "    - Table optimization options (e.g. PARTITIONED BY, CLUSTERED BY)\n",
        "    - Table row count\n",
        "    - Table size in bytes\n",
        "\n",
        "Leverage your bigquery expertise along with table optimization options appearing in the ddls (like Partitioning and Clustering) to suggest optimizations.\n",
        "Provide helpful commentary on the query optimizations that you suggest.\n",
        "Look for opportunities to suggest dataset level optimizations based on the types of queries the user asks about (for example, if partitioning, or clustering would be helpful).\n",
        "\n",
        "Important: Always ground your answer in metadata that is available to you in the storage bucket, or with information provided by the user.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "2_uzgN15iUol"
      },
      "id": "2_uzgN15iUol",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "BK9Al1fMxCsw",
        "128MNryM3tf8",
        "FXRDs6xH4LOZ",
        "yEx3D6513_kN",
        "5CXXETf94TbW",
        "H9LdVURn4kTB",
        "kapNbGnfAD37",
        "wQdeLgR9AJl_"
      ],
      "name": "KE Helper"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
